# AlgVex å®æ–½æ–¹æ¡ˆ

> **Qlib + Hummingbot èåˆçš„ä¸“ä¸šåŠ å¯†è´§å¸é‡åŒ–äº¤æ˜“å¹³å°**
>
> ç½‘ç«™: algvex.com
> ç‰ˆæœ¬: 2.0.0
> æ›´æ–°: 2025-12-31
>
> **v3.10.0 æ›´æ–°**: å®Œå–„ Hummingbot æ‰§è¡Œå±‚é›†æˆè®¾è®¡ï¼Œæ–°å¢ Iteration-4 äº¤ä»˜è®¡åˆ’

---

## ç›®å½•

- [0. ç¡¬çº¦æŸå±‚ï¼ˆå¿…é¡»å…ˆè¿‡é—¨æ§›ï¼‰](#0-ç¡¬çº¦æŸå±‚-ç‰ˆæœ¬åŒ–é…ç½®å“ˆå¸Œå®¡è®¡)
  - [0.0 MVP Scope å®šä¹‰](#00-mvp-scope-å®šä¹‰)
  - [0.1 ç³»ç»Ÿè§„çº¦åŸåˆ™ (P1-P10) + è½åœ°æœºåˆ¶](#01-ç³»ç»Ÿè§„çº¦åŸåˆ™-p1-p10--è½åœ°æœºåˆ¶)
  - [0.2 S1: æ—¶é—´+å¿«ç…§å¥‘çº¦](#02-s1-æ—¶é—´å¿«ç…§å¥‘çº¦-time--snapshot-contract)
  - [0.3 S2: æ•°æ®å¥‘çº¦æ¨¡æ¿](#03-s2-æ•°æ®å¥‘çº¦æ¨¡æ¿-data-contract-template)
  - [0.4 S3: é¢„ç®—ä¸é™çº§ç­–ç•¥](#04-s3-é¢„ç®—ä¸é™çº§ç­–ç•¥-budget--degrade-policy)
  - [0.5 S4: å› å­æ²»ç†](#05-s4-å› å­æ²»ç†-factor-governance)
  - [0.6 S5: å¯¹é½ä¸å½’å›  + Daily Replay](#06-s5-å¯¹é½ä¸å½’å› --daily-replay-alignment--attribution)
  - [0.7 S6: éªŒæ”¶æµ‹è¯•](#07-s6-éªŒæ”¶æµ‹è¯•-acceptance-tests)
  - [0.8 S7: ç‰©ç†è¾¹ç•Œéš”ç¦»](#08-s7-ç‰©ç†è¾¹ç•Œéš”ç¦»-p0-1)
  - [0.9 S8: DataManagerå”¯ä¸€å…¥å£](#09-s8-datamanagerå”¯ä¸€å…¥å£-p0-2)
  - [0.10 S9: Canonical Hashingè§„èŒƒ](#010-s9-canonical-hashingè§„èŒƒ-p0-3)
  - [0.11 S10: Replayç¡®å®šæ€§ä¿éšœ](#011-s10-replayç¡®å®šæ€§ä¿éšœ-p0-4)
  - [0.12 Iteration-1/2/3/4 äº¤ä»˜è®¡åˆ’](#012-iteration-1234-äº¤ä»˜è®¡åˆ’)
  - [0.13 ç¡¬çº¦æŸå±‚æ£€æŸ¥æ¸…å•](#013-ç¡¬çº¦æŸå±‚æ£€æŸ¥æ¸…å•)
  - [0.14 é€»è¾‘ä¸€è‡´æ€§å®¡æŸ¥](#014-é€»è¾‘ä¸€è‡´æ€§å®¡æŸ¥v397-å¢è¡¥)
  - [0.15 å¤æ‚åº¦è¯æ®åŒ–](#015-å¤æ‚åº¦è¯æ®åŒ–æŠŠå¤æ‚å†™æˆå¯éªŒè¯çš„ä»£ä»·ä¸æ”¶ç›Š)
  - [0.16 åˆç†å†³ç­–](#016-åˆç†å†³ç­–å¦‚ä½•ä¿è¯å¤æ‚åº¦ä¸æ˜¯ä¹±åŠ çš„ä¸ç åŠŸèƒ½ä½†æŠŠé«˜é…å˜æˆå¯æ§å¼€å…³)
- [1. é¡¹ç›®æ¦‚è¿°](#1-é¡¹ç›®æ¦‚è¿°)
- [2. ç³»ç»Ÿæ¶æ„](#2-ç³»ç»Ÿæ¶æ„)
- [3. æ•°æ®å±‚](#3-æ•°æ®å±‚)
- [4. ä¿¡å·å±‚](#4-ä¿¡å·å±‚)
- [5. å›æµ‹å±‚](#5-å›æµ‹å±‚)
- [6. æ‰§è¡Œå±‚](#6-æ‰§è¡Œå±‚)
- [7. é£æ§å±‚](#7-é£æ§å±‚)
- [8. æŠ€æœ¯æ ˆ](#8-æŠ€æœ¯æ ˆ)
- [9. ç›®å½•ç»“æ„](#9-ç›®å½•ç»“æ„)
- [10. éƒ¨ç½²æ–¹æ¡ˆ](#10-éƒ¨ç½²æ–¹æ¡ˆ)
- [11. P0 éªŒæ”¶æ ‡å‡†](#11-p0-éªŒæ”¶æ ‡å‡†-ä¸Šçº¿å‰å¿…é¡»å®Œæˆ)
- [12. å¼€å‘è·¯çº¿å›¾](#12-å¼€å‘è·¯çº¿å›¾)
- [æ–‡æ¡£æ€»ç»“](#æ–‡æ¡£æ€»ç»“)

---

## ğŸ“‹ v2.0.0 æ›´æ–°æ—¥å¿— (2025-12-31)

### ğŸ†• é‡å¤§æ›´æ–°: Qlib + Hummingbot å®Œæ•´åŠŸèƒ½å®ç°

#### 1. Qlib æ¨¡å‹å°è£…å±‚ (`research/qlib_models.py`)

å®Œæ•´å°è£… Qlib 0.9.7 æ‰€æœ‰ 25+ æ¨¡å‹:

| æ¨¡å‹ç±»åˆ« | æ¨¡å‹åˆ—è¡¨ |
|----------|----------|
| **GBDT** | LightGBM, XGBoost, CatBoost |
| **çº¿æ€§æ¨¡å‹** | Linear, Ridge, Lasso |
| **åŸºç¡€DL** | LSTM, GRU, MLP, TCN |
| **é«˜çº§DL** | Transformer, ALSTM, TabNet, GATS, SFM, HIST, TRA |
| **é›†æˆæ¨¡å‹** | DoubleEnsemble |
| **å…¶ä»–** | GAT, IGMTF, ADD, ADARNN, TCTS, Localformer |

```python
from algvex.research.qlib_models import ModelFactory, ModelType

# åˆ›å»ºæ¨¡å‹
model = ModelFactory.create(ModelType.TRANSFORMER, d_model=64, n_heads=8)
model.fit(dataset)
predictions = model.predict(dataset)
```

#### 2. äº¤æ˜“æ‰€è¿æ¥å™¨ (`core/execution/exchange_connectors.py`)

æ”¯æŒå¤šäº¤æ˜“æ‰€æ°¸ç»­åˆçº¦äº¤æ˜“:

| äº¤æ˜“æ‰€ | åŠŸèƒ½ |
|--------|------|
| **Binance Perpetual** | è®¢å•ã€æŒä»“ã€è´¦æˆ·ã€Kçº¿ã€èµ„é‡‘è´¹ç‡ |
| **Bybit Perpetual** | è®¢å•ã€æŒä»“ã€è´¦æˆ·ã€Kçº¿ã€èµ„é‡‘è´¹ç‡ |
| **OKX** (é¢„ç•™) | æ¶æ„å·²æ”¯æŒ |
| **Gate.io** (é¢„ç•™) | æ¶æ„å·²æ”¯æŒ |

```python
from algvex.core.execution.exchange_connectors import (
    BinancePerpetualConnector, BybitPerpetualConnector
)

connector = BinancePerpetualConnector(api_key, api_secret)
await connector.connect()
order = await connector.create_order(OrderRequest(...))
positions = await connector.get_positions()
```

#### 3. æ‰§è¡Œç­–ç•¥ (`core/execution/executors.py`)

å®ç° 5 ç§ä¸“ä¸šæ‰§è¡Œç®—æ³•:

| ç­–ç•¥ | è¯´æ˜ | ç”¨é€” |
|------|------|------|
| **TWAP** | æ—¶é—´åŠ æƒå¹³å‡ä»·æ ¼ | å¤§å•æ‹†åˆ†ï¼Œå‡å°‘å†²å‡» |
| **VWAP** | æˆäº¤é‡åŠ æƒå¹³å‡ä»·æ ¼ | è·Ÿè¸ªå¸‚åœºæˆäº¤åˆ†å¸ƒ |
| **Grid** | ç½‘æ ¼äº¤æ˜“ | éœ‡è¡è¡Œæƒ…ç›ˆåˆ© |
| **DCA** | å®šæŠ•ç­–ç•¥ | åˆ†æ‰¹å»ºä»“ |
| **Iceberg** | å†°å±±è®¢å• | éšè—å¤§å•æ„å›¾ |

```python
from algvex.core.execution.executors import TWAPExecutor, GridExecutor

# TWAP æ‰§è¡Œ
executor = TWAPExecutor(connector, OrderRequest(...), duration=3600, slices=12)
result = await executor.execute()

# ç½‘æ ¼äº¤æ˜“
executor = GridExecutor(connector, symbol, total_amount=10000, 
                        lower_price=40000, upper_price=45000, grids=10)
result = await executor.execute()
```

#### 4. HummingbotBridge v2.0.0 é‡å†™

å®Œå…¨é‡å†™çš„æ‰§è¡Œæ¡¥æ¥å±‚:

- å¤šäº¤æ˜“æ‰€æ”¯æŒ
- å¤šæ‰§è¡Œç­–ç•¥æ”¯æŒ
- å¼‚æ­¥è®¢å•ç®¡ç†
- è‡ªåŠ¨é‡è¿æœºåˆ¶
- å®Œæ•´çš„çŠ¶æ€åŒæ­¥

---

## ğŸ“‹ v5.1.0 æ›´æ–°æ—¥å¿— (2025-12-23)

### ğŸ†• æ–°å¢åŠŸèƒ½

#### 1. è·¨æˆªé¢å¤„ç†å™¨ (Qlib åŸç‰ˆé€‚é…)

| å¤„ç†å™¨ | è¯´æ˜ | ç”¨æ³• |
|--------|------|------|
| `CSZScoreNorm` | è·¨æˆªé¢ Z-Score æ ‡å‡†åŒ– | æ¯ä¸ªæ—¶é—´ç‚¹ç‹¬ç«‹è®¡ç®— z-score |
| `CSRankNorm` | è·¨æˆªé¢æ’åæ ‡å‡†åŒ– | å…¬å¼: (rank(pct=True) - 0.5) * 3.46 |
| `CSFillna` | è·¨æˆªé¢ç¼ºå¤±å€¼å¡«å…… | ç”¨åŒä¸€æ—¶é—´ç‚¹çš„å‡å€¼å¡«å…… |
| `TanhProcess` | Tanh å»å™ªå¤„ç† | å‹ç¼©æç«¯å€¼ |
| `ProcessInf` | æ— ç©·å€¼å¤„ç† | æ›¿æ¢ inf/-inf |
| `FilterCol` | åˆ—è¿‡æ»¤å™¨ | ä¿ç•™æŒ‡å®šåˆ— |
| `DropCol` | åˆ—åˆ é™¤å™¨ | åˆ é™¤æŒ‡å®šåˆ— |

```python
from algvex.core.factor import CSZScoreNorm, CSRankNorm, TanhProcess

# ä½¿ç”¨ç¤ºä¾‹
processors = ProcessorChain([
    CSZScoreNorm(),      # è·¨æˆªé¢ z-score
    CSRankNorm(),        # è·¨æˆªé¢æ’å
    TanhProcess(),       # tanh å»å™ª
])
```

#### 2. è¯„ä¼°æ¨¡å— (Qlib åŸç‰ˆ)

| å‡½æ•° | è¯´æ˜ |
|------|------|
| `risk_analysis(returns)` | å¹´åŒ–æ”¶ç›Šã€å¤æ™®æ¯”ç‡ã€æœ€å¤§å›æ’¤ |
| `calc_ic(pred, label)` | IC å’Œ Rank IC è®¡ç®— |
| `calc_long_short_return()` | å¤šç©ºæ”¶ç›Šåˆ†æ |
| `calc_long_short_prec()` | å¤šç©ºç²¾åº¦åˆ†æ |
| `generate_report()` | ç»¼åˆè¯„ä¼°æŠ¥å‘Š |

```python
from algvex.core import risk_analysis, calc_ic, generate_report

# é£é™©åˆ†æ
metrics = risk_analysis(returns, freq='day')
print(f"å¤æ™®æ¯”ç‡: {metrics['information_ratio']:.2f}")

# IC åˆ†æ
ic, rank_ic = calc_ic(predictions, labels)

# ç»¼åˆæŠ¥å‘Š
report = generate_report(predictions, labels, returns)
```

#### 3. Qlib é£æ ¼æ¨¡å‹æ¥å£

| æ¨¡å‹ | è¯´æ˜ |
|------|------|
| `LGBModel` | LightGBMï¼Œæ”¯æŒ fit/predict/finetune |
| `XGBModel` | XGBoostï¼Œå¸¦ç‰¹å¾é‡è¦æ€§ |
| `LinearModel` | OLS, NNLS, Ridge, Lasso |
| `get_model()` | ä¾¿æ·å·¥å‚å‡½æ•° |

```python
from algvex.core.model import LGBModel, LinearModel, get_model

# LightGBM æ¨¡å‹
model = LGBModel(num_leaves=64, learning_rate=0.05)
model.fit(dataset)
predictions = model.predict(dataset, segment='test')

# çº¿æ€§æ¨¡å‹
model = LinearModel(estimator='ridge', alpha=0.1)
model.fit(dataset)

# å¾®è°ƒ
model.finetune(new_dataset, num_boost_round=10)
```

---

## 0. ç¡¬çº¦æŸå±‚ (ç‰ˆæœ¬åŒ–é…ç½®+å“ˆå¸Œå®¡è®¡)

> **æ ¸å¿ƒåŸåˆ™**: æœ¬ç« èŠ‚å®šä¹‰çš„æ‰€æœ‰è§„åˆ™ä¸º**ç¡¬çº¦æŸ**ï¼Œé€šè¿‡**ç‰ˆæœ¬åŒ–é…ç½®æ–‡ä»¶+å“ˆå¸Œå®¡è®¡**å®ç°å¯è¿½æº¯æ€§ã€‚
>
> **é…ç½®ç‰ˆæœ¬åŒ–æœºåˆ¶**:
> - æ¯ä¸ªé…ç½®æ–‡ä»¶éƒ½æœ‰ `config_version` å’Œ `config_hash`
> - ä»»ä½•é…ç½®å˜æ›´å¿…é¡»èµ° Git PRï¼Œè‡ªåŠ¨è®¡ç®—æ–°çš„ hash
> - è¿è¡Œæ—¶æ ¡éªŒ config_hashï¼Œå‘ç°ä¸åŒ¹é…ç«‹å³æŠ¥è­¦
> - å†å²è¿è¡Œå¯é€šè¿‡ trace ä¸­çš„ config_hash ç²¾ç¡®å¤ç°
>
> **ç¡¬çº¦æŸ vs å®ç°**: ç¡¬çº¦æŸå±‚å®šä¹‰"å¿…é¡»éµå®ˆçš„è§„åˆ™"ï¼Œå®ç°å±‚å®šä¹‰"å¦‚ä½•åšåˆ°"ã€‚ç¡¬çº¦æŸé€šè¿‡é…ç½®ç‰ˆæœ¬åŒ–ä¿è¯ä¸€è‡´æ€§ï¼Œå®ç°å¯ä»¥æ¸è¿›æ›¿æ¢ã€‚

---

### 0.0 MVP Scope å®šä¹‰

> **MVP å¿…é¡»æ»¡è¶³ä»¥ä¸‹æ¡ä»¶æ‰èƒ½ä¸Šçº¿ Paper Trading**

#### 0.0.1 MVP è¾¹ç•Œ (å¿…é¡»æ»¡è¶³ A-D)

| æ¡ä»¶ | MVP å®šä¹‰ | éªŒæ”¶æ ‡å‡† |
|------|----------|----------|
| **A) å•ä¸€æ—¶é—´æ¡†æ¶** | ä»… 5 åˆ†é’Ÿ Bar | æ‰€æœ‰å› å­/ä¿¡å·/æ‰§è¡ŒåŸºäº 5m Bar |
| **B) æœ‰é™æ ‡çš„** | 20-50 ä¸ªæ°¸ç»­åˆçº¦ | åˆå§‹: BTCUSDT, ETHUSDT + Top-18 æµåŠ¨æ€§ |
| **C) æ¯æ—¥Replayå¯¹é½** | Live vs Replay åå·® < é˜ˆå€¼ | Daily job è‡ªåŠ¨æ¯”å¯¹å¹¶å‘Šè­¦ |
| **D) é…ç½®å¯è¿½æº¯** | æ‰€æœ‰é…ç½®ç‰ˆæœ¬åŒ–+å“ˆå¸Œ | trace è®°å½• config_hash |

#### 0.0.2 MVP æ•°æ®æº (æœ€å°é›†)

```yaml
# MVP ä»…ä½¿ç”¨ä»¥ä¸‹3ä¸ªæ•°æ®æº
mvp_data_sources:
  - source_id: klines_5m
    description: "5åˆ†é’ŸKçº¿ (OHLCV)"
    visibility: bar_close
    tier: A

  - source_id: open_interest_5m
    description: "5åˆ†é’ŸæŒä»“é‡å¿«ç…§"
    visibility: bar_close+5min
    tier: B

  - source_id: funding_8h
    description: "èµ„é‡‘è´¹ç‡ (æ¯8å°æ—¶)"
    visibility: scheduled
    tier: A
```

#### 0.0.3 å› å­ä½“ç³»åˆ†å±‚ (ç»Ÿä¸€å™äº‹)

> **å› å­å±‚çº§è¯´æ˜**: æ˜ç¡®å› å­æ•°é‡çš„å±‚çº§å…³ç³»ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å› å­ä½“ç³»åˆ†å±‚ (ç»Ÿä¸€å™äº‹)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€å±‚çº§1: MVPç”Ÿäº§å› å­ã€‘11ä¸ª â† å½“å‰é˜¶æ®µåªç”¨è¿™äº›                               â”‚
â”‚  â”œâ”€â”€ åŠ¨é‡æ— (5ä¸ª): return_5m, return_1h, ma_cross, breakout_20d,           â”‚
â”‚  â”‚                 trend_strength                                          â”‚
â”‚  â”œâ”€â”€ æ³¢åŠ¨ç‡æ— (3ä¸ª): atr_288, realized_vol_1d, vol_regime                  â”‚
â”‚  â””â”€â”€ è®¢å•æµæ— (3ä¸ª): oi_change_rate, funding_momentum,                     â”‚
â”‚                      oi_funding_divergence                                 â”‚
â”‚                                                                             â”‚
â”‚  ã€å±‚çº§2: ç ”ç©¶å› å­åº“ã€‘180ä¸ª â† ä»…å­˜åœ¨äº research/ ç›®å½•                        â”‚
â”‚  â”œâ”€â”€ åŸºäº klines + funding + oi çš„æ‰©å±•å› å­                                  â”‚
â”‚  â”œâ”€â”€ ç”¨äºå› å­ç ”ç©¶ã€æ¨¡å‹è®­ç»ƒã€ç­–ç•¥æ¢ç´¢                                        â”‚
â”‚  â””â”€â”€ éªŒè¯é€šè¿‡åå¯æ™‹å‡åˆ° MVP                                                 â”‚
â”‚                                                                             â”‚
â”‚  ã€å±‚çº§3: æ‰©å±•å› å­åº“ã€‘+21ä¸ª (P1æ‰©å±•) â† Phase 2 è€ƒè™‘                         â”‚
â”‚  â”œâ”€â”€ L2æ·±åº¦å› å­ (8ä¸ª): éœ€è¦æ·±åº¦æ•°æ®                                         â”‚
â”‚  â”œâ”€â”€ æ¸…ç®—å› å­ (5ä¸ª): éœ€è¦æ¸…ç®—æ•°æ®                                           â”‚
â”‚  â””â”€â”€ è·¨æ‰€Basis (8ä¸ª): éœ€è¦å¤šäº¤æ˜“æ‰€æ•°æ®                                      â”‚
â”‚                                                                             â”‚
â”‚  ã€è¯»è€…æŒ‡å¼•ã€‘                                                               â”‚
â”‚  - Part A: åªå…³æ³¨ 11ä¸ªMVPå› å­                                               â”‚
â”‚  - Part B Section 4: æ ‡æ³¨äº†å“ªäº›æ˜¯MVPã€å“ªäº›æ˜¯ç ”ç©¶ä¾§                           â”‚
â”‚  - å®æ–½é¡ºåº: MVP-11 â†’ éªŒè¯ç¨³å®š â†’ é€æ­¥æ‰©å±•                                   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**MVPå› å­è¯¦ç»†å®šä¹‰**:

> **å…³é”®çº¦æŸ**:
> - Kçº¿æ•°æ®çª—å£ä»¥ bar æ•°é‡è®¡ï¼Œ5m é¢‘ç‡ä¸‹ 288 bars = 1 day
> - æ´¾ç”Ÿå› å­çª—å£ (å¦‚ vol_regime çš„ MA) ä»¥æ ·æœ¬æ•°é‡è®¡ï¼Œéœ€æ˜ç¡®è¯´æ˜
> - OI å› å­ä½¿ç”¨å¯è§æ•°æ® (å›  5min å»¶è¿Ÿï¼ŒOI[t-1] æ˜¯ signal_time=t æ—¶çš„æœ€æ–°å¯è§å€¼)

| å› å­ID | å› å­æ— | è®¡ç®—å…¬å¼ | æ•°æ®ä¾èµ– | å¯è§æ€§ |
|--------|--------|----------|----------|--------|
| return_5m | åŠ¨é‡ | close[t] / close[t-1] - 1 | klines_5m | bar_close |
| return_1h | åŠ¨é‡ | close[t] / close[t-12] - 1 | klines_5m | bar_close |
| ma_cross | åŠ¨é‡ | MA(close, 5) / MA(close, 20) - 1 | klines_5m | bar_close |
| breakout_20d | åŠ¨é‡ | (close - rolling_max(high, 5760)) / atr_288 | klines_5m | bar_close |
| trend_strength | åŠ¨é‡ | ADX(14 bars) | klines_5m | bar_close |
| atr_288 | æ³¢åŠ¨ç‡ | ATR(288 bars) = 1 day | klines_5m | bar_close |
| realized_vol_1d | æ³¢åŠ¨ç‡ | std(return_5m, 288 bars) = 1 day | klines_5m | bar_close |
| vol_regime | æ³¢åŠ¨ç‡ | realized_vol_1d / MA(realized_vol_1d, 30 days) | klines_5m | bar_close |
| oi_change_rate | è®¢å•æµ | (OI[t-1] - OI[t-2]) / OI[t-2] | open_interest_5m | bar_close + 5min |
| funding_momentum | è®¢å•æµ | MA_settlement(3) - MA_settlement(8) | funding_8h (settled) | settlement_time |
| oi_funding_divergence | è®¢å•æµ | sign(oi_change) != sign(funding) | aligned_asof join | max(oi_visible, funding_visible) |

> **v1.1.0 é‡è¦ä¿®æ­£**:
> - `oi_change_rate`: å…¬å¼æ”¹ä¸º `(OI[t-1] - OI[t-2]) / OI[t-2]`ï¼Œå› ä¸º OI æœ‰ 5min å‘å¸ƒå»¶è¿Ÿ
>   - åœ¨ signal_time=t æ—¶ï¼ŒOI[t] çš„ visible_time = t+5min > tï¼Œä¸å¯ç”¨
>   - OI[t-1] çš„ visible_time = t-5min+5min = tï¼Œåˆšå¥½å¯ç”¨
>   - å› æ­¤è®¡ç®—å˜åŒ–ç‡éœ€ç”¨ OI[t-1] å’Œ OI[t-2]
> - `vol_regime`: æ˜ç¡® MA(30 days) æ˜¯ 30 å¤©çš„æ—¥æ³¢åŠ¨ç‡å¹³å‡å€¼ï¼Œéœ€ 30Ã—288 = 8640 bars æ•°æ®

**å› å­å¯è§æ€§è§„åˆ™**:

```yaml
# ============================================================
# funding_momentum çª—å£å®šä¹‰ (å…³é”®: ä»¥ç»“ç®—æ¬¡æ•°è®¡, é 5m bars!)
# ============================================================
funding_momentum:
  # çª—å£ç±»å‹: settlement_events (ä¸æ˜¯ bars!)
  # MA(3) = æœ€è¿‘3æ¬¡ç»“ç®—çš„å¹³å‡å€¼ (24å°æ—¶)
  # MA(8) = æœ€è¿‘8æ¬¡ç»“ç®—çš„å¹³å‡å€¼ (64å°æ—¶)
  window_type: "settlement_events"
  fast_n: 3   # 3æ¬¡ç»“ç®— = 24h
  slow_n: 8   # 8æ¬¡ç»“ç®— = 64h

  # ç¦æ­¢: å¯¹ forward-fill åçš„ 5m åºåˆ—ç”¨ rolling(n_bars)
  # é”™è¯¯ç¤ºä¾‹: funding.rolling(3).mean() åœ¨ 5m åºåˆ—ä¸Š = 15min è€Œé 24h!
  prohibited_patterns:
    - "rolling(n_bars) on forward-filled 5m series"

  # æ­£ç¡®å®ç°:
  implementation: |
    # åªå–ç»“ç®—æ—¶åˆ»çš„å€¼ (00:00, 08:00, 16:00 UTC)
    settlements = funding_8h.loc[funding_8h.index.hour.isin([0, 8, 16])]
    ma_fast = settlements.rolling(3).mean()
    ma_slow = settlements.rolling(8).mean()
    funding_momentum = ma_fast - ma_slow
    # ç„¶å forward-fill åˆ° 5m æ—¶é—´è½´

# ============================================================
# funding æ•°æ®çš„å¯è§æ€§å…³é”®è¯´æ˜
# ============================================================
funding_8h:
  # MVPåªä½¿ç”¨"å·²ç»“ç®—çš„ realized funding"ï¼Œä¸ä½¿ç”¨é¢„æµ‹ funding
  # å¯è§æ—¶é—´ = 8h ç»“ç®—æ—¶åˆ» (00:00, 08:00, 16:00 UTC)
  semantic: "realized_funding_after_settlement"
  visible_after: "settlement_time"  # 00:00/08:00/16:00 UTC
  forward_fill_to_5m: true  # å¡«å……åˆ° 5m æ—¶é—´è½´ä½†çª—å£è®¡ç®—ç”¨åŸå§‹åºåˆ—

# ============================================================
# oi_funding_divergence å¯¹é½è§„åˆ™
# ============================================================
oi_funding_divergence:
  # OI å¯è§å»¶è¿Ÿ 5minï¼Œfunding æ˜¯å®šæ—¶ç»“ç®—
  # å¿…é¡»ç”¨ aligned_asof åˆå¹¶ï¼Œå– max(oi_visible_time, funding_visible_time)
  alignment: "asof_join"
  oi_delay: "bar_close + 5min"
  funding_delay: "settlement_time"
```

#### 0.0.4 Qlib åœ¨ MVP ä¸­çš„å®šä½

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Qlib å®šä½: ç ”ç©¶å·¥å…·ï¼Œéç”Ÿäº§æ ¸å¿ƒ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€ç ”ç©¶/å›æµ‹é˜¶æ®µã€‘âœ… ä½¿ç”¨ Qlib                                               â”‚
â”‚  - å› å­è®¡ç®—ä¸ç ”ç©¶                                                           â”‚
â”‚  - æ¨¡å‹è®­ç»ƒ (LightGBM / XGBoost)                                           â”‚
â”‚  - å†å²å›æµ‹                                                                 â”‚
â”‚  - Walk-forward éªŒè¯                                                       â”‚
â”‚                                                                             â”‚
â”‚  ã€MVPç”Ÿäº§ç®¡é“ã€‘âŒ ä¸ä¾èµ– Qlib                                               â”‚
â”‚  - åŸå› : Qlib æ˜¯ç ”ç©¶æ¡†æ¶ï¼Œä¸æ˜¯å®æ—¶äº¤æ˜“æ¡†æ¶                                    â”‚
â”‚  - æ›¿ä»£: è‡ªå»ºè½»é‡çº§å› å­è®¡ç®—ç®¡é“ (factors/core/)                              â”‚
â”‚  - æ¨¡å‹: å¯¼å‡º Qlib è®­ç»ƒçš„æ¨¡å‹æƒé‡ï¼Œç”¨ç‹¬ç«‹æ¨ç†ä»£ç åŠ è½½                         â”‚
â”‚                                                                             â”‚
â”‚  ã€è¾¹ç•Œæ¸…æ™°åŒ–ã€‘                                                             â”‚
â”‚  - Qlib â†’ è¾“å‡º: model_weights.pkl, factor_definitions.yaml                 â”‚
â”‚  - ç”Ÿäº§ç®¡é“ â†’ è¾“å…¥: ä¸Šè¿°æ–‡ä»¶ + å®æ—¶æ•°æ® â†’ è¾“å‡º: äº¤æ˜“ä¿¡å·                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

### 0.1 ç³»ç»Ÿè§„çº¦åŸåˆ™ (P1-P10) + è½åœ°æœºåˆ¶

> **åŸåˆ™è½åœ°**: æ¯æ¡åŸåˆ™å¿…é¡»æœ‰å…·ä½“çš„æ£€æŸ¥æ–¹å¼ã€è´£ä»»äººã€è¿ååæœã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         AlgVex ç³»ç»Ÿè§„çº¦åŸåˆ™ (10æ¡)                            â”‚
â”‚                     è¿åä»»ä½•ä¸€æ¡å°†å¯¼è‡´ç³»ç»Ÿä¸å¯ä¿¡/ä¸å¯ç”¨                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€P1 å¯è§æ€§åŸåˆ™ No Lookaheadã€‘â˜…â˜…â˜… æœ€ç¡¬                                      â”‚
â”‚  ä»»ä½•æ•°æ®/å› å­å…ˆé—®ï¼šåœ¨ signal_time ä¹‹å‰ï¼Œæ˜¯å¦çœŸå®å¯è§ï¼Ÿ                         â”‚
â”‚  - æœ‰å‘å¸ƒå»¶è¿Ÿ â†’ å¿…é¡»æ˜¾å¼è®°å½• delayï¼Œå›æµ‹åš shift                              â”‚
â”‚  - ä¼šåè¡¥/ä¿®è®¢ â†’ å¿…é¡»å¼•å…¥ revision_idï¼Œè§„å®šå›æµ‹ç”¨å“ªä¸ªç‰ˆæœ¬                      â”‚
â”‚  - å£å¾„ä¸ç¨³å®š â†’ ç¦ç”¨æˆ–ä»…ä½œé£æ§æç¤ºï¼Œä¸è¿›ä¸»ä¿¡å·                                 â”‚
â”‚                                                                             â”‚
â”‚  ã€P2 å•ä¸€çœŸç›¸æº Single Source of Truthã€‘                                    â”‚
â”‚  æ‰€æœ‰ä¸Šå±‚è®¡ç®—å¿…é¡»å¯è¿½æº¯åˆ°åŒä¸€å¥— L0 äº‹å®æº + åŒä¸€æ¡ snapshot_cutoff             â”‚
â”‚  - Redis/ç¼“å­˜åªæ˜¯æ€§èƒ½å±‚ï¼Œä¸èƒ½æˆä¸º"ç¬¬äºŒäº‹å®æº"                                  â”‚
â”‚  - ä»»ä½•å› å­å¿…é¡»èƒ½å¤ç®—ï¼Œä¸èƒ½åªå­˜åœ¨äºå†…å­˜/ä¸´æ—¶ç¼“å­˜                                â”‚
â”‚                                                                             â”‚
â”‚  ã€P3 å¢é‡è¯æ˜ Marginal Utility Firstã€‘                                      â”‚
â”‚  æ¯æ–°å¢æ•°æ®/å› å­å¿…é¡»å†™æ¸…æ¥šå¢é‡å±äºå“ªä¸€ç±»ï¼š                                      â”‚
â”‚  - A) æå‡æ”¶ç›Šè´¨é‡ (Sharpe/å›æ’¤/ç¨³å®šæ€§)                                       â”‚
â”‚  - B) æå‡é£é™©æ§åˆ¶ (å°¾éƒ¨æŸå¤±/çˆ†ä»“æ¦‚ç‡ä¸‹é™)                                     â”‚
â”‚  - C) æå‡æ‰§è¡Œä¸€è‡´æ€§ (å›æµ‹-å®ç›˜åå·®ä¸‹é™)                                       â”‚
â”‚  è¯´ä¸æ¸…å±äºå“ªä¸€ç±» â†’ 99% æ˜¯å™ªå£°ç¨ (noise tax)ï¼Œç¦æ­¢å…¥åº“                         â”‚
â”‚                                                                             â”‚
â”‚  ã€P4 æˆæœ¬é¢„ç®— Budgeted Dataã€‘                                               â”‚
â”‚  æ¯ä¸ªæ•°æ®æºå¿…é¡»ç»™é¢„ç®—ï¼šå¸¦å®½/æ¶ˆæ¯é‡/CPU/å­˜å‚¨/ç»´æŠ¤æˆæœ¬                            â”‚
â”‚  é¢„ç®—è¶…æ ‡ â†’ å¿…é¡»è‡ªåŠ¨é™çº§ï¼šé™é¢‘ã€ç¼© universeã€åªé‡‡å…³é”®å­—æ®µ                       â”‚
â”‚  å¦åˆ™æç«¯è¡Œæƒ…ç³»ç»Ÿä¼šå› ä¸º"æ•°æ®å¤ªå…¨"è€Œå´©                                          â”‚
â”‚                                                                             â”‚
â”‚  ã€P5 ç¨³å®šä¼˜å…ˆ Stability > Noveltyã€‘                                         â”‚
â”‚  ä¼˜å…ˆé‡‡é›†"å£å¾„ç¨³å®šã€å¯è½ç›˜ã€å¯å¤ç°"çš„æ•°æ®                                      â”‚
â”‚  æ–°å¥‡ä½†ä¸ç¨³å®šçš„æ•°æ®ï¼šå…ˆåšè§‚æµ‹ä¸é£æ§ï¼Œä¸è¿›æ ¸å¿ƒæ¨¡å‹                               â”‚
â”‚  ç­‰ç¨³å®š+è½ç›˜å®Œæ•´å†è¿›å…¥ä¸»å› å­                                                  â”‚
â”‚                                                                             â”‚
â”‚  ã€P6 å¯å¤ç°ä¸å¯è¿½è´£ Reproducibility & Auditã€‘                               â”‚
â”‚  ä»»ä½•ä¸€æ¬¡ä¿¡å·ã€ä»»ä½•ä¸€ç¬”äº¤æ˜“ï¼Œå¿…é¡»èƒ½å›ç­”ï¼š                                       â”‚
â”‚  - å½“æ—¶çœ‹åˆ°çš„æ•°æ®å¿«ç…§æ˜¯ä»€ä¹ˆï¼Ÿ                                                 â”‚
â”‚  - å› å­å€¼æ€ä¹ˆæ¥çš„ï¼Ÿ                                                          â”‚
â”‚  - è®¢å•æ€ä¹ˆä¸‹çš„ï¼Ÿæˆäº¤æ€ä¹ˆå›æ¥çš„ï¼Ÿ                                              â”‚
â”‚  - PnLé‡Œæ¯ä¸€åˆ†é’±æ€ä¹ˆæ‰£çš„ï¼Ÿ(æ‰‹ç»­è´¹/æ»‘ç‚¹/èµ„é‡‘è´¹ç‡/å†²å‡»)                          â”‚
â”‚                                                                             â”‚
â”‚  ã€P7 å»å…±çº¿ä¸å»é‡å¤ Redundancy Controlã€‘                                    â”‚
â”‚  å†—ä½™å› å­ â†’ æ‹Ÿåˆæ›´å¼ºã€æ³›åŒ–æ›´å·®ã€æƒé‡ä¸ç¨³å®šã€ä¿¡å·æŠ–åŠ¨                            â”‚
â”‚  å¿…é¡»å»ºç«‹"å› å­æ—"ï¼šæ¯ä¸€æ—åªä¿ç•™å°‘æ•°ä»£è¡¨ï¼Œæˆ–åšæ­£äº¤åŒ–/é™ç»´                        â”‚
â”‚                                                                             â”‚
â”‚  ã€P8 ç¨³å¥æ€§ä¼˜å…ˆ Robustness Across Regimesã€‘                                 â”‚
â”‚  å› å­å¿…é¡»åœ¨ä¸åŒå¸‚åœºçŠ¶æ€ä¸‹å¯è§£é‡Šï¼šè¶‹åŠ¿/éœ‡è¡ã€é«˜/ä½æ³¢åŠ¨ã€æµåŠ¨æ€§å……è¶³/æ¯ç«­          â”‚
â”‚  åªèƒ½åœ¨ä¸€ä¸ª regime ä¸‹æ¼‚äº® â†’ å®ç›˜å˜æˆ"è¸©é›·æ£€æµ‹å™¨"                               â”‚
â”‚                                                                             â”‚
â”‚  ã€P9 å»¶è¿Ÿä¸é‡‡æ ·ä¸€è‡´ Latency & Sampling Consistencyã€‘                        â”‚
â”‚  æ˜ç¡®ç³»ç»Ÿæ˜¯ bar-based / event-based / hybrid                                â”‚
â”‚  OI/CVD/æ·±åº¦æ•°æ®å¦‚ä½•å¯¹é½åˆ° bar_close å¿…é¡»æœ‰å”¯ä¸€è§„åˆ™                           â”‚
â”‚  å¯¹é½ä¸ä¸€è‡´ â†’ "æ•°æ®è¶Šå¤šï¼Œè¯¯å·®è¶Šå¤§"                                            â”‚
â”‚                                                                             â”‚
â”‚  ã€P10 å…ˆå¯¹é½åå¢å¼º Alignment Firstã€‘                                        â”‚
â”‚  ä¼˜å…ˆæŠŠ"å›æµ‹=å®ç›˜"åšåˆ°æœ€æ¥è¿‘ï¼Œå†åšæ›´å¤æ‚çš„å› å­ä¸æ¨¡å‹                            â”‚
â”‚  å¦åˆ™æ°¸è¿œä¸çŸ¥é“æ”¶ç›Šå˜åŒ–æ¥è‡ªï¼šå› å­å˜å¼º è¿˜æ˜¯ å¯¹é½/æ‰§è¡Œ/æ‰£è´¹æ–¹å¼å˜äº†               â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 0.1.1 åŸåˆ™è½åœ°æœºåˆ¶ (æ¯æ¡åŸåˆ™å¦‚ä½•æ£€æŸ¥)

| åŸåˆ™ | æ£€æŸ¥æ–¹å¼ | æ£€æŸ¥æ—¶æœº | è¿ååæœ |
|------|----------|----------|----------|
| **P1 å¯è§æ€§** | T1_VisibilityTest è‡ªåŠ¨æµ‹è¯• | PRé—¨ç¦ + æ¯æ—¥Replay | PRæ‹’ç» / å‘Šè­¦ |
| **P2 å•ä¸€çœŸç›¸æº** | DataServiceæ¥å£å¼ºåˆ¶ + å¯¼å…¥æ‰«æ | PRé—¨ç¦ | PRæ‹’ç» |
| **P3 å¢é‡è¯æ˜** | å› å­å‡†å…¥å®¡æŸ¥è¡¨ (è§ä¸‹æ–¹æ¨¡æ¿) | å› å­å…¥åº“å‰ | ä¸å¡«è¡¨ä¸å…¥åº“ |
| **P4 æˆæœ¬é¢„ç®—** | budget.yaml é¢„ç®—å®šä¹‰ + è¿è¡Œæ—¶ç›‘æ§ | å¯åŠ¨æ—¶ + è¿è¡Œæ—¶ | è‡ªåŠ¨é™çº§ |
| **P5 ç¨³å®šä¼˜å…ˆ** | æ•°æ®æºtieråˆ†çº§ (A/B/C) | æ•°æ®æºæ¥å…¥æ—¶ | B/Cæ¡£ä¸è¿›MVP |
| **P6 å¯å¤ç°** | Trace Schema å¼ºåˆ¶è®°å½• | æ¯æ¡ä¿¡å· | æ— traceçš„ä¿¡å·ä¸¢å¼ƒ |
| **P7 å»å†—ä½™** | å› å­ç›¸å…³æ€§æ£€æŸ¥è„šæœ¬ | å› å­å…¥åº“å‰ | ç›¸å…³æ€§>0.8æ‹’ç» |
| **P8 ç¨³å¥æ€§** | Walk-forward + åˆ†regimeå›æµ‹ | å› å­å…¥åº“å‰ | å•regimeå› å­é™çº§ |
| **P9 é‡‡æ ·ä¸€è‡´** | visibility.yaml ç»Ÿä¸€è§„åˆ™ | é…ç½®æ ¡éªŒ | é…ç½®ä¸ä¸€è‡´æ‹’å¯åŠ¨ |
| **P10 å…ˆå¯¹é½** | Daily Replayå·®å¼‚ < é˜ˆå€¼ | æ¯æ—¥ | å·®å¼‚å¤§æš‚åœäº¤æ˜“ |

#### 0.1.2 P3å¢é‡è¯æ˜: å› å­/æ•°æ®æºå‡†å…¥å®¡æŸ¥è¡¨

```yaml
# æ¯æ–°å¢å› å­æˆ–æ•°æ®æºå¿…é¡»å¡«å†™æ­¤è¡¨ï¼Œå¦åˆ™ç¦æ­¢å…¥åº“
factor_admission_form:
  # åŸºæœ¬ä¿¡æ¯
  factor_id: "new_factor_xxx"
  proposer: "developer_name"
  date: "2025-12-22"

  # P3 å¢é‡è¯æ˜ (å¿…å¡«ï¼Œä¸‰é€‰ä¸€)
  marginal_utility:
    category: "A"  # A=æ”¶ç›Šæå‡ / B=é£é™©æ§åˆ¶ / C=æ‰§è¡Œä¸€è‡´æ€§
    evidence: |
      åœ¨6ä¸ªæœˆå›æµ‹ä¸­ï¼ŒåŠ å…¥æ­¤å› å­å:
      - Sharpeä»1.2æå‡åˆ°1.35 (+12.5%)
      - æœ€å¤§å›æ’¤ä»15%é™åˆ°12%
    backtest_report_link: "reports/factor_xxx_backtest.html"

  # P5 ç¨³å®šæ€§è¯„ä¼° (å¿…å¡«)
  stability:
    data_source_tier: "A"  # A/B/C
    history_available_days: 365
    schema_change_risk: "low"  # low/medium/high

  # P7 å†—ä½™æ£€æŸ¥ (å¿…å¡«)
  redundancy:
    max_correlation_with_existing: 0.65  # å¿…é¡» < 0.7
    most_correlated_factor: "existing_factor_yyy"

  # P8 ç¨³å¥æ€§ (å¿…å¡«)
  robustness:
    regimes_tested: ["trending", "ranging", "high_volatility"]
    positive_in_all_regimes: true  # å¿…é¡»ä¸ºtrue

  # å®¡æ‰¹
  approved_by: ""  # å®¡æ‰¹äººç­¾å
  approved_date: ""
```

#### 0.1.3 åŸåˆ™è¿åè‡ªåŠ¨å‘Šè­¦

```python
# algvex/core/principle_monitor.py
class PrincipleMonitor:
    """ç›‘æ§åŸåˆ™è¿åæƒ…å†µï¼Œè‡ªåŠ¨å‘Šè­¦"""

    def check_p1_visibility(self, signal: Signal, snapshot_cutoff: datetime) -> bool:
        """
        P1: æ£€æŸ¥ä¿¡å·æ˜¯å¦ä½¿ç”¨äº†æœªæ¥æ•°æ®

        å…³é”®ä¿®æ­£: åˆ¤æ–­åŸºå‡†å¿…é¡»æ˜¯ visible_time (ä¸æ˜¯ data_time!)
        è§„åˆ™: visible_time <= snapshot_cutoff æ‰èƒ½ä½¿ç”¨
        """
        for factor_value in signal.factors_used:
            # å…³é”®: ä½¿ç”¨ visible_time è€Œé data_time
            # visible_time = event_time + publication_delay (ç”± visibility.yaml å®šä¹‰)
            if factor_value.visible_time > snapshot_cutoff:
                self.alert(
                    principle="P1",
                    severity="critical",
                    message=f"Future data detected: {factor_value.factor_id} "
                            f"visible_time={factor_value.visible_time} > "
                            f"snapshot_cutoff={snapshot_cutoff}"
                )
                return False
        return True

    def check_p4_budget(self, metrics: SystemMetrics) -> bool:
        """P4: æ£€æŸ¥èµ„æºä½¿ç”¨æ˜¯å¦è¶…é¢„ç®—"""
        if metrics.api_calls_per_min > self.budget.max_api_calls_per_min * 0.8:
            self.alert(
                principle="P4",
                severity="warning",
                message=f"API usage at {metrics.api_calls_per_min}, approaching limit"
            )
            self.trigger_degrade()
            return False
        return True

    def check_p10_alignment(self, live_signal: Signal, replay_signal: Signal) -> bool:
        """P10: æ£€æŸ¥å›æµ‹-å®ç›˜å¯¹é½"""
        diff = abs(live_signal.value - replay_signal.value)
        if diff > self.alignment_threshold:
            self.alert(
                principle="P10",
                severity="critical",
                message=f"Alignment failed: live={live_signal.value}, "
                        f"replay={replay_signal.value}, diff={diff}"
            )
            return False
        return True

    def alert(self, principle: str, severity: str, message: str):
        """å‘é€å‘Šè­¦"""
        log.error(f"[{principle}][{severity}] {message}")
        if severity == "critical":
            # å‘é€ç´§æ€¥é€šçŸ¥ (Slack/é‚®ä»¶/çŸ­ä¿¡)
            notify_oncall(principle, message)
```

---

### 0.2 S1: æ—¶é—´+å¿«ç…§å¥‘çº¦ (Time & Snapshot Contract)

> **ç‰ˆæœ¬åŒ–é…ç½®**: æœ¬èŠ‚å®šä¹‰çš„æ—¶é—´è¯­ä¹‰å’Œå¯è§æ€§è§„åˆ™é€šè¿‡ `visibility.yaml` é…ç½®æ–‡ä»¶ç®¡ç†ï¼Œä»»ä½•å˜æ›´éœ€èµ° Git PRã€‚

#### 0.2.1 æ—¶é—´å­—æ®µå®šä¹‰ (å…¨ç³»ç»Ÿç»Ÿä¸€)

| å­—æ®µå | å®šä¹‰ | æ—¶åŒº | ç”¨é€” |
|--------|------|------|------|
| `event_time` | äº‹ä»¶å‘ç”Ÿçš„çœŸå®æ—¶é—´ | UTC | åŸå§‹æ•°æ®æ—¶é—´æˆ³ |
| `collected_at` | ç³»ç»Ÿé‡‡é›†åˆ°æ•°æ®çš„æ—¶é—´ | UTC | å»¶è¿Ÿç›‘æ§ã€å®¡è®¡ |
| `bar_open_time` | Kçº¿å¼€å§‹æ—¶é—´ | UTC | Bar æ ‡è¯† |
| `bar_close_time` | Kçº¿ç»“æŸæ—¶é—´ | UTC | ä¿¡å·ç”ŸæˆåŸºå‡†æ—¶é—´ |
| `signal_time` | ä¿¡å·ç”Ÿæˆæ—¶é—´ = `bar_close_time` | UTC | ç­–ç•¥å†³ç­–æ—¶é—´ |
| `snapshot_cutoff` | å¿«ç…§æˆªæ­¢æ—¶é—´ | UTC | å¯ç”¨æ•°æ®è¾¹ç•Œ |

#### 0.2.2 å¯è§æ€§è§„åˆ™ (visibility.yaml)

```yaml
# ============================================================
# æ–‡ä»¶: config/visibility.yaml
# è¯´æ˜: å¯è§æ€§è§„åˆ™é…ç½® (ç‰ˆæœ¬åŒ–ï¼Œä»»ä½•å˜æ›´éœ€èµ° Git PR)
# ============================================================
config_version: "1.1.0"
config_hash: "sha256:abc123..."  # è‡ªåŠ¨è®¡ç®—ï¼ŒCIæ£€æŸ¥ä¸€è‡´æ€§

# ============================================================
# å”¯ä¸€åˆ¤å®šå…¬å¼ (å…¨ç³»ç»Ÿç»Ÿä¸€ï¼Œä¸å…è®¸å…¶ä»–æ¨¡å—è‡ªå®šä¹‰)
# ============================================================
#
# ä»»ä½•æ•°æ®/å­—æ®µ/å› å­å¯ç”¨ å½“ä¸”ä»…å½“: visible_time <= snapshot_cutoff
#
# å®šä¹‰:
#   signal_time = bar_close_time (MVPå›ºå®š)
#   snapshot_cutoff = signal_time (å¯¹äº bar_close ç±»å‹æ•°æ®)
#   visible_time = æŒ‰æ•°æ®ç±»å‹è®¡ç®— (è§ä¸‹æ–¹ visibility_types)
#
# é‡è¦è¯´æ˜ (v1.1.0 ä¿®æ­£):
#   - bar_close æ•°æ®: visible_time = bar_close_time = signal_time
#     å› æ­¤ snapshot_cutoff å¿…é¡» >= signal_timeï¼Œå³ safety_margin = 0
#   - bar_close_delayed æ•°æ® (å¦‚ OI): visible_time = bar_close_time + delay
#     åœ¨ signal_time=t æ—¶ï¼ŒOI[t] çš„ visible_time = t + 5min > tï¼Œä¸å¯ç”¨
#     OI[t-1] çš„ visible_time = (t-5min) + 5min = tï¼Œåˆšå¥½å¯ç”¨ (<=)
#   - funding åªèƒ½ç”¨æœ€è¿‘ä¸€æ¬¡å·²ç»“ç®—çš„å€¼
#
# ============================================================
snapshot_cutoff_rule: "signal_time - safety_margin"
safety_margin: "0s"  # v1.1.0ä¿®æ­£: æ”¹ä¸º0sï¼Œé¿å… bar_close æ•°æ®ä¸å¯è§

visibility_types:
  realtime:
    description: "å®æ—¶æ•°æ®ï¼Œå‡ ä¹æ— å»¶è¿Ÿ"
    rule: "event_time + ${latency_buffer}"
    latency_buffer: "1s"
    examples:
      - mark_price
      - last_price
      - best_bid
      - best_ask

  bar_close:
    description: "Barèšåˆæ•°æ®ï¼Œbaræ”¶ç›˜åå®Œæ•´å¯è§"
    rule: "bar_close_time + 0s"
    examples:
      - ohlcv
      - taker_volume
      - cvd_5m
      - depth_aggregated

  bar_close_delayed:
    description: "Barèšåˆ+å»¶è¿Ÿæ•°æ®"
    rule: "bar_close_time + ${publication_delay}"
    publication_delay: "5min"  # å¯æŒ‰æ•°æ®æºè¦†ç›–
    examples:
      - oi_change
      - long_short_ratio

  scheduled:
    description: "å®šæ—¶å‘å¸ƒæ•°æ®"
    rule: "scheduled_time + ${publication_delay}"
    publication_delay: "0s"
    examples:
      - funding_rate
      - fear_greed_index
      - macro_data

# æ•°æ®æº -> å¯è§æ€§ç±»å‹ æ˜ å°„
source_visibility_map:
  klines_5m: bar_close
  open_interest_5m: bar_close_delayed
  funding_8h: scheduled
  mark_price: realtime
  liquidations: bar_close_delayed

# å®‰å…¨è¾¹é™…é…ç½®
safety_margins:
  default: "0s"
  conservative: "5s"
  # æ³¨æ„: ç”Ÿäº§ç¯å¢ƒç¦æ­¢ä½¿ç”¨è´Ÿå€¼! è´Ÿå€¼ä»…å…è®¸åœ¨ç ”ç©¶ç¯å¢ƒä¸­ä½¿ç”¨
  # aggressive: "-1s" # å·²ç¦ç”¨ - ä»»ä½•è´Ÿè¾¹é™…éƒ½ä¼šå¯¼è‡´ lookahead é£é™©
```

#### 0.2.3 é…ç½®å“ˆå¸ŒéªŒè¯

```python
# è¿è¡Œæ—¶æ ¡éªŒ visibility.yaml çš„ config_hash
def validate_visibility_config():
    """å¯åŠ¨æ—¶æ ¡éªŒé…ç½®æ–‡ä»¶å“ˆå¸Œï¼Œé˜²æ­¢æœªç»å®¡æ‰¹çš„ä¿®æ”¹"""
    config = load_yaml("config/visibility.yaml")
    expected_hash = config["config_hash"]
    actual_hash = compute_hash(config, exclude=["config_hash"])

    if expected_hash != actual_hash:
        raise ConfigIntegrityError(
            f"visibility.yaml å·²è¢«ä¿®æ”¹ä½†æœªæ›´æ–° config_hash! "
            f"expected={expected_hash}, actual={actual_hash}"
        )
```

#### 0.2.3 å¿«ç…§å¥‘çº¦ (Snapshot Contract)

```python
@dataclass(frozen=True)  # frozen=True è¡¨ç¤ºä¸å¯å˜
class SnapshotContract:
    """å¿«ç…§å¥‘çº¦ - å®šä¹‰æ•°æ®å¿«ç…§çš„ä¸å¯å˜è§„åˆ™"""

    # å¿«ç…§IDç”Ÿæˆè§„åˆ™: snapshot_id = f"snap_{cutoff_time}_{content_hash[:16]}"

    # å¿«ç…§å¿…é¡»åŒ…å«çš„å…ƒæ•°æ®
    REQUIRED_METADATA = [
        "snapshot_id",           # å”¯ä¸€æ ‡è¯†
        "cutoff_time",           # æˆªæ­¢æ—¶é—´
        "symbols",               # æ ‡çš„åˆ—è¡¨
        "data_sources",          # æ•°æ®æºåŠå…¶ç‰ˆæœ¬
        "visibility_config",     # å¯è§æ€§é…ç½®çš„hash
        "content_hash",          # æ•°æ®å†…å®¹hash
        "created_at",            # åˆ›å»ºæ—¶é—´
    ]

    # å¿«ç…§ä¸å¯å˜æ€§è§„åˆ™
    # 1. å¿«ç…§ä¸€æ—¦åˆ›å»ºï¼Œå†…å®¹æ°¸ä¸ä¿®æ”¹
    # 2. åŒä¸€ cutoff_time å¯èƒ½æœ‰å¤šä¸ªå¿«ç…§ï¼Œç”¨ snapshot_id åŒºåˆ†
    # 3. å›æµ‹/è®­ç»ƒå¿…é¡»æŒ‡å®š snapshot_idï¼Œä¸èƒ½ç”¨ "latest"
    # 4. å¿«ç…§æ–‡ä»¶å¿…é¡»æœ‰æ ¡éªŒå’Œï¼ŒåŠ è½½æ—¶éªŒè¯
```

---

### 0.3 S2: æ•°æ®å¥‘çº¦æ¨¡æ¿ (Data Contract Template)

> **ç‰ˆæœ¬åŒ–é…ç½®**: æ¯ä¸ªæ•°æ®æºçš„å¥‘çº¦å­˜å‚¨åœ¨ `config/data_contracts/{source_id}.yaml`ï¼Œå˜æ›´éœ€èµ° Git PRã€‚

#### 0.3.1 æ•°æ®å¥‘çº¦æ¨¡æ¿

```yaml
# ============================================================
# æ–‡ä»¶: config/data_contracts/klines_5m.yaml
# è¯´æ˜: æ•°æ®æºå¥‘çº¦ (ç‰ˆæœ¬åŒ–ï¼Œä»»ä½•å˜æ›´éœ€èµ° Git PR)
# ============================================================
config_version: "1.0.0"
config_hash: "sha256:def456..."  # è‡ªåŠ¨è®¡ç®—ï¼ŒCIæ£€æŸ¥ä¸€è‡´æ€§

data_contract:
  source_id: "klines_5m"
  source_name: "å¸å®‰æ°¸ç»­åˆçº¦5åˆ†é’ŸKçº¿"
  exchange: "binance"
  instrument_type: "perpetual"

  # å­—æ®µå®šä¹‰
  schema:
    primary_key: ["symbol", "bar_time"]
    time_field: "bar_time"
    time_zone: "UTC"
    fields:
      - name: open
        type: float
        nullable: false
      - name: high
        type: float
        nullable: false
      - name: low
        type: float
        nullable: false
      - name: close
        type: float
        nullable: false
      - name: volume
        type: float
        nullable: false
      - name: quote_volume
        type: float
        nullable: false
      - name: taker_buy_volume
        type: float
        nullable: false

  # å¯è§æ€§ (å¼•ç”¨ visibility.yaml ä¸­å®šä¹‰çš„ç±»å‹)
  visibility:
    type: "bar_close"  # å¼•ç”¨ visibility.yaml
    publication_delay: "0s"
    revision_policy: "no_revision"

  # å¯å¾—æ€§åˆ†çº§
  availability:
    tier: "A"
    history_window: "unlimited"
    backfill_support: true
    schema_stability: "high"
    free_tier: true  # å…è´¹æ•°æ®

  # æ•°æ®ç¨³å®šæ€§è¯„ä¼°
  stability_assessment:
    api_change_frequency: "low"  # low / medium / high
    last_schema_change: "2023-01-01"
    deprecation_risk: "low"
    backup_sources: []  # æ— å¤‡ç”¨æ•°æ®æº

  # é¢„ç®—ä¸é™çº§
  budget:
    max_symbols: 50
    max_frequency: "5m"
    max_api_calls_per_min: 100

  degrade_policy:
    - trigger: "api_calls > 80%"
      action: "reduce_symbols to top-20"
    - trigger: "latency > 10s"
      action: "skip_non_critical_symbols"

  # è´¨é‡éªŒæ”¶
  acceptance:
    tests:
      - "completeness > 99%"
      - "latency_p99 < 5s"
      - "no_duplicate_bars"
    on_failure: "block_ingestion"
```

#### 0.3.2 MVP æ•°æ®æºå¥‘çº¦çŠ¶æ€

| æ•°æ®æº | å¥‘çº¦æ–‡ä»¶ | çŠ¶æ€ | å¯è§æ€§ | å¯å¾—æ€§ | å…è´¹ |
|--------|----------|------|--------|--------|------|
| klines_5m | `data_contracts/klines_5m.yaml` | âœ… å·²å®šä¹‰ | bar_close | Aæ¡£ | âœ… |
| open_interest_5m | `data_contracts/open_interest_5m.yaml` | âœ… å·²å®šä¹‰ | bar_close+5min | Bæ¡£ | âœ… |
| funding_8h | `data_contracts/funding_8h.yaml` | âœ… å·²å®šä¹‰ | scheduled+0s | Aæ¡£ | âœ… |

**OI æ•°æ®å¥‘çº¦ (å¼ºåˆ¶ asof_join)**:

```yaml
# config/data_contracts/open_interest_5m.yaml
source_id: "open_interest_5m"
config_version: "1.0.0"

visibility:
  type: "bar_close_delayed"
  publication_delay: "5min"
  # visible_time = bar_close_time + 5min

# ============================================================
# å…³é”®çº¦æŸ: ç¦æ­¢ç›´æ¥å–åŒ bar çš„ OI (ä¼šå¯¼è‡´ lookahead)
# ============================================================
alignment:
  method: "asof_join_on_visible_time"
  # å¿…é¡»é€šè¿‡ DataService.asof_get() è·å– last_visible å€¼
  # åœ¨ signal_time=bar_close_time æ—¶, OI[t] ä¸å¯ç”¨, åªèƒ½ç”¨ OI[t-1]
  max_staleness: "15min"  # è¶…è¿‡åˆ™æ ‡è®°ç¼ºå¤±/é™çº§
  fallback: "last_valid"  # ç¼ºå¤±æ—¶ç”¨æœ€è¿‘æœ‰æ•ˆå€¼

# ç”Ÿäº§ä»£ç ç¦æ­¢:
prohibited_access_patterns:
  - "ç›´æ¥ JOIN ON bar_time (ä¼šäº§ç”Ÿ lookahead)"
  - "ä¸ç» visible_time æ£€æŸ¥ç›´æ¥å–å€¼"
```

**OI æ•°æ®è®¿é—®å¼ºåˆ¶è§„åˆ™**:

```python
# algvex/shared/data_service.py
class DataService(ABC):
    @abstractmethod
    def asof_get(
        self,
        source_id: str,
        cutoff_time: datetime,
        symbol: str
    ) -> Optional[DataPoint]:
        """
        è·å– cutoff_time ä¹‹å‰æœ€è¿‘çš„å¯è§æ•°æ®ç‚¹

        å…³é”®: è¿™æ˜¯å”¯ä¸€å…è®¸çš„ OI æ•°æ®è®¿é—®æ–¹å¼!
        ç¦æ­¢: ç›´æ¥æŒ‰ bar_time ç­‰å€¼ JOIN
        """
        pass

# ä½¿ç”¨ç¤ºä¾‹
def get_oi_for_signal(signal_time: datetime, symbol: str) -> float:
    """æ­£ç¡®çš„ OI è·å–æ–¹å¼"""
    # v1.1.0ä¿®æ­£: snapshot_cutoff = signal_time (safety_margin = 0s)
    snapshot_cutoff = signal_time

    # å¿…é¡»ç”¨ asof_get, ä¸èƒ½ç›´æ¥å– OI[bar_time=signal_time]
    # åœ¨ signal_time=t æ—¶:
    #   - OI[t] çš„ visible_time = t + 5min > tï¼Œä¸å¯ç”¨
    #   - OI[t-1] çš„ visible_time = (t-5min) + 5min = tï¼Œåˆšå¥½å¯ç”¨
    oi_point = data_service.asof_get(
        source_id="open_interest_5m",
        cutoff_time=snapshot_cutoff,
        symbol=symbol
    )

    if oi_point is None:
        raise DataNotAvailableError(f"No visible OI for {symbol} at {snapshot_cutoff}")

    # éªŒè¯: oi_point.visible_time <= snapshot_cutoff
    assert oi_point.visible_time <= snapshot_cutoff
    return oi_point.value
```

#### 0.3.3 å¥‘çº¦å˜æ›´å®¡è®¡

```python
# æ¯æ¬¡å¯åŠ¨æ—¶æ ¡éªŒæ‰€æœ‰æ•°æ®å¥‘çº¦
def validate_all_data_contracts():
    """æ ¡éªŒæ‰€æœ‰æ•°æ®å¥‘çº¦çš„ config_hash"""
    contracts_dir = Path("config/data_contracts")
    for yaml_file in contracts_dir.glob("*.yaml"):
        config = load_yaml(yaml_file)
        validate_config_hash(config, yaml_file.name)

    # è®°å½•å½“å‰ä½¿ç”¨çš„å¥‘çº¦ç‰ˆæœ¬åˆ° trace
    return {
        f.stem: config["config_hash"]
        for f in contracts_dir.glob("*.yaml")
        for config in [load_yaml(f)]
    }
```

---

### 0.4 S3: é¢„ç®—ä¸é™çº§ç­–ç•¥ (Budget & Degrade Policy)

> **è§„åˆ™**: ç³»ç»Ÿå¿…é¡»æœ‰èµ„æºé¢„ç®—å’Œè‡ªåŠ¨é™çº§æœºåˆ¶ã€‚

#### 0.4.1 å…¨å±€é¢„ç®—

```yaml
global_budget:
  network:
    max_websocket_connections: 50
    max_rest_calls_per_second: 100
  compute:
    max_factor_compute_time_per_bar: "30s"
  universe:
    default_symbols: ["BTCUSDT", "ETHUSDT"]
    max_symbols_normal: 20
    max_symbols_degraded: 5
```

#### 0.4.2 é™çº§è§¦å‘æ¡ä»¶

| Level | è§¦å‘æ¡ä»¶ | åŠ¨ä½œ | å‘Šè­¦ |
|-------|----------|------|------|
| L1 | api_usage > 70% | ç¼©å‡ universe (TOP-20 â†’ TOP-10) | warning |
| L2 | api_usage > 90% | ä»…ä¿ç•™ BTC/ETH + å…³é—­éæ ¸å¿ƒå› å­ | critical |
| L3 | latency > 30s | ä»… BTC/ETH + ä»…å¼€ä»“/åŠ ä»“æš‚åœ | emergency |
| L4 | æ•°æ®ä¸¢å¤±/äº¤æ˜“æ‰€é”™è¯¯ | ä¿æŠ¤æ¨¡å¼ (ä»…å¹³ä»“/ä¸å¼€æ–°ä»“) | emergency |

> **æ³¨æ„**: MVP å·²å›ºå®š 5m é¢‘ç‡ï¼Œé™çº§ä¸èƒ½æ”¹å˜ bar é¢‘ç‡ã€‚é™çº§åªèƒ½åœ¨ä»¥ä¸‹ç»´åº¦æ“ä½œ:
> - Universe èŒƒå›´ (æ ‡çš„æ•°é‡)
> - å› å­é›†åˆ (å…³é—­éæ ¸å¿ƒå› å­)
> - äº¤æ˜“åŠ¨ä½œ (æš‚åœå¼€ä»“/ä»…å¹³ä»“)
> - ä¸‹æ¸¸æ¨é€é¢‘ç‡ (UI åˆ·æ–°é¢‘ç‡ï¼Œéä¿¡å·é¢‘ç‡)

---

### 0.5 S4: å› å­æ²»ç† (Factor Governance)

> **ç‰ˆæœ¬åŒ–é…ç½®**: å› å­å‡†å…¥é—¨æ§›å­˜å‚¨åœ¨ `config/factor_governance.yaml`ï¼Œé˜ˆå€¼å¯æŒ‰å¸‚åœºçŠ¶æ€åŠ¨æ€è°ƒæ•´ã€‚

#### 0.5.1 å› å­å‡†å…¥é—¨æ§› (åŠ¨æ€é˜ˆå€¼)

```yaml
# ============================================================
# æ–‡ä»¶: config/factor_governance.yaml
# è¯´æ˜: ä½¿ç”¨åŠ¨æ€åŸºå‡†æ›¿ä»£å›ºå®šé˜ˆå€¼
# ============================================================
config_version: "1.0.0"
config_hash: "sha256:ghi789..."

factor_admission:
  # åŸºç¡€é—¨æ§› (å¿…é¡»æ»¡è¶³)
  basic_requirements:
    min_history_days: 180          # è‡³å°‘6ä¸ªæœˆ
    max_missing_rate: 0.05         # <5%
    max_correlation_with_existing: 0.7  # é˜²æ­¢å†—ä½™

  # IC é—¨æ§› (åŠ¨æ€åŸºå‡†)
  ic_thresholds:
    # é—®é¢˜: å›ºå®š IC>2% å¯¹åŠ å¯†è´§å¸é«˜æ³¢åŠ¨å¸‚åœºä¸é€‚ç”¨
    # è§£å†³: ä½¿ç”¨ç›¸å¯¹äºåŸºå‡†çš„åŠ¨æ€é˜ˆå€¼
    method: "relative_to_baseline"
    baseline: "rolling_mean_ic_30d"  # è¿‡å»30å¤©æ‰€æœ‰å› å­ICå‡å€¼
    min_ic_above_baseline: 0.005    # ICéœ€é«˜äºåŸºå‡†0.5%
    min_ic_ir: 0.3                  # IC_IR (IC/std(IC)) æœ€ä½è¦æ±‚

    # å¤‡é€‰: æŒ‰å¸‚åœºçŠ¶æ€åˆ†æ¡£
    regime_specific:
      trending:
        min_ic: 0.03
      ranging:
        min_ic: 0.015
      high_volatility:
        min_ic: 0.01  # é«˜æ³¢åŠ¨æœŸé—´ICè‡ªç„¶è¾ƒä½

  # ç¨³å¥æ€§è¦æ±‚
  robustness:
    min_regimes_positive: 3        # è‡³å°‘åœ¨3ç§å¸‚åœºçŠ¶æ€ä¸‹ICä¸ºæ­£
    max_single_regime_contribution: 0.6  # å•ä¸€çŠ¶æ€è´¡çŒ®ä¸è¶…è¿‡60%
```

#### 0.5.2 å› å­æ—ä¸å»å†—ä½™

```
MVP-11 å› å­æ—å®šä¹‰ (ä¸ Section 0.0.3 ä¸€è‡´):
â”œâ”€â”€ momentumæ— (5ä¸ª): return_5m, return_1h, ma_cross, breakout_20d, trend_strength
â”œâ”€â”€ volatilityæ— (3ä¸ª): atr_288, realized_vol_1d, vol_regime
â”œâ”€â”€ orderflowæ— (3ä¸ª): oi_change_rate, funding_momentum, oi_funding_divergence
â””â”€â”€ æ€»è®¡: 11ä¸ªç”Ÿäº§å› å­ (MVP Gate å¼ºåˆ¶ç™½åå•)

å»å†—ä½™æ–¹æ³•:
- ç›¸å…³æ€§ > 0.8 â†’ åªä¿ç•™ IC_IR æœ€é«˜çš„
- æ¯æ—æœ€å¤šä¿ç•™5ä¸ªä»£è¡¨å› å­
- æ–°å¢å› å­å¿…é¡»è¯æ˜ä¸ç°æœ‰å› å­çš„å¢é‡ä»·å€¼ (P3åŸåˆ™)
```

#### 0.5.3 å› å­é€€å‡ºæ¡ä»¶

| é€€å‡ºæ¡ä»¶ | åŠ¨ä½œ |
|----------|------|
| ICè¿ç»­3ä¸ªæœˆä½äºåŸºå‡†1% | é™æƒ50% â†’ è§‚å¯Ÿ â†’ é€€å‡º |
| IC_IR < 0.2 æŒç»­2ä¸ªæœˆ | ç¨³å®šæ€§æ£€æŸ¥ |
| å•ä¸€regimeè´¡çŒ® > 70% | é™ä¸ºé£æ§å› å­ |
| æ•°æ®æºä¸ç¨³å®š/åœæœ | ç«‹å³æš‚åœä½¿ç”¨ |

---

### 0.6 S5: å¯¹é½ä¸å½’å›  + Daily Replay (Alignment & Attribution)

> **æ ¸å¿ƒç›®æ ‡**: å¢åŠ å¯éªŒè¯çš„æ¯æ—¥Replayé—­ç¯å¯¹é½ï¼Œç¡®ä¿å›æµ‹ä¸å®ç›˜è¡Œä¸ºä¸€è‡´ã€‚

#### 0.6.1 Trace Schema (å®Œæ•´è¿½è¸ª)

> **é‡è¦**: Trace è½ç›˜å¿…é¡»ä½¿ç”¨ç¡®å®šæ€§ JSON åºåˆ—åŒ–ï¼Œç¡®ä¿ data_hash ä¸€è‡´æ€§

```yaml
# ============================================================
# æ–‡ä»¶: config/alignment.yaml
# è¯´æ˜: å¯¹é½ä¸è¿½è¸ªé…ç½® (ç‰ˆæœ¬åŒ–)
# ============================================================
config_version: "1.0.0"
config_hash: "sha256:jkl012..."

trace_schema:
  # æ¯æ¡ä¿¡å·/äº¤æ˜“å¿…é¡»è®°å½•çš„è¿½è¸ªä¿¡æ¯
  required_fields:
    - trace_id           # å”¯ä¸€è¿½è¸ªID
    - run_mode           # "live" | "replay" | "backtest"
    - timestamp          # æ‰§è¡Œæ—¶é—´
    - contract_hash      # visibility.yaml + data_contracts/*.yaml çš„è”åˆhash
    - config_hash        # æ‰€æœ‰é…ç½®æ–‡ä»¶çš„è”åˆhash
    - code_hash          # ä»£ç ç‰ˆæœ¬ (git commit hash)
    - data_hash          # è¾“å…¥æ•°æ®çš„hash

  # ä¿¡å·è¿½è¸ª
  signal_trace:
    - signal_id
    - snapshot_id
    - factors_used       # ä½¿ç”¨çš„å› å­åŠå…¶å€¼
    - model_version
    - raw_prediction
    - final_signal

  # æ‰§è¡Œè¿½è¸ª
  execution_trace:
    - order_intent
    - fill_reports
    - slippage_actual
    - commission_actual

  # åºåˆ—åŒ–è§„èŒƒ
  serialization:
    format: "json"
    sort_keys: true
    separators: [",", ":"]   # æ— ç©ºæ ¼ï¼Œç´§å‡‘æ ¼å¼
    ensure_ascii: false
```

#### 0.6.1.1 ç¡®å®šæ€§ Trace åºåˆ—åŒ–å™¨

```python
# algvex/core/trace_serializer.py
"""
ç¡®å®šæ€§ Trace åºåˆ—åŒ–

ç¡®ä¿ JSON åºåˆ—åŒ–ç¨³å®š: json.dumps(sort_keys=True, separators=(',', ':'))
"""
import json
from datetime import datetime, timezone
from decimal import Decimal
from typing import Any, Dict
import hashlib

class DeterministicTraceSerializer:
    """
    ç¡®å®šæ€§ Trace åºåˆ—åŒ–å™¨

    ä¿è¯:
    1. ç›¸åŒæ•°æ® â†’ ç›¸åŒ JSON å­—ç¬¦ä¸²
    2. ç›¸åŒ JSON å­—ç¬¦ä¸² â†’ ç›¸åŒ hash
    """

    def serialize(self, trace: Dict[str, Any]) -> str:
        """
        åºåˆ—åŒ– trace ä¸ºç¡®å®šæ€§ JSON å­—ç¬¦ä¸²

        Args:
            trace: trace å­—å…¸

        Returns:
            ç¡®å®šæ€§ JSON å­—ç¬¦ä¸²
        """
        # 1. é€’å½’è§„èŒƒåŒ–æ‰€æœ‰å€¼
        normalized = self._normalize(trace)

        # 2. ç¡®å®šæ€§åºåˆ—åŒ–
        # å…³é”®: sort_keys=True + separators æ— ç©ºæ ¼
        return json.dumps(
            normalized,
            sort_keys=True,
            separators=(',', ':'),
            ensure_ascii=False,
        )

    def compute_hash(self, trace: Dict[str, Any]) -> str:
        """è®¡ç®— trace çš„ç¡®å®šæ€§ hash"""
        serialized = self.serialize(trace)
        hash_value = hashlib.sha256(serialized.encode('utf-8')).hexdigest()
        return f"sha256:{hash_value[:16]}"

    def _normalize(self, obj: Any) -> Any:
        """é€’å½’è§„èŒƒåŒ–å€¼"""
        if isinstance(obj, dict):
            # é€’å½’å¤„ç†ï¼Œkey æ’åº
            return {k: self._normalize(v) for k, v in sorted(obj.items())}
        elif isinstance(obj, list):
            return [self._normalize(item) for item in obj]
        elif isinstance(obj, set):
            # set â†’ sorted list
            return sorted([self._normalize(item) for item in obj])
        elif isinstance(obj, datetime):
            # datetime â†’ ISO8601 UTC å­—ç¬¦ä¸²
            if obj.tzinfo is None:
                obj = obj.replace(tzinfo=timezone.utc)
            return obj.strftime("%Y-%m-%dT%H:%M:%S.%fZ")
        elif isinstance(obj, Decimal):
            # Decimal â†’ å­—ç¬¦ä¸² (ä¿ç•™ç²¾åº¦)
            return str(obj.normalize())
        elif isinstance(obj, float):
            # float â†’ 8ä½ç²¾åº¦å­—ç¬¦ä¸²
            return f"{obj:.8f}".rstrip('0').rstrip('.')
        elif obj is None:
            return None
        else:
            return obj

    def deserialize(self, json_str: str) -> Dict[str, Any]:
        """ååºåˆ—åŒ– JSON å­—ç¬¦ä¸²"""
        return json.loads(json_str)


# ============== Trace Writer ==============

class TraceWriter:
    """
    ç¡®å®šæ€§ Trace å†™å…¥å™¨

    ç”¨äºå†™å…¥ live_output_{date}.jsonl å’Œ replay_output_{date}.jsonl
    """

    def __init__(self, output_path: str):
        self.output_path = output_path
        self.serializer = DeterministicTraceSerializer()

    def write(self, trace: Dict[str, Any]):
        """å†™å…¥ä¸€æ¡ trace (JSONL æ ¼å¼)"""
        # ä½¿ç”¨ç¡®å®šæ€§åºåˆ—åŒ–
        line = self.serializer.serialize(trace)

        with open(self.output_path, 'a') as f:
            f.write(line + '\n')

    def compute_file_hash(self) -> str:
        """è®¡ç®—æ•´ä¸ªæ–‡ä»¶çš„ hash (ç”¨äºéªŒè¯)"""
        with open(self.output_path, 'rb') as f:
            content = f.read()
        hash_value = hashlib.sha256(content).hexdigest()
        return f"sha256:{hash_value[:16]}"


# ============== ä½¿ç”¨ç¤ºä¾‹ ==============

def create_signal_trace(
    signal_id: str,
    factors_used: Dict[str, float],
    **kwargs
) -> Dict[str, Any]:
    """åˆ›å»ºä¿¡å· trace"""
    serializer = DeterministicTraceSerializer()

    trace = {
        "trace_id": signal_id,
        "timestamp": datetime.now(timezone.utc),  # å¼ºåˆ¶ UTC
        "factors_used": factors_used,
        **kwargs,
    }

    # è®¡ç®— data_hash (ç”¨äºåç»­éªŒè¯)
    trace["data_hash"] = serializer.compute_hash({"factors": factors_used})

    return trace
```

#### 0.6.1.2 Trace å¯¹æ¯”éªŒè¯

```python
# scripts/verify_trace_determinism.py
"""éªŒè¯ trace åºåˆ—åŒ–ç¡®å®šæ€§"""

from algvex.core.trace_serializer import DeterministicTraceSerializer
from datetime import datetime, timezone
from decimal import Decimal

def test_trace_determinism():
    """æµ‹è¯•ç›¸åŒæ•°æ®äº§ç”Ÿç›¸åŒåºåˆ—åŒ–ç»“æœ"""
    serializer = DeterministicTraceSerializer()

    # æµ‹è¯•ç”¨ä¾‹: ä¸åŒé¡ºåºçš„ dict
    trace1 = {
        "b": 2,
        "a": 1,
        "factors": {"x": 0.1, "y": 0.2},
        "timestamp": datetime(2024, 1, 1, 12, 0, 0, tzinfo=timezone.utc),
    }

    trace2 = {
        "a": 1,
        "factors": {"y": 0.2, "x": 0.1},
        "b": 2,
        "timestamp": datetime(2024, 1, 1, 12, 0, 0, tzinfo=timezone.utc),
    }

    s1 = serializer.serialize(trace1)
    s2 = serializer.serialize(trace2)

    assert s1 == s2, f"å¤±è´¥: ç›¸åŒæ•°æ®äº§ç”Ÿä¸åŒåºåˆ—åŒ–\n{s1}\n{s2}"

    h1 = serializer.compute_hash(trace1)
    h2 = serializer.compute_hash(trace2)

    assert h1 == h2, f"å¤±è´¥: ç›¸åŒæ•°æ®äº§ç”Ÿä¸åŒ hash\n{h1}\n{h2}"

    print("âœ… éªŒè¯é€šè¿‡: trace åºåˆ—åŒ–ç¡®å®šæ€§æ­£å¸¸")

if __name__ == "__main__":
    test_trace_determinism()
```

#### 0.6.2 Daily Replay Alignment (æ¯æ—¥é—­ç¯éªŒè¯)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Daily Replay Alignment é—­ç¯éªŒè¯                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€å·¥ä½œæµç¨‹ã€‘                                                               â”‚
â”‚                                                                             â”‚
â”‚  1. Liveè¿è¡Œ (Tæ—¥)                                                         â”‚
â”‚     â”œâ”€ è®°å½•: signal_trace + execution_trace                                â”‚
â”‚     â””â”€ å­˜å‚¨: live_output_{date}.jsonl                                      â”‚
â”‚                                                                             â”‚
â”‚  2. Replayè¿è¡Œ (T+1æ—¥å‡Œæ™¨)                                                  â”‚
â”‚     â”œâ”€ è¾“å…¥: Tæ—¥çš„ snapshot_id (å›ºå®šæ•°æ®)                                   â”‚
â”‚     â”œâ”€ è¾“å…¥: Tæ—¥çš„ config_hash (å›ºå®šé…ç½®)                                   â”‚
â”‚     â”œâ”€ è¾“å…¥: Tæ—¥çš„ code_hash (å›ºå®šä»£ç )                                     â”‚
â”‚     â””â”€ è¾“å‡º: replay_output_{date}.jsonl                                    â”‚
â”‚                                                                             â”‚
â”‚  3. å¯¹æ¯”éªŒè¯ (è‡ªåŠ¨åŒ–)                                                       â”‚
â”‚     â”œâ”€ æ¯”å¯¹: live vs replay çš„ signal_trace                                â”‚
â”‚     â”œâ”€ å·®å¼‚ > é˜ˆå€¼ â†’ ç«‹å³å‘Šè­¦                                               â”‚
â”‚     â””â”€ è®°å½•: alignment_report_{date}.json                                  â”‚
â”‚                                                                             â”‚
â”‚  ã€å…³é”®çº¦æŸã€‘                                                               â”‚
â”‚  - Replay å¿…é¡»ä½¿ç”¨ä¸ Live ç›¸åŒçš„ snapshot_id                                 â”‚
â”‚  - Replay å¿…é¡»ä½¿ç”¨ä¸ Live ç›¸åŒçš„ config_hash                                 â”‚
â”‚  - ä»»ä½•å·®å¼‚éƒ½è¯´æ˜ç³»ç»Ÿå­˜åœ¨ä¸ç¡®å®šæ€§ (éœ€è¦è°ƒæŸ¥)                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 0.6.3 Trace Schema è§„èŒƒ

> **å…³é”®çº¦æŸ**: JSONL æ¯è¡Œæ˜¯ä¸€ä¸ªå®Œæ•´çš„ traceï¼Œé¡¶å±‚åŒ…å«æ‰€æœ‰å¿…éœ€å­—æ®µï¼Œä¸è¦åµŒå¥— `{"trace": {...}}`

```python
# Trace å¿…éœ€å­—æ®µ (JSONL æ¯è¡Œé¡¶å±‚)
REQUIRED_TRACE_FIELDS = [
    "signal_id",        # å”¯ä¸€æ ‡è¯†: f"{symbol}|{bar_close_time_iso}|{strategy_id}"
    "trace_id",         # å¯ç­‰äº signal_id
    "run_mode",         # "live" æˆ– "replay"
    "timestamp",        # ISO8601 UTC
    "symbol",           # äº¤æ˜“å¯¹
    "bar_close_time",   # ISO8601 UTC
    "raw_prediction",   # æ¨¡å‹åŸå§‹è¾“å‡º
    "final_signal",     # æœ€ç»ˆä¿¡å· (-1 åˆ° 1)
    "factors_used",     # Dict[str, float]
    "data_hash",        # è¾“å…¥æ•°æ®å“ˆå¸Œ
    "config_hash",      # é…ç½®å“ˆå¸Œ
    "snapshot_id",      # å¿«ç…§ID (å¯é€‰ï¼Œä½† replay å¿…éœ€)
]

# signal_id ç”Ÿæˆè§„åˆ™
def make_signal_id(symbol: str, bar_close_time: datetime, strategy_id: str) -> str:
    return f"{symbol}|{bar_close_time.isoformat()}|{strategy_id}"
```

#### 0.6.4 Replay å¯¹é½è„šæœ¬

```python
# scripts/daily_replay_alignment.py
from typing import Dict, List, Any
from dataclasses import dataclass

@dataclass
class AlignmentReport:
    """å¯¹é½æŠ¥å‘Šç»“æ„"""
    date: str
    total_live: int
    total_replay: int
    matched: int
    missing_in_replay: List[str]      # signal_ids åœ¨ live æœ‰ä½† replay æ²¡æœ‰
    missing_in_live: List[str]        # signal_ids åœ¨ replay æœ‰ä½† live æ²¡æœ‰
    mismatched: List[Dict[str, Any]]  # åŒ¹é…ä½†å­—æ®µä¸ä¸€è‡´
    max_signal_diff: float
    config_hash: str
    snapshot_id: str

def run_daily_alignment(date: str) -> AlignmentReport:
    """æ¯æ—¥ Replay å¯¹é½éªŒè¯"""

    # 1. åŠ è½½ Live è®°å½• (JSONL æ¯è¡Œæ˜¯é¡¶å±‚ trace)
    live_traces = load_jsonl(f"logs/live_output_{date}.jsonl")

    # 2. æŒ‰ signal_id å»ºç«‹ç´¢å¼• (å»é‡: ä¿ç•™æœ€åä¸€æ¡)
    live_by_id = {}
    for trace in live_traces:
        signal_id = trace["signal_id"]
        live_by_id[signal_id] = trace  # åå‡ºç°çš„è¦†ç›–

    # 3. è·å–é…ç½® (å–ç¬¬ä¸€æ¡çš„é…ç½®)
    first_trace = live_traces[0]
    snapshot_id = first_trace.get("snapshot_id", "")
    config_hash = first_trace["config_hash"]
    code_hash = first_trace.get("code_hash", "")

    # 4. Replay è¿è¡Œ
    replay_traces = run_replay(
        date=date,
        snapshot_id=snapshot_id,
        config_hash=config_hash,
        code_hash=code_hash,
    )
    replay_by_id = {t["signal_id"]: t for t in replay_traces}

    # 5. æŒ‰ signal_id åš join
    all_signal_ids = set(live_by_id.keys()) | set(replay_by_id.keys())

    missing_in_replay = []
    missing_in_live = []
    mismatched = []
    max_diff = 0.0

    for sid in sorted(all_signal_ids):
        live_t = live_by_id.get(sid)
        replay_t = replay_by_id.get(sid)

        if live_t and not replay_t:
            missing_in_replay.append(sid)
        elif replay_t and not live_t:
            missing_in_live.append(sid)
        else:
            # æ¯”è¾ƒå…³é”®å­—æ®µ
            diff = compare_trace_fields(live_t, replay_t)
            if diff["signal_diff"] > SIGNAL_DIFF_THRESHOLD:
                mismatched.append({
                    "signal_id": sid,
                    "live_signal": live_t["final_signal"],
                    "replay_signal": replay_t["final_signal"],
                    "diff": diff,
                })
            max_diff = max(max_diff, diff["signal_diff"])

    report = AlignmentReport(
        date=date,
        total_live=len(live_by_id),
        total_replay=len(replay_by_id),
        matched=len(all_signal_ids) - len(missing_in_replay) - len(missing_in_live),
        missing_in_replay=missing_in_replay,
        missing_in_live=missing_in_live,
        mismatched=mismatched,
        max_signal_diff=max_diff,
        config_hash=config_hash,
        snapshot_id=snapshot_id,
    )

    # 6. å‘Šè­¦
    if max_diff > SIGNAL_DIFF_THRESHOLD or missing_in_replay or missing_in_live:
        send_alert(f"Replay alignment issues for {date}: {report}")

    return report
```

#### 0.6.5 å¯¹é½éªŒæ”¶æ ‡å‡† (åˆ†å±‚)

> **å…³é”®ä¿®æ­£**: æµ®ç‚¹è¿ç®—/ä¸åŒ BLAS å®ç°ä¼šäº§ç”Ÿå¾®å°å·®å¼‚ï¼Œä¸åº”æŠ¥è­¦ã€‚
> é‡‡ç”¨åˆ†å±‚éªŒæ”¶æ ‡å‡†ï¼šç¡¬æŒ‡æ ‡å¿…é¡» 100% ä¸€è‡´ï¼Œè½¯æŒ‡æ ‡å…è®¸å®¹å·®ã€‚

**åˆ†å±‚éªŒæ”¶æ ‡å‡†**:

| å±‚çº§ | å¯¹é½é¡¹ | è¦æ±‚ | å®¹å·® | è¯´æ˜ |
|------|--------|------|------|------|
| **L1 (ç¡¬)** | data_hash | 100% ä¸€è‡´ | 0 | è¾“å…¥æ•°æ®å¿…é¡»å®Œå…¨ç›¸åŒ |
| **L2 (ç¡¬)** | features_hash | 100% ä¸€è‡´ | 0 | ç‰¹å¾å‘é‡å¿…é¡»å®Œå…¨ç›¸åŒ |
| **L3 (è½¯)** | raw_prediction | å…è®¸å¾®å°å·®å¼‚ | atol=1e-8, rtol=1e-6 | æ¨¡å‹æ¨ç†æµ®ç‚¹è¯¯å·® |
| **L4 (ç¡¬)** | final_signal | 100% ä¸€è‡´ | 0 | ç¦»æ•£åŒ–åçš„æœ€ç»ˆå†³ç­– |
| **L5 (è½¯)** | execution_trace | å…è®¸å·®å¼‚ | 10 bps | æ‰§è¡Œæ»‘ç‚¹/æ—¶åºå·®å¼‚ |

```python
# å¯¹é½éªŒè¯é€»è¾‘
def verify_alignment(live: Trace, replay: Trace) -> AlignmentResult:
    """åˆ†å±‚éªŒè¯ Live vs Replay å¯¹é½"""

    # L1: data_hash å¿…é¡» 100% ä¸€è‡´ (ç¡¬)
    if live.data_hash != replay.data_hash:
        return AlignmentResult(passed=False, level="L1",
                               reason=f"data_hash mismatch: {live.data_hash} vs {replay.data_hash}")

    # L2: features_hash å¿…é¡» 100% ä¸€è‡´ (ç¡¬)
    if live.features_hash != replay.features_hash:
        return AlignmentResult(passed=False, level="L2",
                               reason=f"features_hash mismatch")

    # L3: raw_prediction å…è®¸å¾®å°æµ®ç‚¹å·®å¼‚ (è½¯)
    # åŸå› : ä¸åŒ BLAS å®ç°ã€CPU/GPU å·®å¼‚å¯èƒ½äº§ç”Ÿ 1e-12 çº§è¯¯å·®
    if not np.allclose(live.raw_prediction, replay.raw_prediction,
                       atol=1e-8, rtol=1e-6):
        # è®°å½•å·®å¼‚ä½†ä¸ä¸€å®š fail
        diff = abs(live.raw_prediction - replay.raw_prediction)
        if diff > 1e-4:  # è¶…è¿‡ä¸‡åˆ†ä¹‹ä¸€æ‰ fail
            return AlignmentResult(passed=False, level="L3",
                                   reason=f"raw_prediction diff={diff}")

    # L4: final_signal (ç¦»æ•£åŒ–å) å¿…é¡» 100% ä¸€è‡´ (ç¡¬)
    if live.final_signal != replay.final_signal:
        return AlignmentResult(passed=False, level="L4",
                               reason=f"final_signal mismatch: {live.final_signal} vs {replay.final_signal}")

    return AlignmentResult(passed=True, level="all", reason="OK")
```

**æ‰§è¡Œå±‚å·®å¼‚å®¹å·®**:

| å¯¹é½é¡¹ | æœ€å¤§åå·® | å‘Šè­¦çº§åˆ« | è¯´æ˜ |
|--------|----------|----------|------|
| æˆäº¤ä»·å·® | 10 bps | warning | å¸‚åœºæµåŠ¨æ€§/æ—¶åºå·®å¼‚ |
| æ‰‹ç»­è´¹å·® | 5% | warning | è´¹ç‡é˜¶æ¢¯å·®å¼‚ |
| æ»‘ç‚¹å·® | 20 bps | warning | æ·±åº¦/æ—¶åºå·®å¼‚ |
| æ€»PnLå·® | 10% | critical | ç»¼åˆå·®å¼‚ |

#### 0.6.6 PnLå½’å› 

```python
@dataclass
class PnLAttribution:
    trade_id: str
    trace_id: str               # å…³è”åˆ°å®Œæ•´trace
    gross_pnl: Decimal          # æ¯›æ”¶ç›Š
    trading_fee: Decimal        # æ‰‹ç»­è´¹
    funding_fee: Decimal        # èµ„é‡‘è´¹ç‡
    slippage_cost: Decimal      # æ»‘ç‚¹æˆæœ¬
    net_pnl: Decimal            # å‡€æ”¶ç›Š

    def validate(self) -> bool:
        """æ ¡éªŒ: net = gross - all_costs"""
        expected = self.gross_pnl - self.trading_fee - self.funding_fee - self.slippage_cost
        return abs(expected - self.net_pnl) < Decimal("0.01")
```

---

### 0.7 S6: éªŒæ”¶æµ‹è¯• (Acceptance Tests)

> **è§„åˆ™**: æ¯ä¸ªæ¨¡å—ä¸Šçº¿å‰å¿…é¡»é€šè¿‡ä»¥ä¸‹æµ‹è¯•ã€‚

#### 0.7.1 æµ‹è¯•ç±»å‹

| æµ‹è¯•ç±»å‹ | è¯´æ˜ | å¿…é¡»é€šè¿‡ |
|----------|------|----------|
| T1: å¯è§æ€§æµ‹è¯• | ç»ä¸ä½¿ç”¨æœªæ¥æ•°æ® | âœ… PRå¿…é¡» |
| T2: å¤ç°æµ‹è¯• | åŒå¿«ç…§åŒè¾“å‡º | âœ… å‘å¸ƒå¿…é¡» |
| T3: å¯¹é½æµ‹è¯• | å›æµ‹-å®ç›˜åå·®åœ¨é˜ˆå€¼å†… | âœ… å‘å¸ƒå¿…é¡» |
| T4: ç¨³å®šæ€§æµ‹è¯• | æ–­çº¿/è¡¥æ•°/é‡å¤å¹‚ç­‰ | âœ… PRå¿…é¡» |
| T5: å› å­è´¨é‡æµ‹è¯• | IC/ç¨³å®šæ€§/å†—ä½™åº¦ | âœ… å› å­ä¸Šçº¿å¿…é¡» |

#### 0.7.2 CI/CDé—¨ç¦

```yaml
test_gates:
  pr_required: [T1, T4]
  release_required: [T1, T2, T3, T4]
  factor_admission: [T5, Walk-Forward]
  coverage:
    min_line_coverage: 80%
    critical_modules: 95%
```

---

### 0.8 S7: ç‰©ç†è¾¹ç•Œéš”ç¦» (P0-1)

> **è¦æ±‚**: research ä¸ production å¿…é¡»ç›®å½•éš”ç¦»ï¼Œç”¨ CI é—¨ç¦å¼ºåˆ¶æ‰§è¡Œã€‚

#### 0.8.1 ç›®å½•éš”ç¦»è§„èŒƒ

```
algvex/
â”œâ”€â”€ production/          # ç”Ÿäº§ä»£ç  (MVP)
â”‚   â”œâ”€â”€ factors/         # ä»…MVP-11å› å­
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ momentum.py      # return_5m, return_1h, ma_cross, breakout_20d, trend_strength
â”‚   â”‚   â”œâ”€â”€ volatility.py    # atr_288, realized_vol_1d, vol_regime
â”‚   â”‚   â””â”€â”€ orderflow.py     # oi_change_rate, funding_momentum, oi_funding_divergence
â”‚   â”œâ”€â”€ engine/          # ç”Ÿäº§å› å­è®¡ç®—å¼•æ“
â”‚   â”‚   â”œâ”€â”€ factor_engine.py     # ä¸ä¾èµ–Qlib
â”‚   â”‚   â””â”€â”€ model_runner.py      # åŠ è½½å¯¼å‡ºçš„æ¨¡å‹æƒé‡
â”‚   â”œâ”€â”€ signal/          # ä¿¡å·ç”Ÿæˆ
â”‚   â””â”€â”€ execution/       # æ‰§è¡Œå±‚æ¥å£
â”‚
â”œâ”€â”€ research/            # ç ”ç©¶ä»£ç  (å¯é€‰)
â”‚   â”œâ”€â”€ qlib_adapter.py  # Qlibé€‚é…å™¨ (ä»…æ­¤å¤„å¯import qlib)
â”‚   â”œâ”€â”€ alpha180/        # 180å› å­ç ”ç©¶
â”‚   â”œâ”€â”€ alpha201/        # 201å› å­ç ”ç©¶ (å«P1æ‰©å±•)
â”‚   â””â”€â”€ experiments/     # å®éªŒä»£ç 
â”‚
â””â”€â”€ shared/              # å…±äº«ä»£ç  (ä¸¥æ ¼å®¡æŸ¥)
    â”œâ”€â”€ data_service.py  # DataManageræ¥å£
    â”œâ”€â”€ time_provider.py # æ—¶é—´æœåŠ¡
    â””â”€â”€ types.py         # ç±»å‹å®šä¹‰
```

#### 0.8.2 å¯¼å…¥è§„åˆ™ (å¼ºåˆ¶)

```python
# ============================================================
# è§„åˆ™1: production/ ç¦æ­¢ import qlib
# ============================================================
# âŒ ç¦æ­¢ (CIä¼šå¤±è´¥)
from qlib.data import D
import qlib

# âœ… å…è®¸
from algvex.production.factors import momentum
from algvex.shared.data_service import DataService

# ============================================================
# è§„åˆ™2: production/ ç¦æ­¢ import research/
# ============================================================
# âŒ ç¦æ­¢
from algvex.research.alpha180 import factors

# âœ… å…è®¸
from algvex.production.factors import momentum

# ============================================================
# è§„åˆ™3: research/ å¯ä»¥ import production/ (å…±ç”¨åŸºç¡€è®¾æ–½)
# ============================================================
# âœ… å…è®¸
from algvex.production.factors import momentum  # ç ”ç©¶å¯å¤ç”¨ç”Ÿäº§å› å­
from algvex.shared.data_service import DataService
```

#### 0.8.3 CI é—¨ç¦è„šæœ¬

```python
# scripts/ci/check_import_boundary.py
"""CIé—¨ç¦: æ£€æŸ¥ production/ çš„éæ³•å¯¼å…¥"""

import ast
import sys
from pathlib import Path

FORBIDDEN_IMPORTS_IN_PRODUCTION = [
    "qlib",
    "algvex.research",
]

def check_file(filepath: Path) -> list[str]:
    """æ£€æŸ¥å•ä¸ªæ–‡ä»¶çš„éæ³•å¯¼å…¥"""
    violations = []
    with open(filepath) as f:
        tree = ast.parse(f.read())

    for node in ast.walk(tree):
        if isinstance(node, ast.Import):
            for alias in node.names:
                if any(alias.name.startswith(pkg) for pkg in FORBIDDEN_IMPORTS_IN_PRODUCTION):
                    violations.append(f"{filepath}:{node.lineno} - import {alias.name}")
        elif isinstance(node, ast.ImportFrom):
            if node.module and any(node.module.startswith(pkg) for pkg in FORBIDDEN_IMPORTS_IN_PRODUCTION):
                violations.append(f"{filepath}:{node.lineno} - from {node.module}")

    return violations

def main():
    production_dir = Path("algvex/production")
    all_violations = []

    for py_file in production_dir.rglob("*.py"):
        all_violations.extend(check_file(py_file))

    if all_violations:
        print("âŒ è¾¹ç•Œè¿è§„! production/ åŒ…å«éæ³•å¯¼å…¥:")
        for v in all_violations:
            print(f"  {v}")
        sys.exit(1)

    print("âœ… è¾¹ç•Œæ£€æŸ¥é€šè¿‡")
    sys.exit(0)

if __name__ == "__main__":
    main()
```

#### 0.8.4 CI é…ç½®

```yaml
# .github/workflows/boundary-check.yml
name: Boundary Check
on: [push, pull_request]

jobs:
  check-imports:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
      - name: Check import boundaries
        run: python scripts/ci/check_import_boundary.py

      # é¢å¤–éªŒè¯: production å³ä½¿ qlib æœªå®‰è£…ä¹Ÿèƒ½è¿è¡Œ
      - name: Verify production runs without qlib
        run: |
          pip install -e ".[production-only]"  # ä¸è£…qlib
          python -c "from algvex.production.engine import factor_engine; print('âœ… productionæ— éœ€qlib')"
```

---

### 0.9 S8: æ•°æ®å±‚å”¯ä¸€å…¥å£ (P0-2)

> **è¦æ±‚**: ç¦æ­¢ä»»ä½•æ¨¡å—ç›´æ¥è¯» DB/Redis/æ–‡ä»¶ï¼Œæ‰€æœ‰æ•°æ®è®¿é—®å¿…é¡»ç»è¿‡ DataService æ¥å£ã€‚
>
> **v1.1.0 æœ¯è¯­æ¾„æ¸…**:
> - **DataService**: æŠ½è±¡æ¥å£ (abstract interface)ï¼Œå®šä¹‰æ•°æ®è®¿é—®æ–¹æ³•ï¼Œå¤–éƒ¨æ¨¡å—åªèƒ½çœ‹åˆ°è¿™ä¸ª
> - **DataManager**: å…·ä½“å®ç° (concrete implementation)ï¼Œå†…éƒ¨æŒæœ‰ DB/Redis è¿æ¥ä¿¡æ¯
> - å¤–éƒ¨æ¨¡å—é€šè¿‡ä¾èµ–æ³¨å…¥è·å– DataService æ¥å£ï¼Œæ— æ³•è®¿é—® DataManager çš„è¿æ¥ä¿¡æ¯

#### 0.9.1 å”¯ä¸€å…¥å£æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      æ•°æ®å±‚æ¶æ„ (æ¥å£ä¸å®ç°åˆ†ç¦»)                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  å¤–éƒ¨æ¨¡å—åªèƒ½çœ‹åˆ° (DataService æ¥å£):                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚  interface DataService:  # æŠ½è±¡æ¥å£ï¼Œæ— è¿æ¥ä¿¡æ¯                       â”‚  â”‚
â”‚  â”‚    get_bars(symbol, start, end, freq) -> DataFrame                   â”‚  â”‚
â”‚  â”‚    get_snapshot(snapshot_id) -> Snapshot                             â”‚  â”‚
â”‚  â”‚    get_factor(factor_id, symbol, bar_time) -> float                  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                                             â”‚
â”‚  å†…éƒ¨å®ç° (DataManagerï¼Œå¯¹å¤–ä¸å¯è§):                                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”               â”‚
â”‚  â”‚  TimescaleDB   â”‚  â”‚     Redis      â”‚  â”‚   Parquet      â”‚               â”‚
â”‚  â”‚  (L0 äº‹å®æº)   â”‚  â”‚   (L2 ç¼“å­˜)    â”‚  â”‚  (L1 å¿«ç…§)     â”‚               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                                                                             â”‚
â”‚  å…³é”®: è¿æ¥ä¿¡æ¯åªåœ¨ DataManager å†…éƒ¨ï¼Œå¤–éƒ¨æ¨¡å—é€šè¿‡ DataService æ¥å£è®¿é—®      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 0.9.2 æ¥å£å®šä¹‰

```python
# algvex/shared/data_service.py
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Optional
import pandas as pd

class DataService(ABC):
    """æ•°æ®æœåŠ¡æ¥å£ - æ‰€æœ‰æ•°æ®è®¿é—®çš„å”¯ä¸€å…¥å£"""

    @abstractmethod
    def get_bars(
        self,
        symbol: str,
        start: datetime,
        end: datetime,
        freq: str = "5m",
        snapshot_id: Optional[str] = None,
    ) -> pd.DataFrame:
        """è·å–Kçº¿æ•°æ®"""
        pass

    @abstractmethod
    def get_latest_bar(self, symbol: str, freq: str = "5m") -> pd.Series:
        """è·å–æœ€æ–°Kçº¿"""
        pass

    @abstractmethod
    def get_funding_rate(self, symbol: str, bar_time: datetime) -> float:
        """è·å–èµ„é‡‘è´¹ç‡"""
        pass

    @abstractmethod
    def get_open_interest(self, symbol: str, bar_time: datetime) -> float:
        """è·å–æŒä»“é‡"""
        pass

# ============================================================
# æ¥å£ä¸å®ç°åˆ†ç¦»åŸåˆ™
# ============================================================
# âœ… æ­£ç¡®åšæ³•: DataManager å®ç° DataService æ¥å£ï¼Œé€šè¿‡ä¾èµ–æ³¨å…¥ä½¿ç”¨
# class DataManager(DataService):
#     def __init__(self, db_url, redis_url):  # è¿æ¥ä¿¡æ¯åªåœ¨ DataManager å†…éƒ¨
#         self._db = connect(db_url)
#         self._redis = connect(redis_url)
#
# def create_app():
#     manager = DataManager(db_url=os.getenv("DB_URL"), ...)
#     engine = FactorEngine(data_service=manager)  # æ³¨å…¥ä¸º DataService ç±»å‹
#
# âŒ ç¦æ­¢åšæ³•: å¤–éƒ¨æ¨¡å—ç›´æ¥è®¿é—®è¿æ¥ä¿¡æ¯
# engine = FactorEngine(db_url=..., redis_url=...)  # ä¸åº”è¯¥è®©å¤–éƒ¨çŸ¥é“è¿æ¥ä¿¡æ¯
```

#### 0.9.3 ä¾èµ–æ³¨å…¥

```python
# algvex/production/engine/factor_engine.py
class FactorEngine:
    """å› å­è®¡ç®—å¼•æ“ - é€šè¿‡æ¥å£è·å–æ•°æ®ï¼Œä¸çŸ¥é“æ•°æ®æ¥æº"""

    def __init__(self, data_service: DataService):
        # âœ… åªæ‹¿æ¥å£ï¼Œä¸æ‹¿è¿æ¥ä¿¡æ¯
        self._data = data_service

    def compute_return_5m(self, symbol: str, bar_time: datetime) -> float:
        bars = self._data.get_bars(symbol, bar_time - timedelta(minutes=5), bar_time, "5m")
        return (bars.iloc[-1]["close"] / bars.iloc[0]["close"]) - 1

# åº”ç”¨å¯åŠ¨æ—¶æ³¨å…¥
# main.py
def create_app():
    # è¿æ¥ä¿¡æ¯åªåœ¨è¿™ä¸€å¤„ï¼Œå¤–éƒ¨æ¨¡å—çœ‹ä¸åˆ°
    data_manager = DataManager(
        db_url=os.getenv("DB_URL"),      # åªæœ‰è¿™é‡ŒçŸ¥é“
        redis_url=os.getenv("REDIS_URL"), # åªæœ‰è¿™é‡ŒçŸ¥é“
    )
    factor_engine = FactorEngine(data_service=data_manager)
    return App(factor_engine)
```

#### 0.9.4 å¯¼å…¥æ‰«æé—¨ç¦

```python
# scripts/ci/check_data_access.py
"""
CIé—¨ç¦: æ£€æŸ¥éæ³•æ•°æ®åº“/Redisç›´æ¥è®¿é—®

å…³é”®: ä½¿ç”¨ ALLOWED_IMPL_PREFIXES (ç›®å½•) è€Œéå•ä¸ªæ–‡ä»¶
é¿å…è¯¯æ€: APIå±‚ã€migrationsã€infrastructure ç›®å½•
"""

# ç¦æ­¢ç›´æ¥å¯¼å…¥çš„æ•°æ®åº“/ç¼“å­˜åº“
FORBIDDEN_IMPORTS = [
    "psycopg2",
    "sqlalchemy",
    "redis",
    "asyncpg",
    "databases",
    "pymongo",
    "sqlite3",
]

# å…è®¸ç›´æ¥è®¿é—® DB/Redis çš„ç›®å½•/æ–‡ä»¶å‰ç¼€
# è¿™äº›æ¨¡å—è´Ÿè´£å®ç°æ•°æ®è®¿é—®ï¼Œå…¶ä»–æ¨¡å—å¿…é¡»é€šè¿‡ DataService æ¥å£
ALLOWED_IMPL_PREFIXES = [
    "algvex/infrastructure/",       # æ•°æ®è®¿é—®å®ç°å±‚
    "api/database.py",              # FastAPI æ•°æ®åº“é…ç½®
    "api/models/",                  # SQLAlchemy æ¨¡å‹å®šä¹‰
    "migrations/",                  # Alembic è¿ç§»è„šæœ¬
    "alembic/",                     # å¦ä¸€ç§è¿ç§»ç›®å½•å
    "tests/",                       # æµ‹è¯•å¯ä»¥ç›´æ¥è®¿é—®
]

def is_allowed_file(file_path: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶æ˜¯å¦åœ¨å…è®¸è®¿é—® DB çš„ç™½åå•ä¸­"""
    return any(file_path.startswith(prefix) for prefix in ALLOWED_IMPL_PREFIXES)

def check_data_access_violations():
    """æ‰«æéæ³•æ•°æ®è®¿é—® (æ’é™¤ç™½åå•ç›®å½•)"""
    import ast
    import sys
    from pathlib import Path

    violations = []

    # æ‰«ææ‰€æœ‰ Python æ–‡ä»¶
    for py_file in Path(".").rglob("*.py"):
        rel_path = str(py_file)

        # è·³è¿‡å…è®¸è®¿é—® DB çš„ç›®å½•
        if is_allowed_file(rel_path):
            continue

        # è·³è¿‡é algvex ç›®å½• (åªæ£€æŸ¥æ ¸å¿ƒä»£ç )
        if not rel_path.startswith("algvex/"):
            continue

        content = py_file.read_text()
        try:
            tree = ast.parse(content)
        except SyntaxError:
            continue

        for node in ast.walk(tree):
            if isinstance(node, ast.Import):
                for alias in node.names:
                    for banned in FORBIDDEN_IMPORTS:
                        if banned in alias.name:
                            violations.append({
                                "file": rel_path,
                                "line": node.lineno,
                                "type": "direct_import",
                                "module": alias.name,
                            })

            elif isinstance(node, ast.ImportFrom):
                if node.module:
                    for banned in FORBIDDEN_IMPORTS:
                        if banned in node.module:
                            violations.append({
                                "file": rel_path,
                                "line": node.lineno,
                                "type": "from_import",
                                "module": node.module,
                            })

    if violations:
        print(f"âŒ å‘ç° {len(violations)} å¤„æ•°æ®è®¿é—®è¿è§„:")
        for v in violations:
            print(f"  {v['file']}:{v['line']} - éæ³•å¯¼å…¥ {v['module']}")
        print("\næç¤º: ä¸šåŠ¡ä»£ç åº”é€šè¿‡ DataService æ¥å£è®¿é—®æ•°æ®")
        sys.exit(1)
    else:
        print("âœ… æ•°æ®è®¿é—®æ£€æŸ¥é€šè¿‡")
        return True

if __name__ == "__main__":
    check_data_access_violations()
```

---

### 0.10 S9: Canonical Hashingè§„èŒƒ (P0-3)

> **è¦æ±‚**: config_hash å¿…é¡»åŸºäºè§„èŒƒåŒ–å†…å®¹ï¼Œå®šä¹‰ç»Ÿä¸€çš„åºåˆ—åŒ–/æ’åº/ç²¾åº¦è§„åˆ™ã€‚

#### 0.10.1 Canonical è§„èŒƒ

> **å…³é”®è¯´æ˜**: hash åŸºäº"è§£æåå¯¹è±¡çš„ canonical JSON string"ï¼Œä¸æ˜¯ YAML æ–‡æœ¬

```yaml
# config/hashing_spec.yaml
hashing_specification:
  version: "1.1.0"

  # åºåˆ—åŒ–è§„åˆ™ (ç”¨äºhashè®¡ç®—ï¼Œä¸æ˜¯æ–‡ä»¶æ ¼å¼)
  serialization:
    # ä½¿ç”¨JSONè€ŒéYAMLï¼Œå› ä¸ºJSONæ›´ç¨³å®šç¡®å®š
    format: "json"
    json_options:
      sort_keys: true           # å¼ºåˆ¶æŒ‰keyæ’åº
      separators: [",", ":"]    # æ— ç©ºæ ¼ï¼Œæœ€ç´§å‡‘
      ensure_ascii: false       # ä¿ç•™unicode

  # æµ®ç‚¹æ•°è§„åˆ™
  float_precision:
    max_decimals: 8             # æœ€å¤š8ä½å°æ•°
    rounding: "half_even"       # é“¶è¡Œå®¶èˆå…¥
    representation: "string"    # è½¬ä¸ºå­—ç¬¦ä¸²é¿å…ç²¾åº¦é—®é¢˜

  # æ—¶é—´æ ¼å¼
  datetime_format: "ISO8601"    # 2025-12-22T00:00:00+00:00

  # æ’é™¤å­—æ®µ (è¿™äº›å­—æ®µä¸å‚ä¸hashè®¡ç®—)
  excluded_fields:
    - "config_hash"             # hashæœ¬èº«ä¸å‚ä¸
    - "_comments"               # æ³¨é‡Šä¸å‚ä¸
    - "_meta"                   # å…ƒä¿¡æ¯ä¸å‚ä¸

  # hashç®—æ³•
  algorithm: "sha256"
  truncate_to: 32               # å–å‰32å­—ç¬¦ (128ä½ï¼Œæ¨èç”¨äºå®¡è®¡)
  # æˆ–ä½¿ç”¨ full ä¿å­˜å®Œæ•´hash: truncate_to: 64
```

#### 0.10.2 Canonical Hash å®ç°

> **è¯´æ˜**: ä½¿ç”¨ JSON è®¡ç®— hashï¼Œä½¿ç”¨ ruamel.yaml å†™å›é…ç½®æ–‡ä»¶

**ä¾èµ–ç‰ˆæœ¬é”å®š** (requirements.txt):
```
# é”å®šç‰ˆæœ¬ï¼Œç¡®ä¿è·¨ç¯å¢ƒä¸€è‡´æ€§
PyYAML==6.0.1          # ç”¨äºè¯»å–
ruamel.yaml==0.18.6    # ç”¨äºå†™å› (ä¿ç•™æ³¨é‡Š/æ ¼å¼)
```

```python
# algvex/core/canonical_hash.py
"""
Canonical Hashing å®Œæ•´å®ç°

å…³é”®ç¨³å®šæ€§ä¿è¯:
1. PyYAML ç‰ˆæœ¬é”å®š (6.0.1)
2. æµ®ç‚¹æ•°è½¬ Decimal å­—ç¬¦ä¸² (ä¸è½¬å› float)
3. datetime å¼ºåˆ¶ ISO8601 UTC
4. dict/list é€’å½’æ’åº
5. set è½¬æ’åº list
"""
import hashlib
import yaml
from decimal import Decimal, ROUND_HALF_EVEN
from datetime import datetime, timezone
from typing import Any, Union
import json

class CanonicalHasher:
    """è§„èŒƒåŒ–å“ˆå¸Œè®¡ç®—å™¨"""

    EXCLUDED_FIELDS = {"config_hash", "_comments", "_meta"}
    FLOAT_PRECISION = 8

    def compute_hash(self, config: dict) -> str:
        """è®¡ç®—é…ç½®çš„è§„èŒƒåŒ–å“ˆå¸Œ"""
        # 1. ç§»é™¤æ’é™¤å­—æ®µ
        cleaned = self._remove_excluded(config)

        # 2. è§„èŒƒåŒ–å€¼ (è½¬ä¸ºç¨³å®šå­—ç¬¦ä¸²è¡¨ç¤º)
        normalized = self._normalize_values(cleaned)

        # 3. é€’å½’æ’åº (ç¡®ä¿keyé¡ºåºç¨³å®š)
        sorted_obj = self._deep_sort(normalized)

        # ä½¿ç”¨JSONè€ŒéYAMLï¼Œå› ä¸ºJSONæ›´ç¨³å®š
        # json.dumps ä¿è¯: sort_keys + separators ç¡®å®šæ€§
        canonical_str = json.dumps(
            sorted_obj,
            sort_keys=True,
            separators=(',', ':'),  # æ— ç©ºæ ¼ï¼Œæœ€ç´§å‡‘
            ensure_ascii=False,
        )

        # 4. è®¡ç®—hash (æˆªæ–­32å­—ç¬¦=128ä½ï¼Œæ»¡è¶³å®¡è®¡éœ€æ±‚)
        full_hash = hashlib.sha256(canonical_str.encode('utf-8')).hexdigest()
        return f"sha256:{full_hash[:32]}"

    def _remove_excluded(self, obj: Any) -> Any:
        """é€’å½’ç§»é™¤æ’é™¤å­—æ®µ"""
        if isinstance(obj, dict):
            return {
                k: self._remove_excluded(v)
                for k, v in obj.items()
                if k not in self.EXCLUDED_FIELDS
            }
        elif isinstance(obj, list):
            return [self._remove_excluded(item) for item in obj]
        return obj

    def _normalize_values(self, obj: Any) -> Any:
        """
        è§„èŒƒåŒ–å€¼

        å…³é”®: æµ®ç‚¹æ•°è½¬ä¸º Decimal å­—ç¬¦ä¸²ï¼Œä¸è½¬å› float
        é¿å… float çš„ç²¾åº¦é—®é¢˜å¯¼è‡´ hash ä¸ä¸€è‡´
        """
        if isinstance(obj, dict):
            return {k: self._normalize_values(v) for k, v in obj.items()}
        elif isinstance(obj, list):
            return [self._normalize_values(item) for item in obj]
        elif isinstance(obj, set):
            # set è½¬æ’åº list
            return sorted([self._normalize_values(item) for item in obj])
        elif isinstance(obj, float):
            # æµ®ç‚¹æ•° -> Decimal -> å­—ç¬¦ä¸² (ä¸è½¬å›float!)
            d = Decimal(str(obj)).quantize(
                Decimal(f"1e-{self.FLOAT_PRECISION}"),
                rounding=ROUND_HALF_EVEN
            )
            # è¿”å›è§„èŒƒåŒ–å­—ç¬¦ä¸²ï¼Œå¦‚ "0.12345678"
            return str(d.normalize())
        elif isinstance(obj, Decimal):
            # å·²ç»æ˜¯ Decimalï¼Œç›´æ¥è§„èŒƒåŒ–
            d = obj.quantize(
                Decimal(f"1e-{self.FLOAT_PRECISION}"),
                rounding=ROUND_HALF_EVEN
            )
            return str(d.normalize())
        elif isinstance(obj, datetime):
            # å¼ºåˆ¶ UTC ISO8601
            if obj.tzinfo is None:
                obj = obj.replace(tzinfo=timezone.utc)
            return obj.strftime("%Y-%m-%dT%H:%M:%SZ")
        return obj

    def _deep_sort(self, obj: Any) -> Any:
        """
        é€’å½’æ·±åº¦æ’åºï¼Œç¡®ä¿åµŒå¥—ç»“æ„ç¨³å®š

        å…³é”®è§„åˆ™:
        - dict key æ’åº âœ…
        - set è½¬ sorted list âœ…
        - list ä¿æŒåŸé¡ºåº âœ… (ä¸æ’åº! é¡ºåºæ˜¯è¯­ä¹‰çš„ä¸€éƒ¨åˆ†)

        ä¸æ’åº list çš„åŸå› :
        - degrade_policy çš„ä¼˜å…ˆçº§é¡ºåº
        - rules çš„åŒ¹é…é¡ºåº
        - pipelines çš„æ‰§è¡Œé¡ºåº
        è¿™äº›é¡ºåºå˜åŒ–åº”è¯¥è¢«è§†ä¸ºçœŸå®çš„é…ç½®å˜æ›´å¹¶å¯¼è‡´ hash å˜åŒ–
        """
        if isinstance(obj, dict):
            # dict key æ’åº
            return {k: self._deep_sort(v) for k, v in sorted(obj.items())}
        elif isinstance(obj, set):
            # set è½¬ sorted list (set æœ¬èº«æ— åºï¼Œéœ€æ’åº)
            return sorted(self._deep_sort(x) for x in obj)
        elif isinstance(obj, list):
            # list ä¿æŒåŸé¡ºåº! ä¸æ’åº!
            return [self._deep_sort(x) for x in obj]
        return obj

    def verify_hash(self, config: dict) -> bool:
        """éªŒè¯é…ç½®çš„hashæ˜¯å¦æ­£ç¡®"""
        expected = config.get("config_hash", "")
        actual = self.compute_hash(config)
        return expected == actual

    @staticmethod
    def self_test() -> bool:
        """è‡ªæµ‹ç¡®ä¿åºåˆ—åŒ–ç¨³å®š"""
        hasher = CanonicalHasher()

        # æµ‹è¯•ç”¨ä¾‹: ç›¸åŒè¯­ä¹‰ï¼Œä¸åŒè¡¨ç¤º
        test_cases = [
            ({"a": 1.0, "b": 2.0}, {"b": 2.0, "a": 1.0}),  # é¡ºåºä¸åŒ
            ({"x": 0.1 + 0.2}, {"x": 0.3}),  # æµ®ç‚¹ç²¾åº¦
            ({"t": datetime(2024, 1, 1, 0, 0, 0)},
             {"t": datetime(2024, 1, 1, 0, 0, 0, tzinfo=timezone.utc)}),
        ]

        for a, b in test_cases:
            hash_a = hasher.compute_hash(a)
            hash_b = hasher.compute_hash(b)
            if hash_a != hash_b:
                print(f"âŒ è‡ªæµ‹å¤±è´¥: {a} != {b}")
                return False

        print("âœ… Canonical Hash è‡ªæµ‹é€šè¿‡")
        return True
```

#### 0.10.3 CI è‡ªåŠ¨æ›´æ–° Hash

> **è¯´æ˜**: æ·»åŠ  write æƒé™ + é˜²æ­»å¾ªç¯ guard

```yaml
# .github/workflows/update-config-hash.yml
name: Update Config Hashes
on:
  push:
    paths:
      - 'config/**/*.yaml'
    # æ’é™¤botè‡ªå·±çš„æäº¤ï¼Œé˜²æ­¢æ­»å¾ªç¯
    branches-ignore:
      - 'dependabot/**'

# å¿…é¡»æœ‰ write æƒé™æ‰èƒ½ push
permissions:
  contents: write

jobs:
  update-hashes:
    runs-on: ubuntu-latest
    # è·³è¿‡è‡ªåŠ¨æ›´æ–°è§¦å‘çš„æäº¤
    if: "!contains(github.event.head_commit.message, 'chore: auto-update')"
    steps:
      - uses: actions/checkout@v4
        with:
          # ä½¿ç”¨ token ä»¥ä¾¿ push
          token: ${{ secrets.GITHUB_TOKEN }}

      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: pip install ruamel.yaml==0.18.6  # ä¿ç•™æ³¨é‡Š/æ ¼å¼ï¼Œä¸è„šæœ¬importä¸€è‡´

      - name: Update config hashes
        id: update
        run: |
          python scripts/ci/update_config_hashes.py
          # æ£€æŸ¥æ˜¯å¦æœ‰å®é™…å˜æ›´
          if git diff --quiet config/; then
            echo "no_changes=true" >> $GITHUB_OUTPUT
          else
            echo "no_changes=false" >> $GITHUB_OUTPUT
          fi

      - name: Commit updated hashes
        # åªåœ¨æœ‰å˜æ›´æ—¶æäº¤
        if: steps.update.outputs.no_changes == 'false'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add config/
          # commit message å¸¦ç‰¹æ®Šæ ‡è®°ï¼Œç”¨äºä¸Šé¢çš„ if åˆ¤æ–­
          git commit -m "chore: auto-update config hashes [skip ci]"
          git push
```

```python
# scripts/ci/update_config_hashes.py
"""
é…ç½®å“ˆå¸Œè‡ªåŠ¨æ›´æ–°è„šæœ¬

å…³é”®: ä½¿ç”¨ ruamel.yaml RoundTrip æ¨¡å¼ä¿ç•™æ³¨é‡Šå’Œæ ¼å¼!
- è¯»: ruamel.yaml RoundTripLoader
- å†™: ruamel.yaml RoundTripDumper
- hash è®¡ç®—: åŸºäºè§£æåå¯¹è±¡çš„ canonical JSON (ä¸ä¾èµ– YAML æ–‡æœ¬)
"""

import sys
from pathlib import Path
from ruamel.yaml import YAML
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from algvex.core.canonical_hash import CanonicalHasher

def update_all_config_hashes():
    """æ›´æ–°æ‰€æœ‰é…ç½®æ–‡ä»¶çš„å“ˆå¸Œ (ä¿ç•™æ³¨é‡Šå’Œæ ¼å¼)"""
    hasher = CanonicalHasher()
    config_dir = Path("config")
    updated_count = 0

    # ä½¿ç”¨ ruamel.yaml RoundTrip æ¨¡å¼ (ä¿ç•™æ³¨é‡Š/é¡ºåº/æ ¼å¼)
    yaml = YAML()
    yaml.preserve_quotes = True
    yaml.indent(mapping=2, sequence=4, offset=2)

    for yaml_file in config_dir.rglob("*.yaml"):
        with open(yaml_file, 'r') as f:
            config = yaml.load(f)

        if config is None:
            continue

        # è®¡ç®—æ–°å“ˆå¸Œ (åŸºäºè§£æåçš„ dict, ä¸æ˜¯ YAML æ–‡æœ¬)
        # æ³¨æ„: ruamel è¿”å›çš„æ˜¯ CommentedMap, éœ€è½¬ä¸ºæ™®é€š dict è®¡ç®— hash
        config_dict = dict(config) if hasattr(config, 'items') else config
        new_hash = hasher.compute_hash(config_dict)
        old_hash = config.get("config_hash", "")

        # å¹‚ç­‰æ£€æŸ¥ - åªåœ¨å“ˆå¸ŒçœŸæ­£å˜åŒ–æ—¶æ›´æ–°
        if old_hash == new_hash:
            continue

        # æ›´æ–°å“ˆå¸Œ (åªæ”¹è¿™ä¸€ä¸ªå­—æ®µï¼Œä¿ç•™å…¶ä»–ä¸€åˆ‡)
        config["config_hash"] = new_hash

        # å†™å› (ruamel ä¿ç•™æ³¨é‡Š/é¡ºåº/æ ¼å¼ï¼ŒPR diff æœ€å°åŒ–)
        with open(yaml_file, 'w') as f:
            yaml.dump(config, f)

        print(f"âœ… æ›´æ–° {yaml_file}: {old_hash[:20] if old_hash else 'None'}... -> {new_hash}")
        updated_count += 1

    if updated_count == 0:
        print("â„¹ï¸ æ‰€æœ‰é…ç½®å“ˆå¸Œå·²æ˜¯æœ€æ–°ï¼Œæ— éœ€æ›´æ–°")
    else:
        print(f"âœ… å…±æ›´æ–° {updated_count} ä¸ªé…ç½®æ–‡ä»¶")

    return updated_count

if __name__ == "__main__":
    update_all_config_hashes()
```

#### 0.10.4 Contract Hash å®šä¹‰

```python
# contract_hash = æ‰€æœ‰å¥‘çº¦é…ç½®çš„è”åˆhash
def compute_contract_hash() -> str:
    """è®¡ç®—æ‰€æœ‰å¥‘çº¦é…ç½®çš„è”åˆhash"""
    hasher = CanonicalHasher()
    contract_files = [
        "config/visibility.yaml",
        "config/data_contracts/klines_5m.yaml",
        "config/data_contracts/open_interest_5m.yaml",
        "config/data_contracts/funding_8h.yaml",
    ]

    combined = {}
    for filepath in sorted(contract_files):  # æ’åºä¿è¯ç¨³å®š
        with open(filepath) as f:
            config = yaml.safe_load(f)
            combined[filepath] = hasher._normalize_values(
                hasher._remove_excluded(config)
            )

    return hasher.compute_hash(combined)
```

---

### 0.11 S10: Replayç¡®å®šæ€§ä¿éšœ (P0-4)

> **è¦æ±‚**: æ¶ˆé™¤ Replay ä¸­çš„éç¡®å®šæ€§æ¥æºï¼Œä¿è¯ Live vs Replay å¯ç²¾ç¡®å¯¹æ¯”ã€‚

#### 0.11.1 éç¡®å®šæ€§æ¥æºä¸å¯¹ç­–

> **è¯´æ˜**: é™¤äº† random/timeï¼Œè¿˜éœ€å¤„ç†çº¿ç¨‹å¹¶è¡Œã€seté¡ºåºã€æµ®ç‚¹ç²¾åº¦

| éç¡®å®šæ€§æ¥æº | å¯¹ç­– |
|--------------|------|
| `datetime.now()` | ç»Ÿä¸€ä½¿ç”¨ TimeProviderï¼ŒReplay å›ºå®šæ—¶é’Ÿ |
| `random` / `np.random` | ç»Ÿä¸€ä½¿ç”¨ SeededRandomï¼Œå›ºå®šç§å­ |
| numpy/pandas çº¿ç¨‹å¹¶è¡Œ | å›ºå®š MKL/OPENBLAS çº¿ç¨‹æ•°=1 |
| set è¿­ä»£é¡ºåº | è½¬ä¸º sorted list åè¿­ä»£ |
| å¹¶å‘é˜Ÿåˆ—é¡ºåº | ä½¿ç”¨ç¡®å®šæ€§ä¼˜å…ˆçº§é˜Ÿåˆ— |
| æµ®ç‚¹è®¡ç®—è¯¯å·® | å…³é”®è·¯å¾„ä½¿ç”¨ Decimal |
| Liveç”¨WS vs Replayç”¨è½ç›˜ | Replay å¿…é¡»ä½¿ç”¨ Live è®°å½•çš„ data_hash |
| å­—å…¸è¿­ä»£é¡ºåº | Python 3.7+ é»˜è®¤æœ‰åºï¼Œæ— éœ€å¤„ç† |

#### 0.11.1.1 ç¯å¢ƒç¡®å®šæ€§é…ç½®

```python
# algvex/core/determinism.py
"""
å®Œæ•´çš„ç¡®å®šæ€§ç¯å¢ƒé…ç½®

å…³é”®çº¦æŸ:
- PYTHONHASHSEED å¿…é¡»åœ¨è¿›ç¨‹å¯åŠ¨å‰è®¾ç½® (shell/cron å¯åŠ¨è„šæœ¬)
- çº¿ç¨‹å˜é‡ä¹Ÿåº”åœ¨å¯åŠ¨å‰è®¾ç½®ï¼Œä½†å¯åœ¨ import numpy å‰è¡¥æ•‘
- æœ¬æ¨¡å—åªèƒ½"éªŒè¯"ï¼Œä¸èƒ½"è¡¥æ•‘" PYTHONHASHSEED
"""
import os
import sys
import warnings
from typing import Optional, List

class DeterministicEnvError(Exception):
    """ç¡®å®šæ€§ç¯å¢ƒé…ç½®é”™è¯¯ - ç”Ÿäº§ç¯å¢ƒå¿…é¡»æ‹’ç»å¯åŠ¨"""
    pass

def setup_deterministic_env(seed: int = 42, num_threads: int = 1, strict: bool = True):
    """
    é…ç½®ç¡®å®šæ€§ç¯å¢ƒ

    å¿…é¡»åœ¨ import numpy/pandas ä¹‹å‰è°ƒç”¨!

    Args:
        seed: å…¨å±€éšæœºç§å­
        num_threads: çº¿ç¨‹æ•° (1=å•çº¿ç¨‹ï¼Œç¡®ä¿ç¡®å®šæ€§)
        strict: True=ç”Ÿäº§ç¯å¢ƒ(è¿è§„æŠ›å¼‚å¸¸), False=ç ”ç©¶ç¯å¢ƒ(è¿è§„è­¦å‘Š)
    """
    issues = []

    # ============ æ£€æŸ¥ PYTHONHASHSEED (åªèƒ½æ£€æŸ¥ï¼Œä¸èƒ½è¡¥æ•‘!) ============
    # Python hash seed åœ¨è§£é‡Šå™¨å¯åŠ¨æ—¶å°±ç¡®å®šäº†
    # è¿è¡Œæ—¶è®¾ç½® os.environ["PYTHONHASHSEED"] ä¸ä¼šæ”¹å˜å½“å‰è¿›ç¨‹çš„ hash è¡Œä¸º!
    current_hashseed = os.environ.get("PYTHONHASHSEED")
    if current_hashseed is None:
        issues.append("PYTHONHASHSEED æœªåœ¨å¯åŠ¨å‰è®¾ç½®! è¯·åœ¨ shell/cron å¯åŠ¨è„šæœ¬ä¸­è®¾ç½®")
    elif current_hashseed != str(seed):
        issues.append(f"PYTHONHASHSEED={current_hashseed} ä¸é¢„æœŸ {seed} ä¸ç¬¦")

    # ============ è®¾ç½®çº¿ç¨‹å˜é‡ (å¿…é¡»åœ¨ import numpy ä¹‹å‰) ============
    os.environ["OMP_NUM_THREADS"] = str(num_threads)
    os.environ["MKL_NUM_THREADS"] = str(num_threads)
    os.environ["OPENBLAS_NUM_THREADS"] = str(num_threads)
    os.environ["VECLIB_MAXIMUM_THREADS"] = str(num_threads)
    os.environ["NUMEXPR_NUM_THREADS"] = str(num_threads)
    os.environ["OMP_DYNAMIC"] = "FALSE"
    os.environ["MKL_DYNAMIC"] = "FALSE"

    # ============ å¯¼å…¥ numpy å¹¶è®¾ç½®éšæœºç§å­ ============
    import numpy as np
    import random

    random.seed(seed)
    np.random.seed(seed)

    try:
        import mkl
        mkl.set_num_threads(num_threads)
    except ImportError:
        pass

    # ============ å¤„ç†é—®é¢˜ ============
    if issues:
        msg = f"ç¡®å®šæ€§ç¯å¢ƒé—®é¢˜: {issues}"
        if strict:
            raise DeterministicEnvError(msg)
        else:
            warnings.warn(msg, UserWarning)
            return False

    print(f"âœ… ç¡®å®šæ€§ç¯å¢ƒå·²éªŒè¯: seed={seed}, threads={num_threads}")
    return True


def verify_deterministic_env() -> bool:
    """éªŒè¯ç¡®å®šæ€§ç¯å¢ƒæ˜¯å¦æ­£ç¡®é…ç½®"""
    issues = []

    # æ£€æŸ¥çº¿ç¨‹é…ç½®
    thread_vars = [
        "OMP_NUM_THREADS", "MKL_NUM_THREADS", "OPENBLAS_NUM_THREADS"
    ]
    for var in thread_vars:
        val = os.environ.get(var)
        if val != "1":
            issues.append(f"{var}={val} (åº”ä¸º1)")

    # æ£€æŸ¥ hash seed
    if os.environ.get("PYTHONHASHSEED") is None:
        issues.append("PYTHONHASHSEED æœªè®¾ç½®")

    if issues:
        warnings.warn(f"ç¡®å®šæ€§ç¯å¢ƒé—®é¢˜: {issues}", UserWarning)
        return False

    return True
```

#### 0.11.1.2 Set/Collection ç¡®å®šæ€§å¤„ç†

```python
# algvex/shared/deterministic_collections.py
"""
ç¡®å®šæ€§é›†åˆæ“ä½œ

é—®é¢˜: set è¿­ä»£é¡ºåºåœ¨ä¸åŒè¿è¡Œ/ç¯å¢ƒä¸‹å¯èƒ½ä¸åŒ
è§£å†³: æ‰€æœ‰éœ€è¦è¿­ä»£ set çš„åœ°æ–¹ï¼Œå…ˆè½¬ä¸º sorted list
"""
from typing import Set, List, Any, Callable, TypeVar

T = TypeVar('T')

def sorted_set_iter(s: Set[T], key: Callable[[T], Any] = None) -> List[T]:
    """
    ç¡®å®šæ€§è¿­ä»£ set

    ç”¨æ³•:
        for item in sorted_set_iter(my_set):
            process(item)
    """
    if key:
        return sorted(s, key=key)
    return sorted(s)


def deterministic_dict_keys(d: dict) -> List[str]:
    """ç¡®å®šæ€§è·å– dict keys (è™½ç„¶ Python 3.7+ æœ‰åºï¼Œä½†æ˜¾å¼æ’åºæ›´å®‰å…¨)"""
    return sorted(d.keys())


class DeterministicPriorityQueue:
    """
    ç¡®å®šæ€§ä¼˜å…ˆçº§é˜Ÿåˆ—

    é—®é¢˜: heapq åœ¨ç›¸åŒä¼˜å…ˆçº§æ—¶é¡ºåºä¸ç¡®å®š
    è§£å†³: æ·»åŠ åºåˆ—å·ä½œä¸º tiebreaker
    """
    import heapq

    def __init__(self):
        self._queue = []
        self._counter = 0

    def push(self, priority: float, item: Any):
        """æ’å…¥å…ƒç´  (priority è¶Šå°è¶Šä¼˜å…ˆ)"""
        import heapq
        # counter ä½œä¸º tiebreakerï¼Œç¡®ä¿ FIFO
        heapq.heappush(self._queue, (priority, self._counter, item))
        self._counter += 1

    def pop(self) -> Any:
        """å¼¹å‡ºæœ€é«˜ä¼˜å…ˆçº§å…ƒç´ """
        import heapq
        _, _, item = heapq.heappop(self._queue)
        return item

    def __len__(self):
        return len(self._queue)
```

#### 0.11.1.3 å…³é”®è·¯å¾„ Decimal è§„èŒƒ

```python
# algvex/shared/decimal_utils.py
"""
å…³é”®è·¯å¾„ Decimal è§„èŒƒ

å…³é”®è·¯å¾„ = ä»»ä½•å½±å“ä¿¡å·/è®¢å•çš„æ•°å€¼è®¡ç®—
"""
from decimal import Decimal, ROUND_HALF_EVEN, getcontext
from typing import Union

# è®¾ç½®å…¨å±€ Decimal ç²¾åº¦
def setup_decimal_context():
    """å¿…é¡»åœ¨åº”ç”¨å¯åŠ¨æ—¶è°ƒç”¨"""
    ctx = getcontext()
    ctx.prec = 28  # 28ä½ç²¾åº¦ (è¶³å¤Ÿè¦†ç›–åŠ å¯†è´§å¸ä»·æ ¼)
    ctx.rounding = ROUND_HALF_EVEN  # é“¶è¡Œå®¶èˆå…¥

# å¼ºåˆ¶ Decimal çš„å…³é”®è®¡ç®—
def safe_divide(a: Union[Decimal, float], b: Union[Decimal, float]) -> Decimal:
    """å®‰å…¨é™¤æ³•ï¼Œé¿å…æµ®ç‚¹è¯¯å·®"""
    a_dec = Decimal(str(a)) if isinstance(a, float) else a
    b_dec = Decimal(str(b)) if isinstance(b, float) else b
    return a_dec / b_dec

def safe_multiply(a: Union[Decimal, float], b: Union[Decimal, float]) -> Decimal:
    """å®‰å…¨ä¹˜æ³•"""
    a_dec = Decimal(str(a)) if isinstance(a, float) else a
    b_dec = Decimal(str(b)) if isinstance(b, float) else b
    return a_dec * b_dec

# å› å­è®¡ç®—å¿…é¡»è¿”å› Decimal
class DecimalFactor:
    """å› å­å€¼å°è£… - ç¡®ä¿ç²¾åº¦"""

    def __init__(self, value: Union[float, Decimal, str]):
        if isinstance(value, float):
            self.value = Decimal(str(value))
        elif isinstance(value, str):
            self.value = Decimal(value)
        else:
            self.value = value

    def __float__(self) -> float:
        return float(self.value)

    def __repr__(self):
        return f"DecimalFactor({self.value})"
```

#### 0.11.1.4 å¯åŠ¨æ—¶å¼ºåˆ¶æ£€æŸ¥

```python
# algvex/main.py (ç¤ºä¾‹)
"""åº”ç”¨å…¥å£ - å¿…é¡»é¦–å…ˆé…ç½®ç¡®å®šæ€§ç¯å¢ƒ"""

# âš ï¸ å¿…é¡»åœ¨å…¶ä»– import ä¹‹å‰!
from algvex.core.determinism import setup_deterministic_env
setup_deterministic_env(seed=42, num_threads=1)

# ç°åœ¨å¯ä»¥å®‰å…¨å¯¼å…¥å…¶ä»–æ¨¡å—
import numpy as np
import pandas as pd
from algvex.core.mvp_scope_enforcer import MvpScopeEnforcer
# ...
```

#### 0.11.2 TimeProvider å®ç°

```python
# algvex/shared/time_provider.py
from abc import ABC, abstractmethod
from datetime import datetime
from typing import Optional

class TimeProvider(ABC):
    """æ—¶é—´æœåŠ¡æ¥å£ - æ¶ˆé™¤ datetime.now() çš„éç¡®å®šæ€§"""

    @abstractmethod
    def now(self) -> datetime:
        """è·å–å½“å‰æ—¶é—´"""
        pass

    @abstractmethod
    def sleep(self, seconds: float) -> None:
        """ç­‰å¾…æŒ‡å®šç§’æ•°"""
        pass


class LiveTimeProvider(TimeProvider):
    """ç”Ÿäº§ç¯å¢ƒ: ä½¿ç”¨çœŸå®æ—¶é—´"""

    def now(self) -> datetime:
        return datetime.utcnow()

    def sleep(self, seconds: float) -> None:
        import time
        time.sleep(seconds)


class ReplayTimeProvider(TimeProvider):
    """Replayç¯å¢ƒ: ä½¿ç”¨å›ºå®šæ—¶é—´åºåˆ—"""

    def __init__(self, timestamps: list[datetime]):
        self._timestamps = iter(timestamps)
        self._current: Optional[datetime] = None

    def now(self) -> datetime:
        if self._current is None:
            self._current = next(self._timestamps)
        return self._current

    def advance(self) -> None:
        """æ¨è¿›åˆ°ä¸‹ä¸€ä¸ªæ—¶é—´ç‚¹"""
        self._current = next(self._timestamps)

    def sleep(self, seconds: float) -> None:
        # Replay ä¸­ sleep æ˜¯ç©ºæ“ä½œ
        pass
```

#### 0.11.3 SeededRandom å®ç°

```python
# algvex/shared/seeded_random.py
import random
import numpy as np
from typing import Optional

class SeededRandom:
    """ç¡®å®šæ€§éšæœºæ•°ç”Ÿæˆå™¨"""

    def __init__(self, seed: int = 42):
        self._seed = seed
        self._py_random = random.Random(seed)
        self._np_random = np.random.RandomState(seed)

    def random(self) -> float:
        return self._py_random.random()

    def randint(self, a: int, b: int) -> int:
        return self._py_random.randint(a, b)

    def choice(self, seq):
        return self._py_random.choice(seq)

    def numpy_random(self) -> np.random.RandomState:
        return self._np_random

    def get_seed(self) -> int:
        return self._seed


# å…¨å±€å•ä¾‹ (åœ¨å¯åŠ¨æ—¶è®¾ç½®)
_global_random: Optional[SeededRandom] = None

def set_global_random(seed: int):
    global _global_random
    _global_random = SeededRandom(seed)

def get_global_random() -> SeededRandom:
    if _global_random is None:
        raise RuntimeError("SeededRandom not initialized. Call set_global_random() first.")
    return _global_random
```

#### 0.11.4 Replay è¾“å…¥æ•°æ®è¦æ±‚

```python
# Replay å¿…é¡»ä½¿ç”¨ä¸ Live å®Œå…¨ç›¸åŒçš„è¾“å…¥æ•°æ®
@dataclass
class ReplayInput:
    """Replay æ‰€éœ€çš„ç¡®å®šæ€§è¾“å…¥"""

    # å¿…é¡»æ¥è‡ª Live è®°å½•
    date: str
    snapshot_id: str          # Live ä½¿ç”¨çš„å¿«ç…§ID
    config_hash: str          # Live ä½¿ç”¨çš„é…ç½®hash
    code_hash: str            # Live ä½¿ç”¨çš„ä»£ç hash

    # ç¡®å®šæ€§æ§åˆ¶
    random_seed: int          # éšæœºç§å­
    timestamps: list[datetime]  # æ—¶é—´åºåˆ—

    # æ•°æ®éªŒè¯
    data_hash: str            # è¾“å…¥æ•°æ®çš„hash (å¿…é¡»ä¸Liveä¸€è‡´)

def validate_replay_input(replay_input: ReplayInput, live_trace: dict) -> bool:
    """éªŒè¯ Replay è¾“å…¥ä¸ Live è®°å½•ä¸€è‡´"""
    return (
        replay_input.snapshot_id == live_trace["snapshot_id"] and
        replay_input.config_hash == live_trace["config_hash"] and
        replay_input.code_hash == live_trace["code_hash"] and
        replay_input.data_hash == live_trace["data_hash"]
    )
```

#### 0.11.5 å…³é”®è·¯å¾„ Decimal

```python
# algvex/production/signal/position_calculator.py
from decimal import Decimal, ROUND_DOWN

class PositionCalculator:
    """ä»“ä½è®¡ç®— - ä½¿ç”¨ Decimal ä¿è¯ç²¾åº¦"""

    def calculate_quantity(
        self,
        capital: Decimal,
        price: Decimal,
        leverage: int,
        risk_pct: Decimal,
    ) -> Decimal:
        """è®¡ç®—ä¸‹å•æ•°é‡ (Decimalç²¾åº¦)"""
        risk_capital = capital * risk_pct
        notional = risk_capital * Decimal(leverage)
        quantity = (notional / price).quantize(Decimal("0.001"), rounding=ROUND_DOWN)
        return quantity
```

---

### 0.12 Iteration-1/2/3/4 äº¤ä»˜è®¡åˆ’

> å°†å¤§èŒƒå›´æ”¹é€ æ‹†åˆ†ä¸º4ä¸ªå¯éªŒè¯çš„å°è¿­ä»£ã€‚

#### 0.12.1 Iteration-1: å¥‘çº¦ + å¯è§æ€§ + Trace + è¾¹ç•Œéš”ç¦» (2å‘¨)

```
Iteration-1 äº¤ä»˜ç‰©:
â”œâ”€â”€ é…ç½®æ–‡ä»¶
â”‚   â”œâ”€â”€ config/visibility.yaml
â”‚   â”œâ”€â”€ config/data_contracts/klines_5m.yaml
â”‚   â”œâ”€â”€ config/data_contracts/open_interest_5m.yaml
â”‚   â”œâ”€â”€ config/data_contracts/funding_8h.yaml
â”‚   â””â”€â”€ config/factor_governance.yaml
â”œâ”€â”€ æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ algvex/core/config_validator.py    # é…ç½®å“ˆå¸Œæ ¡éªŒ
â”‚   â”œâ”€â”€ algvex/core/trace_logger.py        # Traceè®°å½•
â”‚   â””â”€â”€ algvex/core/visibility_checker.py  # å¯è§æ€§æ£€æŸ¥
â””â”€â”€ æµ‹è¯•
    â”œâ”€â”€ tests/test_config_hash.py
    â”œâ”€â”€ tests/test_visibility.py
    â””â”€â”€ tests/test_trace_schema.py

éªŒæ”¶æ ‡å‡†:
âœ… æ‰€æœ‰é…ç½®æ–‡ä»¶æœ‰ config_version + config_hash
âœ… å¯åŠ¨æ—¶è‡ªåŠ¨æ ¡éªŒæ‰€æœ‰é…ç½®hash
âœ… æ¯æ¡ä¿¡å·è®°å½•å®Œæ•´trace (åŒ…å«config_hash, code_hash)
âœ… T1å¯è§æ€§æµ‹è¯•100%é€šè¿‡
â”œâ”€â”€ è¾¹ç•Œéš”ç¦» (P0-1)
â”‚   â”œâ”€â”€ algvex/production/           # ç”Ÿäº§ç›®å½• (MVP-11å› å­)
â”‚   â”œâ”€â”€ algvex/research/             # ç ”ç©¶ç›®å½• (alpha180/201)
â”‚   â””â”€â”€ scripts/ci/check_import_boundary.py
â”œâ”€â”€ æ•°æ®å…¥å£ (P0-2)
â”‚   â”œâ”€â”€ algvex/shared/data_service.py   # æ¥å£å®šä¹‰
â”‚   â””â”€â”€ scripts/ci/check_data_access.py
â””â”€â”€ ç¡®å®šæ€§ (P0-4)
    â”œâ”€â”€ algvex/shared/time_provider.py
    â””â”€â”€ algvex/shared/seeded_random.py

éªŒæ”¶æ ‡å‡†:
âœ… æ‰€æœ‰é…ç½®æ–‡ä»¶æœ‰ config_version + config_hash
âœ… å¯åŠ¨æ—¶è‡ªåŠ¨æ ¡éªŒæ‰€æœ‰é…ç½®hash (canonical hashing)
âœ… production/ å¯¼å…¥è¾¹ç•Œæ£€æŸ¥é€šè¿‡ (CIé—¨ç¦)
âœ… éDataManageræ¨¡å—ç¦æ­¢ç›´æ¥è®¿é—®DB/Redis
âœ… T1å¯è§æ€§æµ‹è¯•100%é€šè¿‡
```

#### 0.12.2 Iteration-2: Daily Replay å¯¹é½ + ç¡®å®šæ€§ (2å‘¨)

```
Iteration-2 äº¤ä»˜ç‰©:
â”œâ”€â”€ è„šæœ¬
â”‚   â”œâ”€â”€ scripts/daily_replay_alignment.py
â”‚   â”œâ”€â”€ scripts/snapshot_manager.py
â”‚   â””â”€â”€ scripts/alignment_reporter.py
â”œâ”€â”€ æ ¸å¿ƒä»£ç 
â”‚   â”œâ”€â”€ algvex/core/snapshot_store.py      # å¿«ç…§å­˜å‚¨
â”‚   â”œâ”€â”€ algvex/core/replay_runner.py       # Replayæ‰§è¡Œå™¨ (ä½¿ç”¨TimeProvider)
â”‚   â””â”€â”€ algvex/core/alignment_checker.py   # å¯¹é½æ£€æŸ¥
â”œâ”€â”€ ç¡®å®šæ€§ä¿éšœ
â”‚   â”œâ”€â”€ ç»Ÿä¸€TimeProvider (ç¦æ­¢datetime.now())
â”‚   â”œâ”€â”€ ç»Ÿä¸€SeededRandom (å›ºå®šéšæœºç§å­)
â”‚   â””â”€â”€ å…³é”®è·¯å¾„Decimal (ä»“ä½/ä»·æ ¼è®¡ç®—)
â”œâ”€â”€ å®šæ—¶ä»»åŠ¡
â”‚   â””â”€â”€ cron/daily_alignment_job.sh
â””â”€â”€ æµ‹è¯•
    â”œâ”€â”€ tests/test_snapshot.py
    â”œâ”€â”€ tests/test_replay.py
    â”œâ”€â”€ tests/test_alignment.py
    â””â”€â”€ tests/test_determinism.py  # ç¡®å®šæ€§éªŒè¯

éªŒæ”¶æ ‡å‡†:
âœ… Liveè¿è¡Œäº§ç”Ÿ live_output_{date}.jsonl
âœ… Replayä½¿ç”¨ç›¸åŒ snapshot_id + data_hash äº§ç”Ÿ replay_output_{date}.jsonl
âœ… è‡ªåŠ¨æ¯”å¯¹æŠ¥å‘Š alignment_report_{date}.json
âœ… ä¿¡å·å·®å¼‚ > 0.1% è‡ªåŠ¨å‘Šè­¦
âœ… è¿ç»­7å¤©Replayå¯¹é½é€šè¿‡ (ä¿¡å·å®Œå…¨ä¸€è‡´)
```

#### 0.12.3 Iteration-3: æ•°æ®å¿«ç…§ + Qlibè¾¹ç•Œ (2å‘¨)

```
Iteration-3 äº¤ä»˜ç‰©:
â”œâ”€â”€ æ•°æ®å¿«ç…§
â”‚   â”œâ”€â”€ algvex/data/snapshot_creator.py    # å¿«ç…§ç”Ÿæˆ
â”‚   â”œâ”€â”€ algvex/data/snapshot_loader.py     # å¿«ç…§åŠ è½½
â”‚   â””â”€â”€ data/snapshots/                    # å¿«ç…§å­˜å‚¨ç›®å½•
â”œâ”€â”€ Qlibè¾¹ç•Œ (ç‰©ç†éš”ç¦»)
â”‚   â”œâ”€â”€ algvex/research/qlib_adapter.py    # Qlibé€‚é…å™¨(ä»…ç ”ç©¶ç”¨)
â”‚   â”œâ”€â”€ algvex/production/factor_engine.py # ç”Ÿäº§å› å­è®¡ç®—(ä¸ä¾èµ–Qlib)
â”‚   â””â”€â”€ algvex/production/model_loader.py  # æ¨¡å‹åŠ è½½(ä»Qlibå¯¼å‡º)
â”œâ”€â”€ æ¨¡å‹å¯¼å‡º
â”‚   â”œâ”€â”€ scripts/export_qlib_model.py       # å¯¼å‡ºQlibæ¨¡å‹æƒé‡
â”‚   â””â”€â”€ models/exported/                   # å¯¼å‡ºçš„æ¨¡å‹æ–‡ä»¶
â””â”€â”€ æµ‹è¯•
    â”œâ”€â”€ tests/test_snapshot_integrity.py
    â”œâ”€â”€ tests/test_production_factors.py
    â””â”€â”€ tests/test_qlib_boundary.py

éªŒæ”¶æ ‡å‡†:
âœ… å¿«ç…§å¯ä»¥è¢«å®Œæ•´å­˜å‚¨å’Œæ¢å¤
âœ… ä½¿ç”¨ç›¸åŒå¿«ç…§çš„å¤šæ¬¡è¿è¡Œäº§ç”Ÿç›¸åŒç»“æœ (hashä¸€è‡´)
âœ… ç”Ÿäº§å› å­è®¡ç®—ä¸ä¾èµ–Qlib (pip uninstall qlibåä»å¯è¿è¡Œ)
âœ… Qlibæ¨¡å‹å¯ä»¥æˆåŠŸå¯¼å‡ºå¹¶è¢«ç”Ÿäº§ä»£ç åŠ è½½
âœ… CIé—¨ç¦: production/ ä¸å…è®¸ import qlib
```

#### 0.12.4 Iteration-4: Hummingbot æ‰§è¡Œå±‚é›†æˆ (2å‘¨)

> **ç›®æ ‡**: å®Œæˆ AlgVex ä¸ Hummingbot çš„æ·±åº¦é›†æˆï¼Œå®ç° Paper Trading éªŒè¯

```
Iteration-4 äº¤ä»˜ç‰©:
â”œâ”€â”€ æ‰§è¡Œå±‚æ ¸å¿ƒ
â”‚   â”œâ”€â”€ algvex/core/execution/hummingbot_bridge.py     # Hummingbot æ¡¥æ¥å±‚
â”‚   â”œâ”€â”€ algvex/core/execution/order_tracker.py         # è®¢å•è¿½è¸ªå™¨
â”‚   â”œâ”€â”€ algvex/core/execution/state_synchronizer.py    # çŠ¶æ€åŒæ­¥å™¨
â”‚   â””â”€â”€ algvex/core/execution/event_handlers.py        # äº‹ä»¶å¤„ç†å™¨
â”œâ”€â”€ Strategy V2 é›†æˆ
â”‚   â”œâ”€â”€ algvex/core/execution/controllers/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ algvex_controller.py                       # AlgVex Controller
â”‚   â””â”€â”€ config/hummingbot_connector.yaml               # è¿æ¥å™¨é…ç½®
â”œâ”€â”€ Paper Trading
â”‚   â”œâ”€â”€ scripts/paper_trading.py                       # Paper Trading å¯åŠ¨è„šæœ¬
â”‚   â””â”€â”€ logs/paper_trading/                            # Paper Trading æ—¥å¿—
â””â”€â”€ æµ‹è¯•
    â”œâ”€â”€ tests/execution/test_hummingbot_bridge.py      # Bridge å•å…ƒæµ‹è¯•
    â”œâ”€â”€ tests/execution/test_order_idempotency.py      # å¹‚ç­‰æ€§æµ‹è¯•
    â”œâ”€â”€ tests/execution/test_state_sync.py             # çŠ¶æ€åŒæ­¥æµ‹è¯•
    â””â”€â”€ tests/execution/test_event_handlers.py         # äº‹ä»¶å¤„ç†æµ‹è¯•

éªŒæ”¶æ ‡å‡†:
âœ… HummingbotBridge ä¿¡å· â†’ è®¢å•è½¬æ¢æ­£ç¡®
âœ… å¹‚ç­‰æ€§: ç›¸åŒä¿¡å·é‡å¤è°ƒç”¨è¿”å›ç›¸åŒ order_id
âœ… InFlightOrder è®¢å•çŠ¶æ€è¿½è¸ªæ­£ç¡®
âœ… çŠ¶æ€åŒæ­¥: ä»“ä½å¯¹è´¦æ— å·®å¼‚
âœ… äº‹ä»¶å¤„ç†: æ‰€æœ‰äº‹ä»¶æ­£ç¡®å†™å…¥ trace
âœ… AlgVexController V2 ç­–ç•¥é›†æˆæ­£å¸¸
âœ… æ–­çº¿æ¢å¤: æ–­çº¿åèƒ½æ­£ç¡®æ¢å¤çŠ¶æ€
âœ… Paper Trading: 24h æ¨¡æ‹Ÿè¿è¡Œæ— å¼‚å¸¸
```

#### 0.12.5 è¿­ä»£éªŒè¯çŸ©é˜µ

| è¿­ä»£ | æ ¸å¿ƒéªŒè¯ | é€šè¿‡æ ‡å‡† |
|------|----------|----------|
| Iter-1 | é…ç½®å¯è¿½æº¯ + è¾¹ç•Œéš”ç¦» | config_hashæ ¡éªŒé€šè¿‡ + å¯¼å…¥è¾¹ç•ŒCIé€šè¿‡ |
| Iter-2 | æ¯æ—¥å¯¹é½ + ç¡®å®šæ€§ | è¿ç»­7å¤©Live-Replayä¿¡å·å·®å¼‚=0 |
| Iter-3 | å¿«ç…§å¯å¤ç° + Qlibéš”ç¦» | åŒå¿«ç…§3æ¬¡è¿è¡Œhashç›¸åŒ + æ— Qlibå¯è¿è¡Œ |
| **Iter-4** | **æ‰§è¡Œå±‚é›†æˆ + Paper Trading** | **24h Paper Tradingæ— å¼‚å¸¸ + çŠ¶æ€åŒæ­¥100%** |

---

### 0.13 ç¡¬çº¦æŸå±‚æ£€æŸ¥æ¸…å•

| å¥‘çº¦ | é…ç½®æ–‡ä»¶ | çŠ¶æ€ | éªŒæ”¶æµ‹è¯• |
|------|----------|------|----------|
| S0: MVP Scope | `mvp_scope.yaml` | âœ… å·²å®šä¹‰ | è¾¹ç•Œæ£€æŸ¥ |
| S1: æ—¶é—´+å¿«ç…§å¥‘çº¦ | `visibility.yaml` | âœ… å·²å®šä¹‰ | T1_VisibilityTests |
| S2: æ•°æ®å¥‘çº¦æ¨¡æ¿ | `data_contracts/*.yaml` | â¬œ Iter-1äº¤ä»˜ | æ•°æ®æºå®¡æŸ¥ |
| S3: é¢„ç®—ä¸é™çº§ç­–ç•¥ | `budget.yaml` | âœ… å·²å®šä¹‰ | å‹åŠ›æµ‹è¯• |
| S4: å› å­æ²»ç† | `factor_governance.yaml` | âœ… å·²å®šä¹‰ | T5_FactorTests |
| S5: å¯¹é½ä¸å½’å›  | `alignment.yaml` | â¬œ Iter-2äº¤ä»˜ | T3_AlignmentTests |
| S6: éªŒæ”¶æµ‹è¯• | - | âœ… å·²å®šä¹‰ | CI/CDé›†æˆ |
| **S7: ç‰©ç†è¾¹ç•Œéš”ç¦»** | - | â¬œ Iter-1äº¤ä»˜ | å¯¼å…¥æ‰«æé—¨ç¦ |
| **S8: DataManagerå”¯ä¸€å…¥å£** | - | â¬œ Iter-1äº¤ä»˜ | æ•°æ®è®¿é—®æ‰«æ |
| **S9: Canonical Hashing** | `hashing_spec.yaml` | â¬œ Iter-1äº¤ä»˜ | HashéªŒè¯æµ‹è¯• |
| **S10: Replayç¡®å®šæ€§** | - | â¬œ Iter-2äº¤ä»˜ | ç¡®å®šæ€§æµ‹è¯• |

#### 0.13.1 é…ç½®æ–‡ä»¶ç»“æ„

```
config/
â”œâ”€â”€ visibility.yaml              # S1: å¯è§æ€§è§„åˆ™
â”œâ”€â”€ alignment.yaml               # S5: å¯¹é½é…ç½®
â”œâ”€â”€ factor_governance.yaml       # S4: å› å­æ²»ç†
â”œâ”€â”€ budget.yaml                  # S3: é¢„ç®—é…ç½®
â”œâ”€â”€ hashing_spec.yaml            # S9: Canonical Hashingè§„èŒƒ
â”œâ”€â”€ mvp_scope.yaml               # S0: MVPèŒƒå›´é…ç½® (P0-5)
â””â”€â”€ data_contracts/
    â”œâ”€â”€ klines_5m.yaml           # S2: Kçº¿æ•°æ®å¥‘çº¦
    â”œâ”€â”€ open_interest_5m.yaml    # S2: æŒä»“é‡æ•°æ®å¥‘çº¦
    â””â”€â”€ funding_8h.yaml          # S2: èµ„é‡‘è´¹ç‡æ•°æ®å¥‘çº¦
```

#### 0.13.2 MVP Scope é…ç½®å¼€å…³ (P0-5)

```yaml
# config/mvp_scope.yaml
# MVPèŒƒå›´é…ç½® - ç”Ÿäº§ç¯å¢ƒå¿…é¡»éµå®ˆ
config_version: "1.0.0"
config_hash: "sha256:..."

mvp_constraints:
  # æ—¶é—´æ¡†æ¶é™åˆ¶
  allowed_frequencies:
    - "5m"  # MVPä»…å…è®¸5åˆ†é’Ÿ
  forbidden_frequencies:
    - "1m"
    - "15m"
    - "1h"

  # æ ‡çš„é™åˆ¶
  universe:
    max_symbols: 50
    default_symbols: ["BTCUSDT", "ETHUSDT"]
    # åŠ¨æ€æ‰©å±•éœ€è¦å®¡æ‰¹

  # å› å­é™åˆ¶
  factor_set: "mvp11"  # ä»…MVP-11å› å­
  forbidden_factors:
    - "alpha180/*"  # ç¦æ­¢ä½¿ç”¨ç ”ç©¶å› å­
    - "alpha201/*"

  # æ•°æ®æºé™åˆ¶
  allowed_data_sources:
    - "klines_5m"
    - "open_interest_5m"
    - "funding_8h"
  forbidden_data_sources:
    - "depth_l2"      # B/Cæ¡£æ•°æ®
    - "liquidations"
    - "options_*"

  # è¿è¡Œæ—¶å¼ºåˆ¶æ£€æŸ¥
  enforcement:
    on_violation: "reject"  # reject / warn / log
    check_at_startup: true
    check_on_signal: true
```

#### 0.13.3 MvpScopeEnforcer å®ç°

> å¿…é¡»åœ¨å¯åŠ¨å’Œæ¯æ¬¡ä¿¡å·å…¥å£å¤„å¼ºåˆ¶æ£€æŸ¥MVPè¾¹ç•Œ

```python
# algvex/core/mvp_scope_enforcer.py
"""
MVP Scope å¼ºåˆ¶æ£€æŸ¥å™¨

å…³é”®æ£€æŸ¥ç‚¹:
1. åº”ç”¨å¯åŠ¨æ—¶ (check_at_startup)
2. æ¯æ¬¡ä¿¡å·ç”Ÿæˆå‰ (check_on_signal)
3. æ¯æ¬¡å› å­è®¡ç®—å‰ (check_factor)
4. æ¯æ¬¡æ•°æ®è¯·æ±‚å‰ (check_data_source)
"""
import yaml
from pathlib import Path
from dataclasses import dataclass
from typing import List, Set, Optional
from enum import Enum
import fnmatch

class ViolationAction(Enum):
    REJECT = "reject"    # æ‹’ç»å¹¶æŠ›å¼‚å¸¸
    WARN = "warn"        # è­¦å‘Šä½†ç»§ç»­
    LOG = "log"          # ä»…è®°å½•

@dataclass
class MvpViolation:
    """MVPèŒƒå›´è¿è§„"""
    category: str       # frequency / symbol / factor / data_source
    value: str          # è¿è§„çš„å€¼
    message: str        # è¯¦ç»†ä¿¡æ¯

class MvpScopeEnforcer:
    """
    MVPèŒƒå›´å¼ºåˆ¶æ£€æŸ¥å™¨

    ç”¨æ³•:
    1. åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–
    2. åœ¨ SignalGenerator.__init__ ä¸­è°ƒç”¨ check_startup()
    3. åœ¨ SignalGenerator.generate() å…¥å£è°ƒç”¨ check_signal()
    """

    def __init__(self, config_path: str = "config/mvp_scope.yaml"):
        self.config = self._load_config(config_path)
        self.violations: List[MvpViolation] = []

        # é¢„è§£æé…ç½®
        constraints = self.config.get("mvp_constraints", {})
        self.allowed_frequencies: Set[str] = set(
            constraints.get("allowed_frequencies", ["5m"])
        )

        # Universe é…ç½®
        universe = constraints.get("universe", {})
        self.max_symbols: int = universe.get("max_symbols", 50)
        self.allowed_symbols: Set[str] = set(universe.get("allowed_symbols", []))

        # å› å­é…ç½® - ä½¿ç”¨ç™½åå•è€Œéä»…é»‘åå•
        self.allowed_factors: Set[str] = set(
            constraints.get("allowed_factors", [])  # MVP-11 å› å­ç™½åå•
        )
        self.forbidden_factors: List[str] = constraints.get("forbidden_factors", [])

        # æ•°æ®æºé…ç½® - ç™½åå•æ˜¯æƒå¨
        self.allowed_data_sources: Set[str] = set(
            constraints.get("allowed_data_sources", [])
        )
        self.forbidden_data_sources: List[str] = constraints.get("forbidden_data_sources", [])

        enforcement = constraints.get("enforcement", {})
        self.on_violation = ViolationAction(enforcement.get("on_violation", "reject"))
        self.check_at_startup = enforcement.get("check_at_startup", True)
        self.check_on_signal = enforcement.get("check_on_signal", True)

    def _load_config(self, path: str) -> dict:
        config_file = Path(path)
        if not config_file.exists():
            raise FileNotFoundError(f"MVP Scopeé…ç½®ä¸å­˜åœ¨: {path}")
        with open(config_file) as f:
            return yaml.safe_load(f)

    def check_startup(self, active_symbols: List[str], active_factors: List[str]):
        """
        å¯åŠ¨æ—¶æ£€æŸ¥

        å¿…é¡»åœ¨ SignalGenerator.__init__ æˆ– main() ä¸­è°ƒç”¨
        """
        self.violations.clear()

        # æ£€æŸ¥æ ‡çš„æ•°é‡
        if len(active_symbols) > self.max_symbols:
            self.violations.append(MvpViolation(
                category="symbol",
                value=str(len(active_symbols)),
                message=f"æ ‡çš„æ•°é‡ {len(active_symbols)} è¶…è¿‡MVPé™åˆ¶ {self.max_symbols}"
            ))

        # æ£€æŸ¥æ ‡çš„æ˜¯å¦åœ¨ç™½åå• (å¦‚æœé…ç½®äº†ç™½åå•)
        if self.allowed_symbols:
            for symbol in active_symbols:
                if symbol not in self.allowed_symbols:
                    self.violations.append(MvpViolation(
                        category="symbol",
                        value=symbol,
                        message=f"æ ‡çš„ {symbol} ä¸åœ¨MVPå…è®¸åˆ—è¡¨ä¸­"
                    ))

        # æ£€æŸ¥å› å­ - ç™½åå•ä¼˜å…ˆï¼Œä¸åœ¨ç™½åå•çš„ä¸€å¾‹æ‹’ç»
        if self.allowed_factors:
            for factor in active_factors:
                if factor not in self.allowed_factors:
                    self.violations.append(MvpViolation(
                        category="factor",
                        value=factor,
                        message=f"å› å­ {factor} ä¸åœ¨MVP-11å…è®¸åˆ—è¡¨ä¸­"
                    ))
        else:
            # æ²¡æœ‰ç™½åå•æ—¶ï¼Œä½¿ç”¨é»‘åå• (å‘åå…¼å®¹)
            for factor in active_factors:
                if self._matches_forbidden(factor, self.forbidden_factors):
                    self.violations.append(MvpViolation(
                        category="factor",
                        value=factor,
                        message=f"å› å­ {factor} åœ¨MVPç¦æ­¢åˆ—è¡¨ä¸­"
                    ))

        return self._handle_violations("startup")

    def check_signal(self, frequency: str, symbol: str, factors_used: List[str]):
        """
        æ¯æ¬¡ä¿¡å·ç”Ÿæˆå‰æ£€æŸ¥

        å¿…é¡»åœ¨ SignalGenerator.generate() å…¥å£è°ƒç”¨
        """
        self.violations.clear()

        # æ£€æŸ¥æ—¶é—´æ¡†æ¶
        if frequency not in self.allowed_frequencies:
            self.violations.append(MvpViolation(
                category="frequency",
                value=frequency,
                message=f"æ—¶é—´æ¡†æ¶ {frequency} ä¸åœ¨MVPå…è®¸åˆ—è¡¨ {self.allowed_frequencies}"
            ))

        # æ£€æŸ¥æ ‡çš„ (å¦‚æœé…ç½®äº†ç™½åå•)
        if self.allowed_symbols and symbol not in self.allowed_symbols:
            self.violations.append(MvpViolation(
                category="symbol",
                value=symbol,
                message=f"æ ‡çš„ {symbol} ä¸åœ¨MVPå…è®¸åˆ—è¡¨ä¸­"
            ))

        # æ£€æŸ¥å› å­ - ç™½åå•ä¼˜å…ˆ
        if self.allowed_factors:
            for factor in factors_used:
                if factor not in self.allowed_factors:
                    self.violations.append(MvpViolation(
                        category="factor",
                        value=factor,
                        message=f"ä¿¡å·ä½¿ç”¨äº†éMVPå› å­ {factor}"
                    ))
        else:
            for factor in factors_used:
                if self._matches_forbidden(factor, self.forbidden_factors):
                    self.violations.append(MvpViolation(
                        category="factor",
                        value=factor,
                        message=f"ä¿¡å·ä½¿ç”¨äº†ç¦æ­¢å› å­ {factor}"
                    ))

        return self._handle_violations(f"signal:{symbol}")

    def check_data_source(self, data_source: str):
        """
        æ•°æ®è¯·æ±‚å‰æ£€æŸ¥

        å¿…é¡»åœ¨ DataManager.get_* æ–¹æ³•å…¥å£è°ƒç”¨

        å…³é”®é€»è¾‘: åªè¦ä¸åœ¨ allowed_data_sources å°±æ‹’ç»!
        forbidden_data_sources ä»…ç”¨äºæä¾›æ›´æ¸…æ™°çš„é”™è¯¯ä¿¡æ¯
        """
        if data_source not in self.allowed_data_sources:
            # ä¸åœ¨ç™½åå• = ä¸€å¾‹æ‹’ç» (è¿™æ˜¯MVPè¾¹ç•Œçš„æ ¸å¿ƒ!)
            if self._matches_forbidden(data_source, self.forbidden_data_sources):
                message = f"æ•°æ®æº {data_source} åœ¨MVPç¦æ­¢åˆ—è¡¨ä¸­"
            else:
                message = f"æ•°æ®æº {data_source} ä¸åœ¨MVPå…è®¸åˆ—è¡¨ä¸­ (éœ€å®¡æ‰¹ååŠ å…¥)"

            violation = MvpViolation(
                category="data_source",
                value=data_source,
                message=message
            )
            self.violations = [violation]
            return self._handle_violations(f"data:{data_source}")

        return True

    def _matches_forbidden(self, value: str, patterns: List[str]) -> bool:
        """æ£€æŸ¥æ˜¯å¦åŒ¹é…ç¦æ­¢æ¨¡å¼ (æ”¯æŒé€šé…ç¬¦)"""
        for pattern in patterns:
            if fnmatch.fnmatch(value, pattern):
                return True
        return False

    def _handle_violations(self, context: str) -> bool:
        """å¤„ç†è¿è§„"""
        if not self.violations:
            return True

        for v in self.violations:
            msg = f"[MVPè¿è§„] {context} - {v.category}: {v.message}"

            if self.on_violation == ViolationAction.REJECT:
                raise MvpScopeViolationError(msg)
            elif self.on_violation == ViolationAction.WARN:
                import warnings
                warnings.warn(msg, UserWarning)
            else:  # LOG
                import logging
                logging.warning(msg)

        return self.on_violation != ViolationAction.REJECT


class MvpScopeViolationError(Exception):
    """MVPèŒƒå›´è¿è§„å¼‚å¸¸ - ç”Ÿäº§ç¯å¢ƒå¿…é¡»æ‹’ç»"""
    pass


# ============== é›†æˆç¤ºä¾‹ ==============

class SignalGenerator:
    """ä¿¡å·ç”Ÿæˆå™¨ - å±•ç¤ºMvpScopeEnforcerçš„é›†æˆæ–¹å¼"""

    def __init__(self, symbols: List[str], factors: List[str]):
        # å¯åŠ¨æ—¶å¼ºåˆ¶æ£€æŸ¥
        self.enforcer = MvpScopeEnforcer()
        if self.enforcer.check_at_startup:
            self.enforcer.check_startup(symbols, factors)

        self.symbols = symbols
        self.factors = factors

    def generate(self, symbol: str, frequency: str = "5m") -> dict:
        # æ¯æ¬¡ä¿¡å·ç”Ÿæˆå‰å¼ºåˆ¶æ£€æŸ¥
        if self.enforcer.check_on_signal:
            self.enforcer.check_signal(frequency, symbol, self.factors)

        # ... å®é™…ä¿¡å·ç”Ÿæˆé€»è¾‘ ...
        return {"symbol": symbol, "signal": 0.5}
```

**CIé—¨ç¦æµ‹è¯•**

```python
# tests/p0/test_mvp_scope_enforcer.py
import pytest
from algvex.core.mvp_scope_enforcer import (
    MvpScopeEnforcer, MvpScopeViolationError
)

class TestMvpScopeEnforcer:
    """P0æµ‹è¯•: MVPèŒƒå›´å¼ºåˆ¶æ£€æŸ¥"""

    def test_reject_forbidden_frequency(self):
        """æµ‹è¯•ç¦æ­¢çš„æ—¶é—´æ¡†æ¶è¢«æ‹’ç»"""
        enforcer = MvpScopeEnforcer()
        with pytest.raises(MvpScopeViolationError):
            enforcer.check_signal(
                frequency="15m",  # ç¦æ­¢
                symbol="BTCUSDT",
                factors_used=["return_5m"]
            )

    def test_reject_non_allowed_data_source(self):
        """æ ¸å¿ƒæµ‹è¯•: ä¸åœ¨allowedåˆ—è¡¨çš„æ•°æ®æºå¿…é¡»æ‹’ç» (å³ä½¿ä¸åœ¨forbidden)"""
        enforcer = MvpScopeEnforcer()
        with pytest.raises(MvpScopeViolationError):
            # "new_source" æ—¢ä¸åœ¨ allowed ä¹Ÿä¸åœ¨ forbiddenï¼Œä½†å¿…é¡»æ‹’ç»!
            enforcer.check_data_source("new_source_xyz")

    def test_reject_forbidden_data_source(self):
        """æµ‹è¯•æ˜ç¡®ç¦æ­¢çš„æ•°æ®æºè¢«æ‹’ç»"""
        enforcer = MvpScopeEnforcer()
        with pytest.raises(MvpScopeViolationError):
            enforcer.check_data_source("depth_l2")  # åœ¨ç¦æ­¢åˆ—è¡¨

    def test_reject_non_allowed_factor(self):
        """æ ¸å¿ƒæµ‹è¯•: ä¸åœ¨MVP-11ç™½åå•çš„å› å­å¿…é¡»æ‹’ç»"""
        enforcer = MvpScopeEnforcer()
        with pytest.raises(MvpScopeViolationError):
            enforcer.check_startup(
                active_symbols=["BTCUSDT"],
                active_factors=["some_new_factor"]  # ä¸åœ¨ MVP-11 ç™½åå•
            )

    def test_reject_non_allowed_symbol(self):
        """æ ¸å¿ƒæµ‹è¯•: ä¸åœ¨universeç™½åå•çš„æ ‡çš„å¿…é¡»æ‹’ç»"""
        enforcer = MvpScopeEnforcer()
        with pytest.raises(MvpScopeViolationError):
            enforcer.check_signal(
                frequency="5m",
                symbol="UNKNOWN_COIN",  # ä¸åœ¨ allowed_symbols
                factors_used=["return_5m"]
            )

    def test_allow_mvp_config(self):
        """æµ‹è¯•MVPé…ç½®é€šè¿‡"""
        enforcer = MvpScopeEnforcer()
        assert enforcer.check_signal(
            frequency="5m",
            symbol="BTCUSDT",
            factors_used=["return_5m", "oi_change_rate"]
        )
```

---

# Part B: å®ç°å±‚ (å¯æ¸è¿›æ›¿æ¢)

> ä»¥ä¸‹ç« èŠ‚ä¸ºå®ç°å±‚ï¼Œå¯ä»¥æ ¹æ®éœ€è¦æ¸è¿›æ›¿æ¢ï¼Œä½†å¿…é¡»éµå®ˆ Part A å®šä¹‰çš„ç¡¬çº¦æŸã€‚

---


### 0.14 é€»è¾‘ä¸€è‡´æ€§å®¡æŸ¥ï¼ˆv3.9.7 å¢è¡¥ï¼‰

> ç›®çš„ï¼šæŠŠâ€œå¤æ‚â€æ‹†æˆå¯éªŒè¯çš„çº¦æŸä¸ä»£ä»·ï¼Œé¿å…ä¸ºäº†å¤æ‚è€Œå¤æ‚ï¼›åŒæ—¶æŠŠæ½œåœ¨çš„é€»è¾‘æ¼æ´æå‰æš´éœ²å‡ºæ¥ï¼Œé˜²æ­¢å®ç›˜é˜¶æ®µæ‰è¸©å‘ã€‚

#### 0.14.1 å®¡æŸ¥ç»´åº¦ï¼ˆä½ æå‡ºçš„ 7 é¡¹ï¼‰

| ç»´åº¦ | ç»“è®º | ä¸»è¦é£é™©ç‚¹ï¼ˆå¦‚æœä¸è¡¥ï¼‰ | æœ¬æ–¹æ¡ˆå¯¹åº”æœºåˆ¶ | éœ€è¦è¡¥çš„è¯æ®/åŠ¨ä½œï¼ˆæœ€å°é›†ï¼‰ |
|---|---|---|---|---|
| ä¸€è‡´æ€§ï¼ˆå®šä¹‰/å£å¾„/å‘½åï¼‰ | **åŸºæœ¬æ»¡è¶³** | å› å­/ç‰¹å¾/æ ‡ç­¾å£å¾„æ¼‚ç§»å¯¼è‡´â€œåŒåä¸åŒä¹‰â€ä¸å›æµ‹-å®ç›˜å‰²è£‚ | S2 æ•°æ®å¥‘çº¦ + S4 å› å­æ²»ç† + S9 Hashè§„èŒƒ | å»ºç«‹ **Metric/Factor Dictionary**ï¼ˆç‰ˆæœ¬åŒ–ï¼‰ï¼›CI æ ¡éªŒåŒåå­—æ®µ/åŒåå› å­ hash ä¸å˜ï¼ˆæˆ–æ˜¾å¼ bump ç‰ˆæœ¬ï¼‰ |
| æ—¶é—´ç‚¹æ•°æ®ï¼ˆasof/æ°´ä½çº¿/å¿«ç…§ï¼‰ | **æ»¡è¶³ï¼ˆè®¾è®¡å·²ç»™ï¼‰** | å¤–éƒ¨æ•°æ®å»¶è¿Ÿ/ç¼ºå¤±æ—¶äº§ç”Ÿâ€œæœªæ¥å‡½æ•°â€æˆ–éšå½¢æ¼æ•° | S1 æ—¶é—´+å¿«ç…§å¥‘çº¦ï¼ˆwatermark/asofï¼‰+ S3 é™çº§ | å¢åŠ  2 ç±»éªŒæ”¶ï¼šâ‘  å›æµ‹/å®ç›˜åŒä¸€æ—¥ replay ç»“æœä¸€è‡´ï¼›â‘¡ æ•…æ„åˆ¶é€ å»¶è¿Ÿ/ç¼ºå¤±æ—¶è§¦å‘é™çº§å¹¶å¯è§‚æµ‹ |
| æ•°æ®æµé—­ç¯ï¼ˆè¾“å…¥â†’å†³ç­–â†’æ‰§è¡Œâ†’å›å†™â†’å½’å› ï¼‰ | **æ»¡è¶³ï¼ˆéœ€è¦æŠŠå›å†™åšæˆç¡¬é—¨æ§›ï¼‰** | åªåšâ€œä¸‹å•â€ï¼Œä¸åšâ€œå›å†™+å½’å› â€ï¼Œæœ€ç»ˆæ— æ³•å®šä½ç­–ç•¥é—®é¢˜ | S5 å¯¹é½ä¸å½’å›  + Daily Replay | æŠŠ **Fill/Order å›å†™** å†™å…¥ DoDï¼šæ— å›å†™åˆ™ç­–ç•¥ä¸å¯ä¸Šçº¿ï¼›å¢åŠ  trace_id è´¯ç©¿ï¼ˆsignal_idâ†’order_idâ†’fill_idï¼‰ |
| å¹‚ç­‰/çŠ¶æ€æœºï¼ˆé‡è¯•/é‡æ”¾/æ–­ç‚¹ç»­è·‘ï¼‰ | **éƒ¨åˆ†æ»¡è¶³ï¼ˆéœ€è¦è¡¥è¯æ®ï¼‰** | æ–­çº¿é‡è¿/é‡å¤äº‹ä»¶å¯¼è‡´é‡å¤ä¸‹å•ã€é‡å¤è®°è´¦ã€é‡å¤ä¿¡å· | S8 å”¯ä¸€å…¥å£ + S9 Canonical Hash + S10 Replayç¡®å®šæ€§ | æ˜ç¡® **Order å¹‚ç­‰é”®**ï¼ˆclient_order_idï¼ŒHummingbotå†…ç½®æ”¯æŒï¼‰ï¼›Fills é€šè¿‡ trade_id å»é‡ï¼›è¡¥"é‡æ”¾/é‡å¤äº‹ä»¶"æµ‹è¯•ä¸æ¼”ç»ƒè„šæœ¬ |
| é™çº§é“¾è·¯ï¼ˆä»æ­£å¸¸åˆ°å…œåº•çš„å¯æ§é€€åŒ–ï¼‰ | **æ»¡è¶³ï¼ˆè®¾è®¡å·²ç»™ï¼Œä½†è¦é˜²â€œé™é»˜é™çº§â€ï¼‰** | æ— å£°é™çº§å¯¼è‡´æ€§èƒ½/èƒœç‡å˜åŒ–ä½†ä¸å¯è§ï¼Œè¯¯åˆ¤ç­–ç•¥æœ‰æ•ˆæ€§ | S3 é¢„ç®—ä¸é™çº§ç­–ç•¥ + S6 éªŒæ”¶ | å¢åŠ  **é™çº§äº‹ä»¶æ—¥å¿—+æŒ‡æ ‡**ï¼ˆdegrade_levelã€åŸå› ã€æŒç»­æ—¶é•¿ï¼‰ï¼›åœ¨å›æµ‹è¾“å‡ºä¸­æ ‡æ³¨é™çº§å æ¯” |
| æ¥å£ç­¾å/è´£ä»»è¾¹ç•Œï¼ˆQlib vs æ‰§è¡Œå¼•æ“ï¼‰ | **åŸºæœ¬æ»¡è¶³** | ç ”ç©¶/å›æµ‹/å®ç›˜æ¥å£åˆ†å‰ï¼ŒåæœŸç»´æŠ¤æˆæœ¬çˆ†ç‚¸ | æ˜ç¡® DataManager / Collector æ¥å£ï¼Œç­–ç•¥ä¾§åªæ¶ˆè´¹â€œç»Ÿä¸€æ•°æ®å±‚â€ | åœ¨ä»“åº“å±‚é¢åŠ  **import boundary**ï¼ˆç¦æ­¢ä»æ‰§è¡Œå±‚åå‘ import ç ”ç©¶å±‚ï¼‰ï¼›ç”¨ mypy/ruff è§„åˆ™åšé—¨ç¦ï¼ˆå¯å…ˆè½»é‡ï¼‰ |
| å¾ªç¯ä¾èµ–/å£å¾„æ¼‚ç§»é£é™© | **éœ€è¦è¡¥è¯æ®** | éšè¿­ä»£å‡ºç°â€œè·¨å±‚å¼•ç”¨â€â€œå­—æ®µå«ä¹‰æ‚„æ‚„æ”¹å˜â€ï¼Œå¯¼è‡´é•¿æœŸä¸å¯ç»´æŠ¤ | åˆ†å±‚åŸåˆ™ï¼ˆP ç³»åˆ—ï¼‰+ S4 å› å­æ²»ç† | ç”Ÿæˆæ¨¡å—ä¾èµ–å›¾ï¼ˆCI æ¯æ¬¡ PR äº§å‡ºï¼‰ï¼›æ–°å¢â€œå­—æ®µ/å› å­ç‰ˆæœ¬å˜æ›´â€å¿…é¡»æ›´æ–° CHANGELOG ä¸éªŒæ”¶è®°å½• |

#### 0.14.2 æœ¬æ¬¡å®¡æŸ¥ç»“è®ºï¼šå“ªé‡Œå¤æ‚æ˜¯â€œå¿…è¦çš„â€ï¼Œå“ªé‡Œå¤æ‚å¿…é¡»è¡¥è¯æ®

- **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰**ï¼šS1/S2/S3/S4/S5/S6 + S8/S9/S10ï¼ˆå®ƒä»¬æ˜¯â€œé˜²æœªæ¥å‡½æ•°ã€å£å¾„æ¼‚ç§»ã€å®ç›˜ä¸å¯è¿½è´£â€çš„æœ€ä½é—¨æ§›ï¼‰ã€‚
- **éœ€è¦è¡¥è¯æ®æ‰èƒ½æˆç«‹çš„å¤æ‚åº¦ï¼ˆå…ˆä¸åˆ ï¼Œä½†å¿…é¡»è¯æ®åŒ–/å¼€å…³åŒ–ï¼‰**ï¼š  
  1) å­˜å‚¨ä¸ç»„ä»¶é€‰å‹çš„â€œé«˜é…ç‰ˆâ€ï¼ˆä¾‹å¦‚ Timescale/å¤šç¼“å­˜å±‚/å¤šé˜Ÿåˆ—ç­‰ï¼‰â€”â€”éœ€è¦å‹æµ‹/æˆæœ¬æ”¶ç›Šè¯æ˜ï¼›  
  2) è¿‡åº¦æå‰çš„â€œå¤šäº¤æ˜“æ‰€/å¤šç»çºªå•†/å¤šè´¦æˆ·ç¼–æ’â€â€”â€”éœ€è¦æ˜ç¡®ä¸šåŠ¡é‡Œç¨‹ç¢‘ä¸çœŸå®éœ€æ±‚ï¼›  
  3) è¿‡åº¦ç»†ç²’åº¦çš„å¾®ç»“æ„ç‰¹å¾åœ¨ **ä¸ S1 å¿«ç…§å¥‘çº¦** å†²çªæ—¶â€”â€”éœ€è¦å®šä¹‰åœ¨ä»€ä¹ˆé¢‘ç‡ä¸‹ä»å¯ä¿æŒâ€œæ—¶é—´ç‚¹ä¸€è‡´æ€§â€ã€‚

---

### 0.15 å¤æ‚åº¦è¯æ®åŒ–ï¼ˆæŠŠå¤æ‚å†™æˆâ€œå¯éªŒè¯çš„ä»£ä»·ä¸æ”¶ç›Šâ€ï¼‰

> è§„åˆ™ï¼šæ¯ä¸ªæ¨¡å—å¿…é¡»å†™æ¸…æ¥š **é£é™© â†’ æœºåˆ¶ â†’ éªŒæ”¶ â†’ ä¸åšä»£ä»· â†’ ä¾èµ– â†’ è¿è¡Œæˆæœ¬**ï¼Œå¹¶æ ‡æ³¨â€œå¿…è¦å¤æ‚åº¦ / è¯æ®ä¸è¶³å¤æ‚åº¦â€ã€‚

ä¸‹é¢ç»™å‡º **æ¨¡å—è¯æ®å¡ï¼ˆv3.9.7 å¢è¡¥ï¼‰**ã€‚ä½ åç»­æ¯æ¬¡æ–°å¢æ¨¡å—ï¼Œéƒ½æŒ‰åŒä¸€æ¨¡æ¿è¡¥é½ï¼›å¦åˆ™é»˜è®¤è§†ä¸ºâ€œä¸ºäº†å¤æ‚è€Œå¤æ‚â€ã€‚

#### 0.15.1 S1 æ—¶é—´+å¿«ç…§å¥‘çº¦ï¼ˆTime & Snapshot Contractï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | æœªæ¥å‡½æ•°ã€è·¨æºå»¶è¿Ÿé€ æˆä¿¡å·ä¸å¯å¤ç°ï¼›å›æµ‹/å®ç›˜ä¸€è‡´æ€§ç ´äº§ |
| æœºåˆ¶ | watermark/asofã€å¿«ç…§ç‰ˆæœ¬ã€ç¼ºå¤±å­—æ®µæ˜¾å¼æ ‡æ³¨ï¼›è§¦å‘ S3 é™çº§ |
| éªŒæ”¶ | â‘  åŒä¸€äº¤æ˜“æ—¥ replay ä¸€è‡´ï¼›â‘¡ æ³¨å…¥å»¶è¿Ÿ/ç¼ºå¤±è§¦å‘é™çº§ä¸”å¯è§‚æµ‹ï¼›â‘¢ ä¸åŒé‡‡æ ·é¢‘ç‡ä¸‹ä¸è¶Šè¿‡ asof |
| ä¸åšä»£ä»· | ä»»ä½•å›æµ‹æ”¶ç›Šéƒ½æ— æ³•è¯æ˜ï¼›ä¸Šçº¿åäºæŸæ— æ³•å®šä½è´£ä»»é“¾ |
| ä¾èµ– | DataManagerï¼ˆS8ï¼‰ï¼Œç»Ÿä¸€æ—¶é—´æºï¼Œå¤–éƒ¨æ•°æ®é‡‡é›†å™¨ |
| è¿è¡Œæˆæœ¬ | å¢åŠ ç¼“å­˜/å­˜å‚¨ä¸æ ¡éªŒå¼€é”€ï¼›ä½†è¿œå°äºæ’æŸ¥â€œæœªæ¥å‡½æ•°â€çš„äººåŠ›æˆæœ¬ |

#### 0.15.2 S2 æ•°æ®å¥‘çº¦æ¨¡æ¿ï¼ˆData Contract Templateï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | å­—æ®µæ¼‚ç§»ã€åŒåä¸åŒä¹‰ã€ç¼ºå¤±å­—æ®µé™é»˜åæ‰å¯¼è‡´ç­–ç•¥è¡Œä¸ºçªå˜ |
| æœºåˆ¶ | schema_version + required/optional + nullability + units + timezoneï¼›å…¥åº“/å‡ºåº“æ ¡éªŒ |
| éªŒæ”¶ | åˆåŒæµ‹è¯•ï¼šå­—æ®µæ–°å¢/åˆ é™¤/å•ä½å˜åŒ–å¿…é¡»æ˜¾å¼ç‰ˆæœ¬å˜æ›´ï¼›æ—§ç‰ˆæœ¬æ•°æ®ä»å¯è¢«è¯»å–ï¼ˆæˆ–æ˜ç¡®è¿ç§»ï¼‰ |
| ä¸åšä»£ä»· | è§„æ¨¡åŒ–åâ€œåªè¦ä¸€æ”¹å­—æ®µå°±å…¨ç³»ç»Ÿç‚¸â€ï¼›å›æµ‹ä¸å®ç›˜å£å¾„é•¿æœŸæ¼‚ç§» |
| ä¾èµ– | å› å­æ²»ç†ï¼ˆS4ï¼‰ã€å“ˆå¸Œè§„èŒƒï¼ˆS9ï¼‰ã€éªŒæ”¶æµ‹è¯•ï¼ˆS6ï¼‰ |
| è¿è¡Œæˆæœ¬ | å¤šä¸€æ¬¡æ ¡éªŒä¸å…ƒæ•°æ®ç»´æŠ¤ï¼›ä½†æ¢æ¥å¯æ§è¿­ä»£ä¸å¯è¿½è´£å˜æ›´ |

#### 0.15.3 S3 é¢„ç®—ä¸é™çº§ç­–ç•¥ï¼ˆBudget & Degrade Policyï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | æ•°æ®ç¼ºå¤±/å»¶è¿Ÿæ—¶ç³»ç»Ÿâ€œå‡æ­£å¸¸â€ï¼›æˆ–è€…ç›´æ¥åœæ‘†ï¼Œé”™è¿‡é£é™©æ§åˆ¶çª—å£ |
| æœºåˆ¶ | degrade_levelï¼ˆ0/1/2â€¦ï¼‰+ æ˜ç¡® fallbackï¼šåœä¿¡å·/åªåšé£æ§/åªåšå‡ä»“ï¼›æ‰€æœ‰é™çº§å¯è§‚æµ‹ |
| éªŒæ”¶ | å¼ºåˆ¶æ³¨å…¥å¼‚å¸¸ï¼šç½‘ç»œæŠ–åŠ¨ã€äº¤æ˜“æ‰€é™æµã€å¤–éƒ¨æ•°æ®ç¼ºå¤±ï¼›éªŒè¯é™çº§è·¯å¾„ä¸æ¢å¤è·¯å¾„ |
| ä¸åšä»£ä»· | å®ç›˜æœ€å¸¸è§çš„ä¸æ˜¯ç­–ç•¥é—®é¢˜ï¼Œè€Œæ˜¯â€œæ•°æ®/æ‰§è¡Œä¸ç¨³å®šâ€å¼•å‘çš„éçº¿æ€§æŸå¤± |
| ä¾èµ– | S1 æ—¶é—´å¿«ç…§ã€S6 éªŒæ”¶ã€ç›‘æ§å‘Šè­¦ |
| è¿è¡Œæˆæœ¬ | éœ€è¦æ›´å¤šçŠ¶æ€ä¸æŒ‡æ ‡ï¼Œä½†èƒ½æ˜¾è‘—é™ä½äº‹æ•…æ¦‚ç‡ä¸æ’æŸ¥æ—¶é—´ |

#### 0.15.4 S4 å› å­æ²»ç†ï¼ˆFactor Governanceï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | å› å­å®ç°/å‚æ•°/å½’ä¸€åŒ–æ–¹å¼æ‚„æ‚„å˜åŒ–ï¼Œå¯¼è‡´æ¨¡å‹æ¼‚ç§»ä¸ä¸å¯å¤ç° |
| æœºåˆ¶ | å› å­æ³¨å†Œè¡¨ï¼ˆname+version+hash+depsï¼‰ã€å˜æ›´å®¡è®¡ã€å†»ç»“çª—å£ |
| éªŒæ”¶ | â‘  å› å­ hash ç¨³å®šï¼›â‘¡ å˜æ›´å¿…é¡» bump ç‰ˆæœ¬å¹¶æ›´æ–°å½±å“é¢ï¼›â‘¢ å›æµ‹/å®ç›˜åŒä¸€ç‰ˆæœ¬å› å­è¾“å‡ºä¸€è‡´ |
| ä¸åšä»£ä»· | æ¨¡å‹è®­ç»ƒä¸çº¿ä¸Šä¿¡å·æ— æ³•å¯¹é½ï¼Œæœ€ç»ˆé€€åŒ–æˆâ€œç„å­¦è°ƒå‚â€ |
| ä¾èµ– | æ•°æ®å¥‘çº¦ï¼ˆS2ï¼‰ã€å“ˆå¸Œè§„èŒƒï¼ˆS9ï¼‰ã€replayï¼ˆS10ï¼‰ |
| è¿è¡Œæˆæœ¬ | ç»´æŠ¤æ³¨å†Œè¡¨ä¸ç‰ˆæœ¬ï¼›ä½†è¿™æ˜¯è§„æ¨¡åŒ–ç ”ç©¶çš„å‰æ |

#### 0.15.5 S5 å¯¹é½ä¸å½’å›  + Daily Replayï¼ˆAlignment & Attributionï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | æ— æ³•å›ç­”â€œèµš/äºæ˜¯å“ªä¸ªç­–ç•¥ã€å“ªä¸ªå› å­ã€å“ªä¸ªæ‰§è¡Œå»¶è¿Ÿå¯¼è‡´çš„â€ |
| æœºåˆ¶ | trace_id é“¾è·¯è´¯ç©¿ï¼ˆsignalâ†’orderâ†’fillâ†’pnlï¼‰ï¼›æ¯æ—¥ replay è¾“å‡ºå·®å¼‚æŠ¥å‘Š |
| éªŒæ”¶ | â‘  ä»»æ„ä¸€ç¬”æˆäº¤èƒ½è¿½æº¯åˆ°ç”Ÿæˆå®ƒçš„ä¿¡å·ä¸å½“æ—¶å¿«ç…§ï¼›â‘¡ daily replay å·®å¼‚å¯è§£é‡Šï¼ˆâ‰¤é˜ˆå€¼ï¼‰ |
| ä¸åšä»£ä»· | ç­–ç•¥è¿­ä»£æ— æ³•æ”¶æ•›ï¼›äº‹æ•…å¤ç›˜æ— è¯æ®é“¾ |
| ä¾èµ– | S1/S8/S9/S10ï¼›æ‰§è¡Œå›å†™ï¼ˆHummingbotï¼‰ |
| è¿è¡Œæˆæœ¬ | å­˜å‚¨ä¸è®¡ç®—é¢å¤–å¼€é”€ï¼›ä½†è¿™å°±æ˜¯â€œå¯è¿è¥â€çš„æˆæœ¬ |

#### 0.15.6 S6 éªŒæ”¶æµ‹è¯•ï¼ˆAcceptance Testsï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | æ–¹æ¡ˆå†™å¾—å†å¥½ï¼Œæ²¡æœ‰ç¡¬é—¨æ§›å°±ä¼šåœ¨å®ç°é˜¶æ®µè¢«â€œå·å·¥å‡æ–™â€ |
| æœºåˆ¶ | DoDï¼šä¸€è‡´æ€§ã€é™çº§ã€replayã€å›å†™ã€å¹‚ç­‰ã€æ€§èƒ½é—¨æ§› |
| éªŒæ”¶ | CI å¿…è·‘ï¼›å‡ºå…·æŠ¥å‘Šï¼ˆpass/fail + å·®å¼‚è§£é‡Šï¼‰ |
| ä¸åšä»£ä»· | åæœŸ bug ä¸ä¸€è‡´æ€§é—®é¢˜æŒ‡æ•°çº§å¢é•¿ |
| ä¾èµ– | å…¨æ¨¡å— |
| è¿è¡Œæˆæœ¬ | CI æ—¶é•¿ä¸Šå‡ï¼›ä½†å¯é€šè¿‡åˆ†å±‚ï¼ˆå¿«æµ‹/æ…¢æµ‹/å¤œé—´æµ‹ï¼‰æ§åˆ¶ |

#### 0.15.7 S7 ç‰©ç†è¾¹ç•Œéš”ç¦»ï¼ˆç ”ç©¶/æ‰§è¡Œ/å¯†é’¥ï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | å¯†é’¥æ³„éœ²ã€ç ”ç©¶ä»£ç è¯¯è§¦å‘å®ç›˜ã€æ‰§è¡Œå±‚è¢«ç ”ç©¶å±‚æ±¡æŸ“ |
| æœºåˆ¶ | ç‰©ç†éš”ç¦»ï¼ˆè¿›ç¨‹/æƒé™ï¼‰ã€å¯†é’¥åªåœ¨æ‰§è¡Œä¾§å¯è§ã€åªè¯»æ•°æ®å‡ºå£ |
| éªŒæ”¶ | â‘  ç ”ç©¶ä¾§æ— æ³•è¯»å–å¯†é’¥ï¼›â‘¡ ç ”ç©¶ä¾§æ— æ³•ç›´æ¥è°ƒç”¨ä¸‹å• APIï¼›â‘¢ æ‰§è¡Œä¾§é‡å¯ä¸å½±å“ç ”ç©¶æ•°æ®ä¸€è‡´æ€§ |
| ä¸åšä»£ä»· | å®‰å…¨ä¸èµ„é‡‘é£é™©ï¼Œä¸”ä¸€æ—¦å‘ç”Ÿé€šå¸¸æ˜¯â€œä¸å¯é€†â€ |
| ä¾èµ– | éƒ¨ç½²è§„èŒƒã€æƒé™ä½“ç³» |
| è¿è¡Œæˆæœ¬ | è¿ç»´å¤æ‚åº¦ç•¥å¢ï¼›ä½†å±äºå®‰å…¨åŸºçº¿ |

#### 0.15.8 S8 DataManager å”¯ä¸€å…¥å£ï¼ˆå•ä¸€äº‹å®æºï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | å¤šå…¥å£å¤šç¼“å­˜å¯¼è‡´æ•°æ®å£å¾„åˆ†è£‚ï¼›debug æˆæœ¬çˆ†ç‚¸ |
| æœºåˆ¶ | æ‰€æœ‰è¯»å–/å†™å…¥èµ° DataManagerï¼›ç¼“å­˜ç­–ç•¥é›†ä¸­ï¼›ç»Ÿä¸€ key ä¸ TTL |
| éªŒæ”¶ | ä»£ç æ‰«æï¼šç¦æ­¢ç»•è¿‡ DataManagerï¼›è¿è¡Œæ—¶ metricsï¼šcache hit/missã€å»¶è¿Ÿã€å›æºæ¬¡æ•° |
| ä¸åšä»£ä»· | â€œä¸€åŠæ—¶é—´åœ¨æ‰¾æ•°æ®åˆ°åº•ä»å“ªæ¥çš„â€ |
| ä¾èµ– | S2 æ•°æ®å¥‘çº¦ï¼›S9 key/hash |
| è¿è¡Œæˆæœ¬ | é›†ä¸­åŒ–åç»„ä»¶æ›´æ¸…æ™°ï¼Œé•¿æœŸåè€Œé™ä½æˆæœ¬ |

#### 0.15.9 S9 Canonical Hashing è§„èŒƒï¼ˆç»Ÿä¸€ key / å»é‡ / å¯¹é½ï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | å»é‡å¤±è´¥å¯¼è‡´é‡å¤ä¿¡å·/é‡å¤è®¢å•ï¼›å¯¹é½å¤±è´¥å¯¼è‡´å½’å› å¤±çœŸ |
| æœºåˆ¶ | canonical serialize + stable hashï¼›ç”¨äºæ•°æ®è¡Œã€å› å­ã€ä¿¡å·ã€è®¢å•äº‹ä»¶ |
| éªŒæ”¶ | hash ç¨³å®šæ€§æµ‹è¯•ï¼›è·¨è¯­è¨€/è·¨è¿›ç¨‹ä¸€è‡´ï¼›å‡çº§å¿…é¡»ç‰ˆæœ¬åŒ– |
| ä¸åšä»£ä»· | å¹‚ç­‰/å½’å› /é‡æ”¾éƒ½æ— æ³•å¯é å®ç° |
| ä¾èµ– | S4 å› å­æ²»ç†ï¼›S10 replay |
| è¿è¡Œæˆæœ¬ | è®¡ç®—å¼€é”€æå°ï¼›æ”¶ç›Šå·¨å¤§ |

#### 0.15.10 S10 Replay ç¡®å®šæ€§ä¿éšœï¼ˆå¯å¤ç° = å¯è¿è¥ï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰** |
| é£é™© | çº¿ä¸Šé—®é¢˜æ— æ³•å¤ç°ï¼›ç­–ç•¥è¿­ä»£å˜æˆâ€œè¯•é”™èµŒåšâ€ |
| æœºåˆ¶ | å›ºå®šéšæœºç§å­/ç‰ˆæœ¬é”å®š/æ•°æ®å¿«ç…§ï¼›daily replay å·®å¼‚æŠ¥å‘Š |
| éªŒæ”¶ | åŒè¾“å…¥åŒç‰ˆæœ¬è¾“å‡ºä¸¥æ ¼ä¸€è‡´ï¼›å·®å¼‚å¿…é¡»å¯è§£é‡Šä¸”åœ¨é˜ˆå€¼å†… |
| ä¸åšä»£ä»· | ç³»ç»Ÿæ°¸è¿œåœç•™åœ¨â€œä¸ªäººé¡¹ç›®â€æ°´å¹³ï¼Œæ— æ³•è§„æ¨¡åŒ– |
| ä¾èµ– | S1/S2/S4/S9 |
| è¿è¡Œæˆæœ¬ | å­˜å‚¨ä¸è®¡ç®—å¢åŠ ï¼›å¯é€šè¿‡åˆ†å±‚ replayï¼ˆæŠ½æ ·/å…¨é‡ï¼‰æ§åˆ¶ |

#### 0.15.11 æ‰§è¡Œå¼•æ“ï¼ˆHummingbot é›†æˆï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆå¿…é¡»ä¿ç•™ï¼‰**ï¼ˆä½†â€œå¤šäº¤æ˜“æ‰€/å¤šè´¦æˆ·ç¼–æ’â€å±äº**å¾…è¯æ®å¤æ‚åº¦**ï¼‰ |
| é£é™© | ä¸‹å•/æ’¤å•/éƒ¨åˆ†æˆäº¤/é‡è¿ä¸ä¸€è‡´å¯¼è‡´èµ„é‡‘æŸå¤±ï¼›å›æµ‹æ— æ³•é€¼è¿‘å®ç›˜ |
| æœºåˆ¶ | è®¢å•ç”Ÿå‘½å‘¨æœŸäº‹ä»¶åŒ–ï¼ˆorder/fill å›å†™ï¼‰ï¼›å¹‚ç­‰é”®ï¼›å¤±è´¥é‡è¯•ä¸é™æµï¼›ä¸ S1/S5 å¯¹é½ |
| éªŒæ”¶ | â‘  æ¨¡æ‹Ÿæ’®åˆ/æ²™ç›’å›æ”¾ï¼›â‘¡ æ–­çº¿é‡è¿/é‡å¤äº‹ä»¶ä¸é‡å¤ä¸‹å•ï¼›â‘¢ å»¶è¿Ÿ/æ»‘ç‚¹ç»Ÿè®¡ä¸é˜ˆå€¼ |
| ä¸åšä»£ä»· | â€œç­–ç•¥å†å¥½ä¹Ÿèµšä¸åˆ°é’±â€ï¼Œè€Œä¸”äº‹æ•…é€šå¸¸ä¸å¯æ§ |
| ä¾èµ– | äº¤æ˜“æ‰€è¿æ¥ã€å¯†é’¥å®‰å…¨ï¼ˆS7ï¼‰ã€ç›‘æ§å‘Šè­¦ |
| è¿è¡Œæˆæœ¬ | éœ€è¦ç»´æŠ¤è¿æ¥ä¸é€‚é…å™¨ï¼›å¯å…ˆå•äº¤æ˜“æ‰€å•è´¦æˆ· MVPï¼Œé€æ­¥æ‰©å±• |

#### 0.15.12 è§‚æµ‹ä¸è¿ç»´ï¼ˆObservability & Opsï¼‰

| é¡¹ | å†…å®¹ |
|---|---|
| å¿…è¦å¤æ‚åº¦ | **å¿…è¦å¤æ‚åº¦ï¼ˆä¿ç•™ï¼Œä½†å¯åˆ†é˜¶æ®µï¼‰** |
| é£é™© | ä¸çŸ¥é“ç³»ç»Ÿæ˜¯å¦é™çº§/æ˜¯å¦æ¼å•/æ˜¯å¦æ•°æ®å»¶è¿Ÿï¼›äº‹æ•…å‘ç°æ™š |
| æœºåˆ¶ | å…³é”® SLOï¼šæ•°æ®å»¶è¿Ÿã€é™çº§ç­‰çº§ã€è®¢å•å¤±è´¥ç‡ã€replay å·®å¼‚ï¼›å‘Šè­¦ä¸ä»ªè¡¨ç›˜ |
| éªŒæ”¶ | â‘  æŒ‡æ ‡é½å…¨ä¸”æœ‰æŠ¥è­¦é˜ˆå€¼ï¼›â‘¡ äº‹æ•…æ¼”ç»ƒï¼ˆé™æµ/æ–­ç½‘/æ•°æ®ç¼ºå¤±ï¼‰èƒ½è¢«æ•æ‰ |
| ä¸åšä»£ä»· | å®ç›˜è¿è¡Œç­‰åŒâ€œç›²é£â€ |
| ä¾èµ– | æ—¥å¿—/æŒ‡æ ‡ç»„ä»¶ã€CI æŠ¥å‘Š |
| è¿è¡Œæˆæœ¬ | ç»„ä»¶ä¸å­˜å‚¨æˆæœ¬ï¼›MVP å¯å…ˆåšæœ€å°é›†ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ + å…³é”®æŠ¥è­¦ï¼‰ |

---

### 0.16 åˆç†å†³ç­–ï¼šå¦‚ä½•ä¿è¯å¤æ‚åº¦ä¸æ˜¯ä¹±åŠ çš„ï¼ˆä¸ç åŠŸèƒ½ï¼Œä½†æŠŠâ€œé«˜é…â€å˜æˆå¯æ§å¼€å…³ï¼‰

1) **å…ˆæŠŠâ€œå¿…è¦å¤æ‚åº¦â€è¿‡é—¨æ§›**ï¼šåªè¦æ¶‰åŠä¸€è‡´æ€§ã€æ—¶é—´ç‚¹æ•°æ®ã€å›å†™å½’å› ã€å¹‚ç­‰é‡æ”¾ã€å®‰å…¨éš”ç¦»ï¼Œè¿™äº›å¤æ‚åº¦éƒ½æ˜¯â€œä¹°ä¿é™©â€ï¼Œä¸èƒ½çœã€‚  
2) **æŠŠâ€œè¯æ®ä¸è¶³å¤æ‚åº¦â€å…¨éƒ¨å¼€å…³åŒ–**ï¼šé»˜è®¤ offï¼Œåªæœ‰åœ¨æ»¡è¶³è¯æ®æ¡ä»¶ï¼ˆå‹æµ‹/æˆæœ¬æ”¶ç›Š/çœŸå®éœ€æ±‚ï¼‰åæ‰å¼€å¯ã€‚  
3) **ç»™æ¯ä¸ªå¼€å…³å†™æ¸…æ¥šä¸‰ä»¶äº‹**ï¼šå¼€å¯æ¡ä»¶ï¼ˆè¯æ®ï¼‰ã€å›é€€è·¯å¾„ï¼ˆé™çº§ï¼‰ã€ä¸Šçº¿å½±å“é¢ï¼ˆæŒ‡æ ‡/å‘Šè­¦ï¼‰ã€‚  
4) **æ‰©å±•è·¯çº¿å»ºè®®ï¼ˆä¸ç ï¼Œåˆ†é˜¶æ®µï¼‰**ï¼š  
   - é˜¶æ®µ Aï¼šå•äº¤æ˜“æ‰€ + å•è´¦æˆ· + å•ç­–ç•¥æ—ï¼ˆæŠŠ S1-S10+å›å†™å½’å› è·‘é€šï¼‰  
   - é˜¶æ®µ Bï¼šå¢åŠ ç­–ç•¥æ—/å‚æ•°æ‰«æï¼ˆè¯æ˜ç ”ç©¶æ•ˆç‡æå‡ï¼‰  
   - é˜¶æ®µ Cï¼šå†åšå¤šäº¤æ˜“æ‰€/å¤šè´¦æˆ·/æ›´å¤æ‚çš„æ‰§è¡Œè·¯ç”±ï¼ˆç”¨çœŸå®æ”¶ç›Šä¸è¿ç»´æˆæœ¬è¯æ˜å®ƒå€¼å¾—ï¼‰


## 1. é¡¹ç›®æ¦‚è¿°

> âœ… **MVPåŒ…å«** - æ­¤èŠ‚ä¸ºæ ¸å¿ƒè®¾è®¡åŸåˆ™ï¼ŒMVPå¿…é¡»éµå®ˆã€‚

### 1.1 æ ¸å¿ƒåŸåˆ™

> **"æˆç†Ÿåº¦å’Œç¨³å®šæ€§ä¼˜å…ˆï¼Œä¸ä»¥ç³»ç»Ÿå¤æ‚åº¦ä¸ºåŸºå‡†"**

### 1.2 æŠ€æœ¯é€‰å‹

| å±‚çº§ | ç»„ä»¶ | ç‰ˆæœ¬ | è¯´æ˜ |
|------|------|------|------|
| **æ•°æ®å±‚** | MultiSourceDataManager | è‡ªå»º | ç»Ÿä¸€ç®¡ç†æ•°æ®æºï¼Œæ”¯æŒå¿«ç…§å­˜å‚¨ |
| **ç ”ç©¶å±‚** | Microsoft Qlib | 0.9.7 | **ä»…ç”¨äºç ”ç©¶/å›æµ‹** (è§ Section 0.0.4) |
| **ç”Ÿäº§ä¿¡å·å±‚** | FactorEngine | è‡ªå»º | è½»é‡çº§å› å­è®¡ç®—ï¼Œ**ä¸ä¾èµ–Qlib** |
| **å›æµ‹å±‚** | CryptoPerpetualBacktest | è‡ªå»º | èµ„é‡‘è´¹ç‡æ¨¡æ‹Ÿã€çˆ†ä»“æ£€æµ‹ |
| **æ‰§è¡Œå±‚** | Hummingbot | 2.11.0 | 15k starsï¼Œä¼ä¸šçº§æ‰§è¡Œå¼•æ“ |
| **é£æ§å±‚** | RiskManager + PositionManager | è‡ªå»º | å¤šå±‚é£æ§ã€æ™ºèƒ½ä»“ä½åˆ†é… |

> **å…³é”®æ¾„æ¸…**: Qlib æ˜¯ç ”ç©¶å·¥å…·ï¼Œä¸æ˜¯ç”Ÿäº§ç³»ç»Ÿæ ¸å¿ƒã€‚MVPç”Ÿäº§ç®¡é“ä½¿ç”¨è‡ªå»ºçš„ FactorEngineï¼Œä¸ä¾èµ– Qlibã€‚è¯¦è§ Section 0.0.4ã€‚

### 1.3 æºç ä½ç½®

```
/home/user/
â”œâ”€â”€ qlib/                    # ç”¨æˆ·é¡¹ç›®ä»“åº“ (AlgVex)
â”‚   â””â”€â”€ algvex/              # AlgVex æ ¸å¿ƒä»£ç 
â”œâ”€â”€ hummingbot/              # Hummingbot v2.11.0 æºç 
â””â”€â”€ microsoft-qlib/          # Microsoft Qlib v0.9.7 æºç 
```

---

## 2. ç³»ç»Ÿæ¶æ„

> âœ… **MVPåŒ…å«** - åŒé“¾è·¯æ¶æ„ä¸ºæ ¸å¿ƒè®¾è®¡ï¼ŒMVPç”Ÿäº§é“¾è·¯åªç”¨FactorEngine(11å› å­)ï¼Œç ”ç©¶é“¾è·¯å¯åæœŸæ‰©å±•ã€‚

### 2.1 æ¶æ„å›¾ (ç”Ÿäº§/ç ”ç©¶åŒé“¾è·¯)

> ç”Ÿäº§é“¾è·¯ä¸ä¾èµ–Qlibï¼Œç ”ç©¶é“¾è·¯ç‹¬ç«‹ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              algvex.com                                     â”‚
â”‚                            (Cloudflare CDN)                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚      Nginx      â”‚
                         â”‚   (åå‘ä»£ç†)    â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                  â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend    â”‚        â”‚  Backend API  â”‚        â”‚   WebSocket   â”‚
â”‚    (React)    â”‚        â”‚   (FastAPI)   â”‚        â”‚   (å®æ—¶æ¨é€)  â”‚
â”‚   Port:3000   â”‚        â”‚   Port:8000   â”‚        â”‚   Port:8001   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                        â”‚                        â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
â”‚    Celery     â”‚       â”‚     Redis     â”‚       â”‚  PostgreSQL   â”‚
â”‚   (ä»»åŠ¡é˜Ÿåˆ—)  â”‚       â”‚  (ç¼“å­˜/æ¶ˆæ¯)  â”‚       â”‚ +TimescaleDB  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚
        â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  â”‚                    AlgVex Core Engine                    â”‚
        â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
        â””â”€â”€â–¶                                                          â”‚
           â”‚                                                          â”‚
           â”‚  â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—   â”‚
           â”‚  â•‘            ç”Ÿäº§é“¾è·¯ (Production)                 â•‘   â”‚
           â”‚  â•‘            âŒ ä¸ä¾èµ– Qlib                         â•‘   â”‚
           â”‚  â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£   â”‚
           â”‚  â•‘                                                  â•‘   â”‚
           â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘   â”‚
           â”‚  â•‘  â”‚DataService â”‚â†’â”‚FactorEngineâ”‚â†’â”‚ ModelRunnerâ”‚ â•‘   â”‚
           â”‚  â•‘  â”‚ (æ¥å£)     â”‚  â”‚ (MVP-11)   â”‚  â”‚(å¯¼å‡ºæƒé‡) â”‚ â•‘   â”‚
           â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘   â”‚
           â”‚  â•‘                        â”‚                        â•‘   â”‚
           â”‚  â•‘                        â–¼                        â•‘   â”‚
           â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â•‘   â”‚
           â”‚  â•‘  â”‚ RiskManagerâ”‚â†â”‚ PositionMgrâ”‚â†â”‚SignalGen   â”‚ â•‘   â”‚
           â”‚  â•‘  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â•‘   â”‚
           â”‚  â•‘        â–¼                                        â•‘   â”‚
           â”‚  â•‘  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â•‘   â”‚
           â”‚  â•‘  â”‚         æ‰§è¡Œå±‚ (Hummingbot)             â”‚   â•‘   â”‚
           â”‚  â•‘  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â•‘   â”‚
           â”‚  â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
           â”‚                                                          â”‚
           â”‚  â”Œ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”      â”‚
           â”‚  â”‚           ç ”ç©¶é“¾è·¯ (Research)                 â”‚      â”‚
           â”‚  â”‚           âœ… ä½¿ç”¨ Qlib                        â”‚      â”‚
           â”‚  â”œ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”¤      â”‚
           â”‚  â”‚                                               â”‚      â”‚
           â”‚  â”‚ DataManager â†’ QlibAdapter â†’ Alpha180/201 â†’   â”‚      â”‚
           â”‚  â”‚ QlibDataset â†’ Trainer â†’ ExportModelArtifact  â”‚      â”‚
           â”‚  â”‚                    â†“                          â”‚      â”‚
           â”‚  â”‚              models/exported/                 â”‚      â”‚
           â”‚  â”‚              (ä¾›ç”Ÿäº§é“¾è·¯ä½¿ç”¨)                  â”‚      â”‚
           â”‚  â”‚                                               â”‚      â”‚
           â”‚  â”” â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€ â”€â”˜      â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                      â”‚
                                      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        MVP å¤–éƒ¨æ•°æ®æº (ä»…3ä¸ª)                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ å¸å®‰ klines_5m          â”‚ å¸å®‰ open_interest  â”‚ å¸å®‰ funding_rate      â”‚
â”‚ (Kçº¿æ•°æ®)               â”‚ (æŒä»“é‡)            â”‚ (èµ„é‡‘è´¹ç‡)             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.2 ç»Ÿä¸€æ•°æ®ç®¡ç†æ¶æ„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨ (DataManager)                          â”‚
â”‚                     æ•´ä¸ªç³»ç»Ÿçš„å”¯ä¸€æ•°æ®å…¥å£å’Œå‡ºå£                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    1. æ•°æ®é‡‡é›†å±‚ (Collectors)                        â”‚   â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚   â”‚
â”‚  â”‚  â”‚ Binance  â”‚ â”‚ Deribit  â”‚ â”‚DefiLlama â”‚ â”‚Sentiment â”‚ â”‚  Macro   â”‚  â”‚   â”‚
â”‚  â”‚  â”‚Collector â”‚ â”‚Collector â”‚ â”‚Collector â”‚ â”‚Collector â”‚ â”‚Collector â”‚  â”‚   â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚   â”‚
â”‚  â”‚       â”‚            â”‚            â”‚            â”‚            â”‚         â”‚   â”‚
â”‚  â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚   â”‚
â”‚  â”‚                                 â–¼                                    â”‚   â”‚
â”‚  â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚   â”‚
â”‚  â”‚                    â”‚  ç»Ÿä¸€æ•°æ®æ ¼å¼è½¬æ¢    â”‚                          â”‚   â”‚
â”‚  â”‚                    â”‚  (Qlib MultiIndex)  â”‚                          â”‚   â”‚
â”‚  â”‚                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                  â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    2. æ•°æ®å­˜å‚¨å±‚ (Storage)                           â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚   â”‚
â”‚  â”‚   â”‚ TimescaleDB â”‚    â”‚   Redis     â”‚    â”‚  Qlibæœ¬åœ°   â”‚             â”‚   â”‚
â”‚  â”‚   â”‚  (å†å²æ•°æ®)  â”‚    â”‚ (å®æ—¶ç¼“å­˜)  â”‚    â”‚  (ç‰¹å¾æ–‡ä»¶) â”‚             â”‚   â”‚
â”‚  â”‚   â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚   â”‚
â”‚  â”‚          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚   â”‚
â”‚  â”‚                             â–¼                                        â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                â–¼                                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    3. æ•°æ®æœåŠ¡å±‚ (DataService)                       â”‚   â”‚
â”‚  â”‚                    ç»Ÿä¸€APIï¼Œä¾›æ‰€æœ‰ä¸‹æ¸¸æ¨¡å—è°ƒç”¨                         â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   get_historical()  get_realtime()  get_features()  get_labels()    â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚              â”‚                 â”‚                 â”‚                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â–¼                 â–¼                 â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚    å› å­è®¡ç®—      â”‚ â”‚     å›æµ‹å¼•æ“    â”‚ â”‚    å®ç›˜æ‰§è¡Œ      â”‚
     â”‚  (FactorEngine) â”‚ â”‚   (Backtest)    â”‚ â”‚  (LiveTrader)   â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 2.3 æ•°æ®æµè¯¦è§£

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                              å®Œæ•´æ•°æ®æµ                                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€ç ”ç©¶/å›æµ‹æ¨¡å¼ã€‘                                                           â”‚
â”‚                                                                             â”‚
â”‚   å¤–éƒ¨API â”€â”€â†’ Collector â”€â”€â†’ Storage â”€â”€â†’ DataService.get_historical()       â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚                                       FactorEngine (å› å­è®¡ç®—)               â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚                                       Qlib Dataset (è®­ç»ƒæ•°æ®)               â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚                                       ML Model (è®­ç»ƒ/é¢„æµ‹)                  â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚                                       Backtest (å›æµ‹éªŒè¯)                   â”‚
â”‚                                              â”‚                              â”‚
â”‚                                              â–¼                              â”‚
â”‚                                       Report (å›æµ‹æŠ¥å‘Š)                     â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€å®ç›˜æ¨¡å¼ã€‘                                                                â”‚
â”‚                                                                             â”‚
â”‚   å¤–éƒ¨API â”€â”€â†’ Collector â”€â”€â†’ Redis â”€â”€â†’ DataService.get_realtime()           â”‚
â”‚                (WebSocket)              â”‚                                   â”‚
â”‚                                         â–¼                                   â”‚
â”‚                                  FactorEngine (å®æ—¶å› å­)                    â”‚
â”‚                                         â”‚                                   â”‚
â”‚                                         â–¼                                   â”‚
â”‚                                  ML Model (å®æ—¶é¢„æµ‹)                        â”‚
â”‚                                         â”‚                                   â”‚
â”‚                                         â–¼                                   â”‚
â”‚                                  SignalGenerator (ä¿¡å·ç”Ÿæˆ)                 â”‚
â”‚                                         â”‚                                   â”‚
â”‚                                         â–¼                                   â”‚
â”‚                                  RiskManager (é£æ§æ£€æŸ¥)                     â”‚
â”‚                                         â”‚                                   â”‚
â”‚                                         â–¼                                   â”‚
â”‚                                  Hummingbot (è®¢å•æ‰§è¡Œ)                      â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 3. æ•°æ®å±‚

> âœ… **MVPåŒ…å«** - ä½†ä»…éœ€å®ç°**Aæ¡£æ•°æ®æº**(å¸å®‰klines_5m, open_interest_5m, funding_rate)ã€‚
> â¸ï¸ **MVPä¸åŒ…å«** - Bæ¡£(DeribitæœŸæƒ, Google Trendsç­‰)å’ŒCæ¡£(è‡ªå»ºè½ç›˜)å»¶ååˆ°Phase 2ã€‚

> **åŸåˆ™**: ä»…ä½¿ç”¨å…è´¹æ•°æ®æºï¼›å†å²å¯å¾—æ€§åˆ†A/B/Cä¸‰æ¡£ï¼ŒB/Cæ¡£éœ€è‡ªå»ºè½ç›˜æ‰èƒ½å½¢æˆé•¿æœŸå¯å›æ”¾å†å²ã€‚

### 3.1 æ•°æ®å¯å¾—æ€§åˆ†çº§ (å…³é”®ï¼)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   æ•°æ®å¯å¾—æ€§ä¸‰çº§åˆ†ç±» (å†³å®šå›æµ‹å¯ä¿¡åº¦)                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€Aæ¡£ã€‘å¯ç¨³å®šå›æº¯å¤šå¹´ - ç›´æ¥å¯ç”¨äºé•¿æœŸå›æµ‹                                    â”‚
â”‚  â”œâ”€ å¸å®‰ OHLCV (Kçº¿)          å†å²çª—å£: æ— é™          å£å¾„ç¨³å®š: â˜…â˜…â˜…         â”‚
â”‚  â”œâ”€ Yahoo Finance (å®è§‚)      å†å²çª—å£: å¤šå¹´          å£å¾„ç¨³å®š: â˜…â˜…â˜…         â”‚
â”‚  â”œâ”€ FRED (åˆ©ç‡/ç»æµ)          å†å²çª—å£: å¤šå¹´          å£å¾„ç¨³å®š: â˜…â˜…â˜…         â”‚
â”‚  â””â”€ DefiLlama (TVL/ç¨³å®šå¸)    å†å²çª—å£: 2å¹´+          å£å¾„ç¨³å®š: â˜…â˜…â˜†         â”‚
â”‚                                                                             â”‚
â”‚  ã€Bæ¡£ã€‘å†å²çª—å£æœ‰é™ - éœ€è‡ªå»ºè½ç›˜ç§¯ç´¯é•¿æœŸæ•°æ®                                  â”‚
â”‚  â”œâ”€ å¸å®‰ OI/å¤šç©ºæ¯”/å¤§æˆ·æ¯”     å†å²çª—å£: 30-90å¤©       å£å¾„ç¨³å®š: â˜…â˜…â˜†         â”‚
â”‚  â”œâ”€ å¸å®‰ Taker Buy/Sell       å†å²çª—å£: 500æ¡/è¯·æ±‚    å£å¾„ç¨³å®š: â˜…â˜…â˜…         â”‚
â”‚  â”œâ”€ Deribit æœŸæƒæ•°æ®          å†å²çª—å£: æœ‰é™          å£å¾„ç¨³å®š: â˜…â˜…â˜†         â”‚
â”‚  â””â”€ Alternative Fear&Greed    å†å²çª—å£: å¤šå¹´          å£å¾„ç¨³å®š: â˜…â˜…â˜…         â”‚
â”‚                                                                             â”‚
â”‚  ã€Cæ¡£ã€‘å¿…é¡»è‡ªå»ºè½ç›˜ - æ— å®˜æ–¹å†å²APIæˆ–ä¸ç¨³å®š                                   â”‚
â”‚  â”œâ”€ Google Trends             å†å²çª—å£: æŠ“å–ä¾èµ–      å£å¾„ç¨³å®š: â˜…â˜†â˜†         â”‚
â”‚  â”œâ”€ å®æ—¶WebSocketæ•°æ®         å†å²çª—å£: æ—             å£å¾„ç¨³å®š: N/A          â”‚
â”‚  â””â”€ è·¨äº¤æ˜“æ‰€ä»·å·® (éœ€è‡ªè¡Œè®¡ç®—)  å†å²çª—å£: å–å†³äºæº     å£å¾„ç¨³å®š: â˜…â˜…â˜†         â”‚
â”‚                                                                             â”‚
â”‚  âš ï¸ é‡è¦: B/Cæ¡£æ•°æ®å¿…é¡»ä»ç°åœ¨å¼€å§‹è‡ªå»ºè½ç›˜ï¼Œæ‰èƒ½å½¢æˆé•¿æœŸå¯å›æ”¾çš„å†å²ï¼          â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3.2 æ•°æ®æºè¯¦ç»†é…ç½®

| ç±»åˆ« | æ•°æ®æº | å­—æ®µ | é¢‘ç‡ | å»¶è¿Ÿ | å†å²çª—å£ | å£å¾„ç¨³å®šæ€§ | è¡¥æ´ç­–ç•¥ |
|------|--------|------|------|------|----------|-----------|----------|
| **äº¤æ˜“æ‰€åŸºç¡€** | å¸å®‰æ°¸ç»­ | $open, $close, $high, $low, $volume | 1m-1d | baræ”¶ç›˜ | æ— é™ (Aæ¡£) | High | backfill |
| | å¸å®‰æ°¸ç»­ | $funding_rate | 8h | ç»“ç®—å | å¤šå¹´ (Aæ¡£) | High | backfill |
| | å¸å®‰æ°¸ç»­ | $open_interest | 5m | ~5min | 30å¤© (Bæ¡£) | Medium | éœ€è½ç›˜ |
| | å¸å®‰æ°¸ç»­ | $long_short_ratio, $top_long_short_ratio | 5m | ~5min | 30å¤© (Bæ¡£) | Medium | éœ€è½ç›˜ |
| | å¸å®‰æ°¸ç»­ | $taker_buy_volume, $taker_sell_volume | 1m-1d | baræ”¶ç›˜ | 500æ¡ (Bæ¡£) | High | éœ€è½ç›˜ |
| **æœŸæƒ** | Deribit | $dvol_index (BTC/ETH) | 1h | ~1min | æœ‰é™ (Bæ¡£) | Medium | éœ€è½ç›˜ |
| | Deribit | $iv_atm, $put_call_ratio, $max_pain | 1h | ~5min | æœ‰é™ (Bæ¡£) | Medium | éœ€è½ç›˜ |
| **è¡ç”Ÿå“ç»“æ„** | å¤šäº¤æ˜“æ‰€ | $basis (spot - perp) | 1m | baræ”¶ç›˜ | éœ€è®¡ç®— (Cæ¡£) | Medium | éœ€è½ç›˜ |
| | å¸å®‰ | $insurance_fund | 1d | T+1 | å¤šå¹´ (Aæ¡£) | High | backfill |
| **é“¾ä¸Š** | DefiLlama | $stablecoin_supply, $stablecoin_change | 1d | ~1h | 2å¹´+ (Aæ¡£) | Medium | backfill |
| | DefiLlama | $defi_tvl, $tvl_change | 1d | ~1h | 2å¹´+ (Aæ¡£) | Medium | backfill |
| **æƒ…ç»ª** | Alternative | $fear_greed (0-100) | 1d | ~1h | å¤šå¹´ (Aæ¡£) | High | backfill |
| | Google | $btc_trend, $crypto_trend | 1d | ~1d | æŠ“å– (Cæ¡£) | Low | éœ€è½ç›˜ |
| **å®è§‚** | Yahoo/FRED | $dxy, $us10y, $us02y, $gold, $spx, $vix | 1d | ~1h | å¤šå¹´ (Aæ¡£) | High | backfill |

### 3.3 ç»Ÿä¸€æ•°æ®ç®¡ç†å™¨ (DataManager)

> **æ ¸å¿ƒè®¾è®¡**: DataManager æ˜¯æ•´ä¸ªç³»ç»Ÿçš„å”¯ä¸€æ•°æ®å…¥å£ï¼Œæ‰€æœ‰æ¨¡å—é€šè¿‡å®ƒè·å–æ•°æ®ï¼Œç¡®ä¿æ•°æ®ä¸€è‡´æ€§ã€‚

```python
from algvex.core.data import DataManager

# åˆå§‹åŒ–æ•°æ®ç®¡ç†å™¨ï¼ˆæ•´ä¸ªç³»ç»Ÿåªéœ€åˆå§‹åŒ–ä¸€æ¬¡ï¼‰
dm = DataManager(
    db_url="postgresql://localhost/algvex",
    redis_url="redis://localhost:6379",
    qlib_path="~/.algvex/qlib_data",
)

# ==================== ç ”ç©¶/å›æµ‹æ¨¡å¼ ====================

# 1. ä¸‹è½½/æ›´æ–°å†å²æ•°æ®ï¼ˆé¦–æ¬¡æˆ–å®šæœŸæ›´æ–°ï¼‰
dm.update_historical(
    start_date="2023-01-01",
    end_date="2024-12-31",
    symbols=["BTCUSDT", "ETHUSDT"],
)

# 2. è·å–å†å²æ•°æ®ï¼ˆå› å­è®¡ç®—ã€å›æµ‹ä½¿ç”¨ï¼‰
df = dm.get_historical(
    symbols=["BTCUSDT", "ETHUSDT"],
    start_date="2024-01-01",
    end_date="2024-12-31",
    freq="1h",
    fields=["$open", "$close", "$funding_rate", "$dvol", "$fear_greed"],
)

# 3. è·å– Qlib Datasetï¼ˆæ¨¡å‹è®­ç»ƒä½¿ç”¨ï¼‰
dataset = dm.get_qlib_dataset(
    symbols=["BTCUSDT", "ETHUSDT"],
    segments={
        "train": ("2023-01-01", "2024-06-30"),
        "valid": ("2024-07-01", "2024-09-30"),
        "test": ("2024-10-01", "2024-12-31"),
    },
    handler="CryptoAlpha180",  # 180å› å­å¤„ç†å™¨
)

# ==================== å®ç›˜æ¨¡å¼ ====================

# 4. å¯åŠ¨å®æ—¶æ•°æ®æµ
await dm.start_realtime(symbols=["BTCUSDT", "ETHUSDT"])

# 5. è·å–å®æ—¶æ•°æ®ï¼ˆå®ç›˜ä¿¡å·ç”Ÿæˆä½¿ç”¨ï¼‰
realtime_df = dm.get_realtime(
    symbols=["BTCUSDT"],
    lookback="24h",  # æœ€è¿‘24å°æ—¶æ•°æ®
)

# 6. è·å–æœ€æ–°å› å­å€¼ï¼ˆå®ç›˜é¢„æµ‹ä½¿ç”¨ï¼‰
latest_features = dm.get_latest_features(
    symbols=["BTCUSDT", "ETHUSDT"],
)
```

### 3.4 æ•°æ®æœåŠ¡æ¥å£ (DataService API)

| æ–¹æ³• | ç”¨é€” | è°ƒç”¨æ–¹ |
|------|------|--------|
| `update_historical()` | ä¸‹è½½/æ›´æ–°å†å²æ•°æ® | å®šæ—¶ä»»åŠ¡ |
| `get_historical()` | è·å–å†å²æ•°æ® | å› å­è®¡ç®—ã€å›æµ‹ |
| `get_qlib_dataset()` | è·å–Qlibæ ¼å¼æ•°æ®é›† | æ¨¡å‹è®­ç»ƒ |
| `start_realtime()` | å¯åŠ¨å®æ—¶æ•°æ®æµ | å®ç›˜æœåŠ¡ |
| `get_realtime()` | è·å–å®æ—¶æ•°æ® | å®æ—¶å› å­ |
| `get_latest_features()` | è·å–æœ€æ–°å› å­å€¼ | å®æ—¶é¢„æµ‹ |

### 3.5 æ•°æ®é‡‡é›†å™¨æ¥å£ (Collector Interface)

```python
from abc import ABC, abstractmethod

class BaseCollector(ABC):
    """æ‰€æœ‰æ•°æ®é‡‡é›†å™¨çš„åŸºç±»"""

    @abstractmethod
    async def fetch_historical(self, symbol: str, start: str, end: str) -> pd.DataFrame:
        """è·å–å†å²æ•°æ®"""
        pass

    @abstractmethod
    async def subscribe_realtime(self, symbol: str, callback: Callable) -> None:
        """è®¢é˜…å®æ—¶æ•°æ®"""
        pass

    @abstractmethod
    def to_qlib_format(self, df: pd.DataFrame) -> pd.DataFrame:
        """è½¬æ¢ä¸ºQlibæ ¼å¼"""
        pass

# å„æ•°æ®æºé‡‡é›†å™¨ç»§æ‰¿ç»Ÿä¸€æ¥å£
class BinanceCollector(BaseCollector): ...
class DeribitCollector(BaseCollector): ...
class DefiLlamaCollector(BaseCollector): ...
class SentimentCollector(BaseCollector): ...
class MacroCollector(BaseCollector): ...
```

### 3.6 Qlib æ•°æ®æ ¼å¼

```
MultiIndex: (datetime, instrument)
å­—æ®µå‰ç¼€: $ (å¦‚ $open, $close, $funding_rate)
æ—¶åŒº: å…¨ç³»ç»Ÿå¼ºåˆ¶ UTC (å°¤å…¶ funding ç»“ç®— 0/8/16 UTC)
æ—¥å†: åŠ å¯†è´§å¸ 24/7 (éœ€è‡ªå®šä¹‰ï¼Œä¸ä½¿ç”¨è‚¡ç¥¨äº¤æ˜“æ—¥)

                           $open    $close  $funding_rate  $cvd      $dvol  $fear_greed
datetime    instrument
2024-01-01  btcusdt      42000.0  42100.0        0.0001   15000.0    55.2          65
            ethusdt       2200.0   2210.0        0.00015   8000.0    62.1          65
```

### 3.7 æ•°æ®äº‹å®æºä¸ç‰ˆæœ¬åŒ– (ç ”ç©¶å¯å¤ç°çš„å…³é”®)

> **æ ¸å¿ƒé—®é¢˜**: å¤šå­˜å‚¨å±‚ï¼ˆTimescaleDB + Qlibæ–‡ä»¶ + Redisï¼‰å¦‚æœä¸å®šä¹‰äº‹å®æºï¼Œå°†å¯¼è‡´æ•°æ®ä¸ä¸€è‡´å’Œå®éªŒä¸å¯å¤ç°ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ•°æ®å±‚çº§ä¸äº‹å®æºå®šä¹‰                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  ã€L0 åŸå§‹æ•°æ®å±‚ã€‘ äº‹å®æº = TimescaleDB                                       â”‚
â”‚  â”œâ”€ ç‰¹ç‚¹: ä¸å¯å˜ã€å¯è¿½æº¯ã€å¸¦æ—¶é—´æˆ³                                            â”‚
â”‚  â”œâ”€ å­˜å‚¨: åŸå§‹APIå“åº” (JSON/Parquet)                                        â”‚
â”‚  â””â”€ è§„åˆ™: ä¸€æ—¦å†™å…¥ä¸å¯ä¿®æ”¹ï¼Œåªèƒ½è¿½åŠ                                           â”‚
â”‚                                                                             â”‚
â”‚  ã€L1 æ´¾ç”Ÿç‰¹å¾å±‚ã€‘ Qlib æœ¬åœ°æ–‡ä»¶ / Parquet                                    â”‚
â”‚  â”œâ”€ ç‰¹ç‚¹: ç”± L0 è®¡ç®—ç”Ÿæˆï¼Œå¿…é¡»ç‰ˆæœ¬åŒ–                                         â”‚
â”‚  â”œâ”€ ç‰ˆæœ¬åŒ–: feature_set_id = hash(å› å­ä»£ç  + å‚æ•° + L0å¿«ç…§ID)                â”‚
â”‚  â””â”€ è§„åˆ™: æ¯æ¬¡é‡æ–°è®¡ç®—ç”Ÿæˆæ–°ç‰ˆæœ¬ï¼Œæ—§ç‰ˆæœ¬ä¿ç•™                                   â”‚
â”‚                                                                             â”‚
â”‚  ã€L2 å®æ—¶ç¼“å­˜å±‚ã€‘ Redis                                                      â”‚
â”‚  â”œâ”€ ç‰¹ç‚¹: æ˜“å¤±æ€§ï¼Œä»…ç”¨äºå®ç›˜ä½å»¶è¿Ÿè®¿é—®                                        â”‚
â”‚  â”œâ”€ è§„åˆ™: ä¸ä½œä¸ºå¯å¤ç°å®éªŒçš„æ•°æ®æ¥æº                                          â”‚
â”‚  â””â”€ åˆ·æ–°: å®šæœŸä» L0/L1 åŒæ­¥                                                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

```python
# æ•°æ®å¿«ç…§ä¸è¡€ç¼˜è®°å½• (æ¯æ¬¡è®­ç»ƒ/å›æµ‹å¿…é¡»è®°å½•)
@dataclass
class DataSnapshot:
    """æ•°æ®å¿«ç…§ - ç¡®ä¿å®éªŒå¯å¤ç°"""
    snapshot_id: str                    # å”¯ä¸€ID
    created_at: datetime                # åˆ›å»ºæ—¶é—´

    # æ•°æ®èŒƒå›´
    symbols: List[str]                  # æ ‡çš„åˆ—è¡¨
    start_date: str                     # å¼€å§‹æ—¥æœŸ
    end_date: str                       # ç»“æŸæ—¥æœŸ

    # å„æ•°æ®æºæˆªè‡³æ—¶é—´ä¸ç‰ˆæœ¬
    source_versions: Dict[str, str]     # {"binance_ohlcv": "2024-12-21T00:00:00Z", ...}

    # å»¶è¿Ÿé…ç½®ç‰ˆæœ¬
    delay_config_hash: str              # PUBLICATION_DELAYS é…ç½®çš„ hash

    # è¡¥æ´ç­–ç•¥ç‰ˆæœ¬
    backfill_strategy_hash: str         # è¡¥æ´é€»è¾‘çš„ hash

@dataclass
class ExperimentRecord:
    """å®éªŒè®°å½• - å®Œæ•´è¡€ç¼˜é“¾"""
    experiment_id: str

    # æ•°æ®è¡€ç¼˜
    data_snapshot_id: str               # ä½¿ç”¨çš„æ•°æ®å¿«ç…§
    feature_set_id: str                 # å› å­ç‰ˆæœ¬ (ä»£ç hash + å‚æ•°hash)

    # æ¨¡å‹è¡€ç¼˜
    model_config_hash: str              # æ¨¡å‹é…ç½® hash
    random_seed: int                    # éšæœºç§å­

    # ç»“æœ
    train_metrics: Dict[str, float]
    test_metrics: Dict[str, float]

    # å¯è¿½æº¯
    git_commit: str                     # ä»£ç ç‰ˆæœ¬
    created_at: datetime
```

---

## 4. ä¿¡å·å±‚

> âœ… **MVPåŒ…å«** - ä½†ä»…å®ç°**MVP-11å› å­**(è§Section 0.0.3)ï¼Œä½¿ç”¨è‡ªå»ºFactorEngineã€‚
> â¸ï¸ **MVPä¸åŒ…å«** - 180å› å­ç ”ç©¶åº“(å«Qlib Alpha180)å»¶ååˆ°ç ”ç©¶é˜¶æ®µï¼Œä¸è¿›å…¥ç”Ÿäº§é“¾è·¯ã€‚

### 4.1 å› å­ä½“ç³» (AlgVex è‡ªå»º 201ä¸ªï¼Œå…¨éƒ¨åŸºäºå…è´¹æ•°æ®)

> **é‡è¦è¯´æ˜**: Qlib æœ¬èº«ä¸æä¾›åŠ å¯†è´§å¸å› å­ã€‚ä»¥ä¸‹ 201 ä¸ªå› å­å‡ä¸º AlgVex åŸºäº Qlib æ¡†æ¶è‡ªå»ºï¼Œä¸“ä¸ºæ°¸ç»­åˆçº¦è®¾è®¡ã€‚**æ•°æ®æºå…¨éƒ¨å…è´¹ï¼Œä½†å†å²å¯å¾—æ€§åˆ†A/B/Cä¸‰æ¡£ï¼ˆè§ Section 3.1ï¼‰ï¼ŒB/Cæ¡£éœ€è‡ªå»ºè½ç›˜æ‰èƒ½å½¢æˆé•¿æœŸå¯å›æ”¾å†å²ã€‚**
>
> **å› å­æ„æˆ**: 180ä¸ªæ ¸å¿ƒå› å­ + 21ä¸ªP1æ‰©å±•å› å­ (L2æ·±åº¦8ä¸ª + æ¸…ç®—5ä¸ª + Basis8ä¸ª)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   AlgVex è‡ªå»ºå› å­ä½“ç³» (180ä¸ªï¼Œä»…å…è´¹æ•°æ®)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ä¸€ã€åŸºç¡€ä»·é‡å› å­ (50ä¸ª) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [ä»·æ ¼åŠ¨é‡] 20ä¸ª                    [æ³¢åŠ¨ç‡] 15ä¸ª                           â”‚
â”‚  â”œâ”€ return_1h/4h/24h/7d            â”œâ”€ volatility_12h/24h/7d               â”‚
â”‚  â”œâ”€ mom_12h/24h/72h                â”œâ”€ atr_24h/7d                          â”‚
â”‚  â”œâ”€ ma_cross_12_24/24_72           â”œâ”€ skewness/kurtosis                   â”‚
â”‚  â”œâ”€ price_position_52w             â”œâ”€ volatility_ratio                    â”‚
â”‚  â””â”€ breakout_20d/60d               â””â”€ realized_vol / rv_ratio             â”‚
â”‚                                                                             â”‚
â”‚  [æˆäº¤é‡] 15ä¸ª                                                              â”‚
â”‚  â”œâ”€ volume_ratio_12h/24h/7d        â”œâ”€ volume_trend                        â”‚
â”‚  â”œâ”€ price_volume_corr              â”œâ”€ obv / obv_change                    â”‚
â”‚  â”œâ”€ volume_breakout                â””â”€ relative_volume                     â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• äºŒã€æ°¸ç»­åˆçº¦ä¸“ç”¨å› å­ (45ä¸ª) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [èµ„é‡‘è´¹ç‡] 12ä¸ª â˜…æ°¸ç»­ä¸“ç”¨                                                  â”‚
â”‚  â”œâ”€ funding_rate                   â”œâ”€ funding_rate_ma_8h/24h             â”‚
â”‚  â”œâ”€ funding_premium                â”œâ”€ funding_momentum                   â”‚
â”‚  â”œâ”€ funding_zscore                 â”œâ”€ funding_extreme (>0.1% æˆ– <-0.05%) â”‚
â”‚  â”œâ”€ funding_cumsum_24h/7d          â””â”€ funding_reversal_signal            â”‚
â”‚                                                                             â”‚
â”‚  [æŒä»“é‡ OI] 12ä¸ª â˜…æ°¸ç»­ä¸“ç”¨                                                 â”‚
â”‚  â”œâ”€ oi_change_1h/4h/24h            â”œâ”€ oi_volume_ratio                    â”‚
â”‚  â”œâ”€ oi_price_divergence            â”œâ”€ oi_momentum                        â”‚
â”‚  â”œâ”€ oi_zscore                      â”œâ”€ oi_concentration                   â”‚
â”‚  â””â”€ oi_funding_interaction         â””â”€ oi_breakout                        â”‚
â”‚                                                                             â”‚
â”‚  [å¤šç©ºåšå¼ˆ+CVD] 21ä¸ª â˜…æ°¸ç»­ä¸“ç”¨                                              â”‚
â”‚  â”œâ”€ long_short_ratio               â”œâ”€ top_trader_long_short_ratio        â”‚
â”‚  â”œâ”€ top_trader_position_ratio      â”œâ”€ ls_momentum                        â”‚
â”‚  â”œâ”€ ls_extreme                     â”œâ”€ ls_reversal_signal                 â”‚
â”‚  â”œâ”€ taker_buy_volume               â”œâ”€ taker_sell_volume                  â”‚
â”‚  â”œâ”€ taker_buy_sell_ratio           â”œâ”€ taker_delta                        â”‚
â”‚  â”œâ”€ cvd (ç´¯è®¡æˆäº¤é‡å·®)              â”œâ”€ cvd_change_1h/4h/24h              â”‚
â”‚  â”œâ”€ cvd_price_divergence           â”œâ”€ cvd_momentum                       â”‚
â”‚  â””â”€ cvd_zscore                     â””â”€ net_taker_flow                     â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ä¸‰ã€æœŸæƒ/æ³¢åŠ¨ç‡å› å­ (20ä¸ª) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [éšå«æ³¢åŠ¨ç‡] 10ä¸ª (Deribit å…è´¹API)                                        â”‚
â”‚  â”œâ”€ dvol_btc / dvol_eth            â”œâ”€ dvol_change_24h                    â”‚
â”‚  â”œâ”€ iv_atm                         â”œâ”€ iv_skew (put vs call)              â”‚
â”‚  â”œâ”€ iv_term_structure              â”œâ”€ iv_rv_spread (IV - RV)             â”‚
â”‚  â”œâ”€ iv_percentile                  â””â”€ vol_risk_premium                   â”‚
â”‚                                                                             â”‚
â”‚  [æœŸæƒæŒä»“] 10ä¸ª (Deribit å…è´¹API)                                          â”‚
â”‚  â”œâ”€ put_call_ratio                 â”œâ”€ put_call_oi_ratio                  â”‚
â”‚  â”œâ”€ max_pain                       â”œâ”€ max_pain_distance                  â”‚
â”‚  â”œâ”€ gamma_exposure                 â”œâ”€ option_volume_spike                â”‚
â”‚  â”œâ”€ large_put_oi                   â””â”€ large_call_oi                      â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• å››ã€è¡ç”Ÿå“ç»“æ„å› å­ (15ä¸ª) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [åŸºå·®] 8ä¸ª                                                                 â”‚
â”‚  â”œâ”€ basis (spot - perp)            â”œâ”€ basis_percentage                   â”‚
â”‚  â”œâ”€ basis_ma_24h                   â”œâ”€ basis_zscore                       â”‚
â”‚  â”œâ”€ basis_momentum                 â”œâ”€ annualized_basis                   â”‚
â”‚  â”œâ”€ basis_funding_corr             â””â”€ basis_extreme                      â”‚
â”‚                                                                             â”‚
â”‚  [å¸‚åœºç»“æ„] 7ä¸ª                                                             â”‚
â”‚  â”œâ”€ cross_exchange_spread          â”œâ”€ binance_premium                    â”‚
â”‚  â”œâ”€ insurance_fund_change          â”œâ”€ market_depth_ratio                 â”‚
â”‚  â”œâ”€ exchange_dominance             â””â”€ volume_concentration               â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• äº”ã€é“¾ä¸Šå› å­ (10ä¸ªï¼ŒDefiLlamaå…è´¹) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [ç¨³å®šå¸] 5ä¸ª (DefiLlama å…è´¹)                                              â”‚
â”‚  â”œâ”€ stablecoin_supply              â”œâ”€ stablecoin_supply_change_7d        â”‚
â”‚  â”œâ”€ stablecoin_dominance           â”œâ”€ usdt_usdc_ratio                    â”‚
â”‚  â””â”€ stablecoin_momentum                                                    â”‚
â”‚                                                                             â”‚
â”‚  [DeFi TVL] 5ä¸ª (DefiLlama å…è´¹)                                            â”‚
â”‚  â”œâ”€ defi_tvl_total                 â”œâ”€ defi_tvl_change_7d                 â”‚
â”‚  â”œâ”€ eth_tvl_dominance              â”œâ”€ tvl_mcap_ratio                     â”‚
â”‚  â””â”€ tvl_momentum                                                           â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• å…­ã€æƒ…ç»ªå› å­ (10ä¸ª) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [Fear & Greed] 5ä¸ª (alternative.me å…è´¹)                                   â”‚
â”‚  â”œâ”€ fear_greed_index               â”œâ”€ fear_greed_ma_7d                   â”‚
â”‚  â”œâ”€ fear_greed_momentum            â”œâ”€ fear_greed_extreme                 â”‚
â”‚  â””â”€ fear_greed_reversal                                                    â”‚
â”‚                                                                             â”‚
â”‚  [Google Trends] 5ä¸ª (å…è´¹)                                                 â”‚
â”‚  â”œâ”€ btc_search_trend               â”œâ”€ crypto_search_trend                â”‚
â”‚  â”œâ”€ search_trend_change            â”œâ”€ search_spike_detection             â”‚
â”‚  â””â”€ search_price_divergence                                                â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ä¸ƒã€å®è§‚å…³è”å› å­ (15ä¸ª) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [ç¾å…ƒ/åˆ©ç‡] 8ä¸ª (Yahoo/FRED å…è´¹)                                          â”‚
â”‚  â”œâ”€ dxy_index                      â”œâ”€ dxy_change_5d                      â”‚
â”‚  â”œâ”€ btc_dxy_corr_30d               â”œâ”€ us10y_yield                        â”‚
â”‚  â”œâ”€ us02y_yield                    â”œâ”€ yield_curve (10y - 2y)             â”‚
â”‚  â”œâ”€ rate_sensitivity               â””â”€ real_yield                         â”‚
â”‚                                                                             â”‚
â”‚  [é£é™©èµ„äº§] 7ä¸ª (Yahoo å…è´¹)                                                â”‚
â”‚  â”œâ”€ spx_return_5d                  â”œâ”€ btc_spx_corr_30d                   â”‚
â”‚  â”œâ”€ nasdaq_return_5d               â”œâ”€ vix_index                          â”‚
â”‚  â”œâ”€ vix_change                     â”œâ”€ gold_return_5d                     â”‚
â”‚  â””â”€ btc_gold_corr_30d                                                      â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• å…«ã€å¤åˆ/MLå› å­ (15ä¸ª) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•    â”‚
â”‚                                                                             â”‚
â”‚  [å¤åˆå› å­] 15ä¸ª                                                            â”‚
â”‚  â”œâ”€ alpha_momentum                 â”œâ”€ alpha_mean_reversion               â”‚
â”‚  â”œâ”€ alpha_orderflow                â”œâ”€ alpha_sentiment                    â”‚
â”‚  â”œâ”€ alpha_volatility               â”œâ”€ alpha_structure                    â”‚
â”‚  â”œâ”€ risk_on_off_score              â”œâ”€ regime_indicator                   â”‚
â”‚  â”œâ”€ trend_strength                 â”œâ”€ mean_reversion_score               â”‚
â”‚  â”œâ”€ breakout_probability           â”œâ”€ crash_risk_indicator               â”‚
â”‚  â”œâ”€ momentum_quality               â”œâ”€ factor_momentum                    â”‚
â”‚  â””â”€ ml_ensemble_score                                                      â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               æ ¸å¿ƒå› å­: 180 ä¸ª (å…¨éƒ¨å…è´¹ï¼Œå¯ç›´æ¥è·å–å†å²æ•°æ®)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ä¹ã€P1æ‰©å±•å› å­ (21ä¸ªï¼Œéœ€è‡ªå»ºè½ç›˜) â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•  â”‚
â”‚                                                                             â”‚
â”‚  [L2æ·±åº¦å› å­] 8ä¸ª (Step 9, Cæ¡£)                                             â”‚
â”‚  â”œâ”€ bid_ask_spread                â”œâ”€ order_book_imbalance                 â”‚
â”‚  â”œâ”€ depth_1pct_bid/ask            â”œâ”€ depth_slope_bid/ask                  â”‚
â”‚  â””â”€ impact_cost_buy/sell                                                   â”‚
â”‚                                                                             â”‚
â”‚  [æ¸…ç®—å› å­] 5ä¸ª (Step 10, Bæ¡£)                                              â”‚
â”‚  â”œâ”€ liquidation_volume_long/short â”œâ”€ liquidation_imbalance                â”‚
â”‚  â”œâ”€ liquidation_spike             â””â”€ liquidation_momentum                 â”‚
â”‚                                                                             â”‚
â”‚  [å¤šäº¤æ˜“æ‰€Basis] 8ä¸ª (Step 11, Cæ¡£)                                         â”‚
â”‚  â”œâ”€ basis_binance/bybit/okx       â”œâ”€ basis_consensus                      â”‚
â”‚  â”œâ”€ basis_dispersion              â”œâ”€ cross_exchange_spread                â”‚
â”‚  â”œâ”€ price_discovery_leader        â””â”€ arbitrage_pressure                   â”‚
â”‚                                                                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚               æ€»è®¡: 201 ä¸ªå› å­ (180æ ¸å¿ƒ + 21 P1æ‰©å±•)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 4.2 å› å­åˆ†ç±»ç»Ÿè®¡

| ç±»åˆ« | å› å­æ•° | æ•°æ®æ¥æº | å†å²æ•°æ® | å¤‡æ³¨ |
|------|--------|----------|----------|------|
| åŸºç¡€ä»·é‡ | 50 | å¸å®‰ REST | âœ… å¤šå¹´ (Aæ¡£) | æ ¸å¿ƒ |
| æ°¸ç»­åˆçº¦ä¸“ç”¨ | 45 | å¸å®‰ REST | âœ… 30å¤©+ (Bæ¡£) | æ ¸å¿ƒ |
| æœŸæƒ/æ³¢åŠ¨ç‡ | 20 | Deribit | âœ… æœ‰å†å² (Bæ¡£) | æ ¸å¿ƒ |
| è¡ç”Ÿå“ç»“æ„ | 15 | å¤šäº¤æ˜“æ‰€ | âœ… å¯è®¡ç®— (Cæ¡£) | æ ¸å¿ƒ |
| é“¾ä¸Š | 10 | DefiLlama | âœ… å¤šå¹´ (Aæ¡£) | æ ¸å¿ƒ |
| æƒ…ç»ª | 10 | Alternative/Google | âœ… å¤šå¹´ (A/Cæ¡£) | æ ¸å¿ƒ |
| å®è§‚å…³è” | 15 | Yahoo/FRED | âœ… å¤šå¹´ (Aæ¡£) | æ ¸å¿ƒ |
| å¤åˆ/ML | 15 | è‡ªå»º | âœ… åŸºäºä»¥ä¸Š | æ ¸å¿ƒ |
| **æ ¸å¿ƒå°è®¡** | **180** | | | |
| â˜… L2æ·±åº¦ | 8 | å¸å®‰ WebSocket | âš ï¸ éœ€è‡ªå»º (Cæ¡£) | Step 9 |
| â˜… æ¸…ç®— | 5 | å¸å®‰ WebSocket | âš ï¸ éœ€è‡ªå»º (Bæ¡£) | Step 10 |
| â˜… å¤šäº¤æ˜“æ‰€Basis | 8 | Binance/Bybit/OKX | âš ï¸ éœ€è‡ªå»º (Cæ¡£) | Step 11 |
| **P1æ‰©å±•å°è®¡** | **21** | | | |
| **æ€»è®¡** | **201** | **å…¨éƒ¨å…è´¹** | | |

### 4.3 MLæ¨¡å‹é…ç½®

```yaml
model:
  type: LGBMModel  # æˆ– XGBoostModel, DNNModel
  lgbm_params:
    n_estimators: 500
    learning_rate: 0.05
    max_depth: 8
    num_leaves: 64
    feature_fraction: 0.8
    bagging_fraction: 0.8
    min_child_samples: 50
  training:
    loss: mse
    early_stopping_rounds: 50
    validation_split: 0.2
  feature_selection:
    method: importance
    top_k: 50
```

---

## 5. å›æµ‹å±‚

> âœ… **MVPåŒ…å«** - æ ¸å¿ƒå›æµ‹å¼•æ“å¿…é¡»å®ç°ï¼Œæ”¯æŒèµ„é‡‘è´¹ç‡ã€æ»‘ç‚¹ã€çˆ†ä»“æ£€æµ‹ã€‚
> ğŸ“ **MVPç²¾ç®€** - ä»…éœ€å•äº¤æ˜“æ‰€(å¸å®‰)ã€å•æ—¶é—´æ¡†æ¶(5m)ã€åŸºç¡€æŒ‡æ ‡(Sharpe/MaxDD/èƒœç‡)ã€‚

### 5.1 CryptoPerpetualBacktest

```python
from algvex.core.backtest import BacktestConfig, CryptoPerpetualBacktest

config = BacktestConfig(
    initial_capital=100000.0,     # åˆå§‹èµ„é‡‘ $100k
    leverage=3.0,                  # é»˜è®¤æ æ† 3x
    max_leverage=10.0,             # æœ€å¤§æ æ† 10x
    taker_fee=0.0004,              # Takerè´¹ç‡ 0.04%
    maker_fee=0.0002,              # Makerè´¹ç‡ 0.02%
    slippage=0.0001,               # æ»‘ç‚¹ 0.01%
    funding_rate_interval=8,       # èµ„é‡‘è´¹ç‡é—´éš” 8å°æ—¶
    liquidation_threshold=0.8,     # çˆ†ä»“é˜ˆå€¼ 80%ä¿è¯é‡‘ç‡
)

engine = CryptoPerpetualBacktest(config)
results = engine.run(signals, prices, funding_rates)
```

### 5.2 å›æµ‹æŒ‡æ ‡

| æ”¶ç›ŠæŒ‡æ ‡ | é£é™©æŒ‡æ ‡ | äº¤æ˜“æŒ‡æ ‡ | æ°¸ç»­ä¸“ç”¨ |
|----------|----------|----------|----------|
| æ€»æ”¶ç›Šç‡ | æœ€å¤§å›æ’¤ | èƒœç‡ | èµ„é‡‘è´¹ç”¨æ€»é¢ |
| å¹´åŒ–æ”¶ç›Š | æ³¢åŠ¨ç‡ | ç›ˆäºæ¯” | èµ„é‡‘è´¹ç”¨å æ¯” |
| å¤æ™®æ¯”ç‡ | ç´¢æè¯ºæ¯”ç‡ | å¹³å‡æŒä»“æ—¶é—´ | çˆ†ä»“æ¬¡æ•° |
| å¡å°”ç›æ¯”ç‡ | VaR | äº¤æ˜“æ¬¡æ•° | ä¿è¯é‡‘åˆ©ç”¨ç‡ |

---

## 6. æ‰§è¡Œå±‚

> âœ… **MVPåŒ…å«** - Hummingboté›†æˆä¸ºæ ¸å¿ƒï¼Œå¿…é¡»å®ç°è®¢å•æ‰§è¡Œå’Œä¸‰é‡å±éšœã€‚
> ğŸ“ **MVPç²¾ç®€** - ä»…éœ€PositionExecutoræ‰§è¡Œå™¨ï¼Œå…¶ä»–5ç§æ‰§è¡Œå™¨(DCA/TWAP/Grid/Arbitrage/XEMM)å»¶åã€‚

### 6.1 Hummingbot v2.11.0 Strategy V2 æ¡†æ¶

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Hummingbot Strategy V2 æ¶æ„                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  [æ§åˆ¶å™¨å±‚] ControllerConfigBase                                        â”‚
â”‚  â”œâ”€ controller_name: ç­–ç•¥åç§°                                           â”‚
â”‚  â”œâ”€ candles_config: Kçº¿æ•°æ®é…ç½®                                         â”‚
â”‚  â”œâ”€ initial_positions: åˆå§‹æŒä»“é…ç½®                                     â”‚
â”‚  â””â”€ manual_kill_switch: æ‰‹åŠ¨åœæ­¢å¼€å…³                                    â”‚
â”‚                                                                         â”‚
â”‚  [æ‰§è¡Œå™¨å±‚] 6ç§å†…ç½®æ‰§è¡Œå™¨                                                â”‚
â”‚  â”œâ”€ PositionExecutor: å•ä»“ä½æ‰§è¡Œ (ä¸‰é‡å±éšœ: æ­¢æŸ/æ­¢ç›ˆ/æ—¶é—´é™åˆ¶)          â”‚
â”‚  â”œâ”€ DCAExecutor: å®šæŠ•/åˆ†æ‰¹å»ºä»“                                          â”‚
â”‚  â”œâ”€ TWAPExecutor: æ—¶é—´åŠ æƒå¹³å‡ä»·æ ¼æ‰§è¡Œ                                   â”‚
â”‚  â”œâ”€ GridExecutor: ç½‘æ ¼äº¤æ˜“æ‰§è¡Œ                                          â”‚
â”‚  â”œâ”€ ArbitrageExecutor: è·¨äº¤æ˜“æ‰€å¥—åˆ©                                      â”‚
â”‚  â””â”€ XEMMExecutor: è·¨äº¤æ˜“æ‰€åšå¸‚                                          â”‚
â”‚                                                                         â”‚
â”‚  [å›æµ‹å±‚] strategy_v2/backtesting/                                      â”‚
â”‚  â”œâ”€ BacktestingEngineBase: å›æµ‹å¼•æ“åŸºç±»                                  â”‚
â”‚  â”œâ”€ BacktestingDataProvider: å›æµ‹æ•°æ®æä¾›è€…                              â”‚
â”‚  â””â”€ ExecutorSimulator: æ‰§è¡Œå™¨æ¨¡æ‹Ÿå™¨                                      â”‚
â”‚                                                                         â”‚
â”‚  [æ°¸ç»­äº¤æ˜“æ‰€] 12ä¸ª CEX/DEX                                               â”‚
â”‚  â”œâ”€ CEX: Binance, Bybit, OKX, KuCoin, Gate.io, Bitget, BitMart          â”‚
â”‚  â””â”€ DEX: Hyperliquid, dYdX v4, Injective v2, Derive                     â”‚
â”‚                                                                         â”‚
â”‚  [æ•°æ®æº] 21ä¸ªKçº¿æ•°æ®æº                                                  â”‚
â”‚  â”œâ”€ æ”¯æŒé—´éš”: 1s, 1m, 3m, 5m, 15m, 30m, 1h, 2h, 4h, 6h, 8h, 12h, 1d    â”‚
â”‚  â””â”€ å­—æ®µ: timestamp, open, high, low, close, volume, quote_asset_volume â”‚
â”‚                                                                         â”‚
â”‚  [æ¸…ç®—æ•°æ®] liquidations_feed (é£æ§å¢å¼º)                                 â”‚
â”‚  â””â”€ BinancePerpetualLiquidations: å®æ—¶å¸‚åœºæ¸…ç®—äº‹ä»¶                       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 6.2 ä¸‰é‡å±éšœé£æ§ (Triple Barrier)

```python
from hummingbot.strategy_v2.executors.position_executor.data_types import (
    PositionExecutorConfig,
    TripleBarrierConfig,
)

config = PositionExecutorConfig(
    connector_name="binance_perpetual",
    trading_pair="BTC-USDT",
    side=TradeType.BUY,
    amount=Decimal("0.1"),
    triple_barrier_config=TripleBarrierConfig(
        stop_loss=Decimal("0.03"),          # æ­¢æŸ 3%
        take_profit=Decimal("0.06"),        # æ­¢ç›ˆ 6%
        time_limit=60 * 60 * 24,            # æ—¶é—´é™åˆ¶ 24å°æ—¶
        stop_loss_order_type=OrderType.MARKET,
        take_profit_order_type=OrderType.LIMIT,
    )
)
```

### 6.3 HummingbotBridge è¯¦ç»†å®ç°

> **æ ¸å¿ƒèŒè´£**: è¿æ¥ AlgVex SignalGenerator å’Œ Hummingbot Connectorï¼Œç®¡ç†è®¢å•ç”Ÿå‘½å‘¨æœŸï¼ŒçŠ¶æ€åŒæ­¥

```python
# algvex/core/execution/hummingbot_bridge.py

from decimal import Decimal
from typing import Dict, Optional, List
from datetime import datetime
import asyncio

from hummingbot.connector.connector_base import ConnectorBase
from hummingbot.core.data_type.in_flight_order import InFlightOrder
from hummingbot.core.data_type.common import OrderType, TradeType
from hummingbot.core.data_type.order_candidate import OrderCandidate

from algvex.production.signal.signal_generator import Signal
from algvex.shared.trace_serializer import DeterministicTraceSerializer


class HummingbotBridge:
    """
    AlgVex ä¸ Hummingbot çš„æ¡¥æ¥å±‚

    æ ¸å¿ƒåŠŸèƒ½:
    1. ä¿¡å· â†’ è®¢å•è½¬æ¢ (Signal â†’ Order)
    2. è®¢å•ç”Ÿå‘½å‘¨æœŸç®¡ç† (InFlightOrder)
    3. çŠ¶æ€åŒæ­¥ (Position Reconciliation)
    4. äº‹ä»¶è¿½è¸ª (Order Events â†’ Trace)

    âš ï¸ å¹‚ç­‰æ€§ä¿éšœ: ç›¸åŒä¿¡å·ç”Ÿæˆç›¸åŒ client_order_id
    """

    def __init__(
        self,
        connector: ConnectorBase,
        trace_writer: Optional['TraceWriter'] = None,
        exchange: str = "binance_perpetual",
        api_key: str = "",
        api_secret: str = "",
        testnet: bool = True,
        max_leverage: int = 10,
    ):
        self.connector = connector
        self.trace_writer = trace_writer
        self.serializer = DeterministicTraceSerializer()
        self.exchange = exchange
        self.testnet = testnet
        self.max_leverage = max_leverage

        # è®¢å•è·Ÿè¸ª (å¹‚ç­‰æ€§å…³é”®)
        self._signal_to_order: Dict[str, str] = {}  # signal_id -> client_order_id
        self._order_to_signal: Dict[str, str] = {}  # client_order_id -> signal_id
        self._pending_signals: Dict[str, Signal] = {}

    async def connect(self):
        """è¿æ¥äº¤æ˜“æ‰€"""
        await self.connector.start()

    async def execute_signal(self, signal: Signal) -> Dict:
        """
        æ‰§è¡Œ AlgVex ä¿¡å·

        âš ï¸ å¹‚ç­‰æ€§: ç›¸åŒä¿¡å·é‡å¤è°ƒç”¨è¿”å›ç›¸åŒç»“æœ

        Args:
            signal: AlgVex ä¿¡å·å¯¹è±¡

        Returns:
            æ‰§è¡Œç»“æœ dict
        """
        # 1. ç”Ÿæˆå¹‚ç­‰çš„ client_order_id
        client_order_id = self._generate_idempotent_order_id(signal)

        # 2. æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡ (å¹‚ç­‰ä¿æŠ¤)
        if client_order_id in self.connector.in_flight_orders:
            existing_order = self.connector.in_flight_orders[client_order_id]
            return {
                "status": "duplicate",
                "client_order_id": client_order_id,
                "order_state": existing_order.current_state.name,
            }

        # 3. è½¬æ¢ä¸º Hummingbot OrderCandidate
        order_candidate = self._signal_to_order_candidate(signal, client_order_id)

        # 4. é¢„ç®—æ£€æŸ¥ (ä½¿ç”¨ Hummingbot BudgetChecker)
        adjusted_candidate = self.connector.budget_checker.adjust_candidate(
            order_candidate, all_or_none=False
        )
        if adjusted_candidate.amount == Decimal("0"):
            return {
                "status": "rejected",
                "reason": "insufficient_funds",
                "signal_id": signal.signal_id,
            }

        # 5. ä¸‹å•
        try:
            if signal.direction > 0:
                order_id = self.connector.buy(
                    trading_pair=signal.symbol,
                    amount=adjusted_candidate.amount,
                    order_type=OrderType.MARKET,
                    price=Decimal("0"),
                )
            else:
                order_id = self.connector.sell(
                    trading_pair=signal.symbol,
                    amount=adjusted_candidate.amount,
                    order_type=OrderType.MARKET,
                    price=Decimal("0"),
                )

            # 6. è®°å½•æ˜ å°„
            self._signal_to_order[signal.signal_id] = order_id
            self._order_to_signal[order_id] = signal.signal_id
            self._pending_signals[order_id] = signal

            # 7. å†™å…¥ trace
            if self.trace_writer:
                self._write_order_trace(signal, order_id, "submitted")

            return {
                "status": "submitted",
                "client_order_id": order_id,
                "signal_id": signal.signal_id,
                "amount": str(adjusted_candidate.amount),
            }

        except Exception as e:
            return {
                "status": "failed",
                "error": str(e),
                "signal_id": signal.signal_id,
            }

    def _generate_idempotent_order_id(self, signal: Signal) -> str:
        """
        ç”Ÿæˆå¹‚ç­‰çš„è®¢å• ID

        åŸºäºä¿¡å·å†…å®¹ hashï¼Œç›¸åŒä¿¡å·ç”Ÿæˆç›¸åŒ ID
        âš ï¸ è¿™æ˜¯é˜²æ­¢é‡å¤ä¸‹å•çš„æ ¸å¿ƒæœºåˆ¶
        """
        content = {
            "symbol": signal.symbol,
            "direction": signal.direction,
            "bar_close_time": signal.bar_close_time.isoformat(),
            "final_signal": signal.final_signal,
        }
        hash_str = self.serializer.compute_hash(content)
        return f"algvex_{hash_str[:16]}"

    def _signal_to_order_candidate(
        self, signal: Signal, client_order_id: str
    ) -> OrderCandidate:
        """å°† AlgVex Signal è½¬æ¢ä¸º Hummingbot OrderCandidate"""
        return OrderCandidate(
            trading_pair=signal.symbol,
            is_maker=False,  # Market order = taker
            order_type=OrderType.MARKET,
            order_side=TradeType.BUY if signal.direction > 0 else TradeType.SELL,
            amount=Decimal(str(signal.quantity)),
            price=Decimal("0"),
        )

    def signal_to_order(
        self,
        signal: Signal,
        capital: float,
        risk_per_trade: float = 0.02,
        leverage: int = 1
    ) -> OrderCandidate:
        """
        ä¿¡å·è½¬è®¢å• (å«ä»“ä½è®¡ç®—)

        Args:
            signal: ä¿¡å·å¯¹è±¡
            capital: æ€»èµ„é‡‘
            risk_per_trade: å•ç¬”é£é™©æ¯”ä¾‹
            leverage: æ æ†å€æ•°
        """
        # è®¡ç®—ä»“ä½å¤§å°
        position_value = capital * risk_per_trade * leverage
        quantity = position_value / signal.price if signal.price > 0 else Decimal("0")

        return OrderCandidate(
            trading_pair=signal.symbol,
            is_maker=False,
            order_type=OrderType.MARKET,
            order_side=TradeType.BUY if signal.score > 0 else TradeType.SELL,
            amount=Decimal(str(quantity)),
            price=Decimal("0"),
        )

    async def execute_order(self, order: OrderCandidate) -> Dict:
        """æ‰§è¡Œè®¢å•"""
        # é¢„ç®—æ£€æŸ¥
        adjusted = self.connector.budget_checker.adjust_candidate(order, all_or_none=False)
        if adjusted.amount == Decimal("0"):
            return {"status": "rejected", "reason": "insufficient_funds"}

        # ä¸‹å•
        if order.order_side == TradeType.BUY:
            order_id = self.connector.buy(
                trading_pair=order.trading_pair,
                amount=adjusted.amount,
                order_type=order.order_type,
                price=order.price,
            )
        else:
            order_id = self.connector.sell(
                trading_pair=order.trading_pair,
                amount=adjusted.amount,
                order_type=order.order_type,
                price=order.price,
            )

        return {"status": "submitted", "order_id": order_id}

    def _write_order_trace(self, signal: Signal, order_id: str, status: str):
        """å†™å…¥è®¢å•è¿½è¸ª"""
        trace = {
            "type": "order_event",
            "signal_id": signal.signal_id,
            "client_order_id": order_id,
            "status": status,
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }
        self.trace_writer.write(trace)

    # ==================== äº‹ä»¶å¤„ç† ====================

    async def on_order_filled(self, event: 'OrderFilledEvent'):
        """å¤„ç†è®¢å•æˆäº¤äº‹ä»¶"""
        order_id = event.order_id
        signal_id = self._order_to_signal.get(order_id)

        if signal_id and self.trace_writer:
            trace = {
                "type": "order_filled",
                "signal_id": signal_id,
                "client_order_id": order_id,
                "exchange_order_id": event.exchange_order_id,
                "price": str(event.price),
                "amount": str(event.amount),
                "trade_fee": str(event.trade_fee.flat_fees) if event.trade_fee else "0",
                "timestamp": datetime.utcnow().isoformat() + "Z",
            }
            self.trace_writer.write(trace)

        # æ¸…ç†
        if order_id in self._pending_signals:
            del self._pending_signals[order_id]

    async def on_order_cancelled(self, event: 'OrderCancelledEvent'):
        """å¤„ç†è®¢å•å–æ¶ˆäº‹ä»¶"""
        order_id = event.order_id
        signal_id = self._order_to_signal.get(order_id)

        if signal_id and self.trace_writer:
            trace = {
                "type": "order_cancelled",
                "signal_id": signal_id,
                "client_order_id": order_id,
                "timestamp": datetime.utcnow().isoformat() + "Z",
            }
            self.trace_writer.write(trace)

    # ==================== çŠ¶æ€åŒæ­¥ ====================

    async def sync_positions(self) -> Dict:
        """ä¸äº¤æ˜“æ‰€åŒæ­¥ä»“ä½"""
        exchange_positions = {}

        for trading_pair in self.connector.trading_pairs:
            position = self.connector.get_position(trading_pair)
            if position:
                exchange_positions[trading_pair] = {
                    "amount": str(position.amount),
                    "entry_price": str(position.entry_price),
                    "leverage": position.leverage,
                    "unrealized_pnl": str(position.unrealized_pnl),
                }

        return exchange_positions

    async def reconcile(self) -> Dict:
        """
        å¯¹è´¦: æ¯”è¾ƒæœ¬åœ°çŠ¶æ€å’Œäº¤æ˜“æ‰€çŠ¶æ€

        ç”¨äºæ£€æµ‹çŠ¶æ€ä¸ä¸€è‡´å¹¶å‘Šè­¦
        """
        exchange_positions = await self.sync_positions()
        # TODO: ä¸æœ¬åœ° PositionManager çŠ¶æ€å¯¹æ¯”
        return {
            "timestamp": datetime.utcnow().isoformat() + "Z",
            "exchange_positions": len(exchange_positions),
            "aligned": True,  # ç®€åŒ–ç‰ˆ
        }
```

### 6.4 InFlightOrder é›†æˆ

> Hummingbot çš„ `InFlightOrder` æ˜¯è®¢å•ç”Ÿå‘½å‘¨æœŸç®¡ç†çš„æ ¸å¿ƒï¼ŒAlgVex å¿…é¡»æ­£ç¡®é›†æˆã€‚

```python
# Hummingbot InFlightOrder çŠ¶æ€æœº
# hummingbot/core/data_type/in_flight_order.py

class InFlightOrder:
    """
    è®¢å•ç”Ÿå‘½å‘¨æœŸè¿½è¸ª

    çŠ¶æ€æµè½¬:
    PENDING_CREATE â†’ OPEN â†’ FILLED / CANCELLED / FAILED
    """
    client_order_id: str          # å®¢æˆ·ç«¯è®¢å•ID (å¹‚ç­‰é”®)
    exchange_order_id: Optional[str]
    trading_pair: str
    order_type: OrderType
    trade_type: TradeType
    price: Decimal
    amount: Decimal
    creation_timestamp: float
    current_state: OrderState     # PENDING, OPEN, FILLED, CANCELLED, FAILED

    # çŠ¶æ€è½¬æ¢æ–¹æ³•
    def update_with_order_update(self, order_update: OrderUpdate)
    def update_with_trade_update(self, trade_update: TradeUpdate)
```

**AlgVex ä¸ InFlightOrder çš„é›†æˆ**:

```python
# algvex/core/execution/order_tracker.py

class AlgVexOrderTracker:
    """
    è®¢å•è¿½è¸ªå™¨ - é›†æˆ Hummingbot InFlightOrder

    åŠŸèƒ½:
    1. è®¢å•çŠ¶æ€æŸ¥è¯¢
    2. è®¢å•è¶…æ—¶æ£€æµ‹
    3. æ–­çº¿æ¢å¤
    """

    def __init__(self, bridge: HummingbotBridge):
        self.bridge = bridge
        self._order_timeout = 60  # 60ç§’è¶…æ—¶

    def get_order_status(self, client_order_id: str) -> Optional[Dict]:
        """è·å–è®¢å•çŠ¶æ€"""
        order = self.bridge.connector.in_flight_orders.get(client_order_id)
        if order:
            return {
                "client_order_id": client_order_id,
                "exchange_order_id": order.exchange_order_id,
                "state": order.current_state.name,
                "filled_amount": str(order.executed_amount_base),
                "avg_price": str(order.average_executed_price),
            }
        return None

    async def check_timeout_orders(self) -> List[str]:
        """æ£€æŸ¥è¶…æ—¶è®¢å•"""
        timeout_orders = []
        current_time = time.time()

        for order_id, order in self.bridge.connector.in_flight_orders.items():
            if order.current_state == OrderState.PENDING_CREATE:
                age = current_time - order.creation_timestamp
                if age > self._order_timeout:
                    timeout_orders.append(order_id)

        return timeout_orders
```

### 6.5 çŠ¶æ€åŒæ­¥å™¨

```python
# algvex/core/execution/state_synchronizer.py

class StateSynchronizer:
    """
    çŠ¶æ€åŒæ­¥å™¨

    èŒè´£:
    1. å®šæœŸåŒæ­¥ä»“ä½çŠ¶æ€
    2. æ£€æµ‹å¹¶å¤„ç†çŠ¶æ€ä¸ä¸€è‡´
    3. å¤„ç†æ–­çº¿é‡è¿
    """

    def __init__(
        self,
        bridge: HummingbotBridge,
        position_manager: 'PositionManager',
        sync_interval: float = 60.0,  # 60ç§’åŒæ­¥ä¸€æ¬¡
    ):
        self.bridge = bridge
        self.position_manager = position_manager
        self.sync_interval = sync_interval
        self._running = False

    async def start(self):
        """å¯åŠ¨åŒæ­¥å¾ªç¯"""
        self._running = True
        while self._running:
            try:
                await self.sync()
            except Exception as e:
                logger.error(f"Sync failed: {e}")
            await asyncio.sleep(self.sync_interval)

    async def sync(self):
        """æ‰§è¡Œä¸€æ¬¡åŒæ­¥"""
        # 1. è·å–äº¤æ˜“æ‰€ä»“ä½
        exchange_positions = await self.bridge.sync_positions()

        # 2. è·å–æœ¬åœ°ä»“ä½
        local_positions = self.position_manager.get_all_positions()

        # 3. å¯¹æ¯”å¹¶å¤„ç†å·®å¼‚
        for symbol in set(exchange_positions.keys()) | set(local_positions.keys()):
            await self._sync_symbol(symbol, exchange_positions, local_positions)

    async def _sync_symbol(
        self,
        symbol: str,
        exchange_positions: Dict,
        local_positions: Dict,
    ):
        """åŒæ­¥å•ä¸ªå“ç§"""
        exchange_pos = exchange_positions.get(symbol)
        local_pos = local_positions.get(symbol)

        if exchange_pos and not local_pos:
            # äº¤æ˜“æ‰€æœ‰ä»“ä½ï¼Œæœ¬åœ°æ²¡æœ‰ -> æ›´æ–°æœ¬åœ°
            logger.warning(f"Missing local position for {symbol}, syncing")
            self.position_manager.update_position(symbol, exchange_pos)

        elif local_pos and not exchange_pos:
            # æœ¬åœ°æœ‰ä»“ä½ï¼Œäº¤æ˜“æ‰€æ²¡æœ‰ -> å¯èƒ½å·²å¹³ä»“
            logger.warning(f"Position {symbol} closed on exchange")
            self.position_manager.close_position(symbol)

        elif exchange_pos and local_pos:
            # ä¸¤è¾¹éƒ½æœ‰ï¼Œæ£€æŸ¥æ•°é‡æ˜¯å¦ä¸€è‡´
            exchange_amt = Decimal(exchange_pos["amount"])
            local_amt = local_pos["amount"]

            if abs(exchange_amt - local_amt) > Decimal("0.00001"):
                logger.error(f"Position mismatch for {symbol}")
                # ä»¥äº¤æ˜“æ‰€ä¸ºå‡†
                self.position_manager.update_position(symbol, exchange_pos)

    async def on_disconnect(self):
        """å¤„ç†æ–­çº¿"""
        logger.warning("Connector disconnected, entering protection mode")
        self.position_manager.enter_protection_mode()

    async def on_reconnect(self):
        """å¤„ç†é‡è¿"""
        logger.info("Connector reconnected, performing full sync")
        await self.sync()
        self.position_manager.exit_protection_mode()
```

### 6.6 AlgVexController (Strategy V2 é›†æˆ)

> å°† AlgVex ä¿¡å·ç”Ÿæˆé›†æˆåˆ° Hummingbot Strategy V2 æ¡†æ¶

```python
# algvex/core/execution/controllers/algvex_controller.py

from hummingbot.smart_components.controllers.controller_base import ControllerBase
from hummingbot.smart_components.executors.position_executor.data_types import PositionConfig


class AlgVexControllerConfig:
    """AlgVex Controller é…ç½®"""
    trading_pairs: Set[str]
    signal_threshold: float = 0.5
    max_position_per_pair: Decimal = Decimal("0.1")
    leverage: int = 1


class AlgVexController(ControllerBase):
    """
    AlgVex ä¿¡å·æ§åˆ¶å™¨

    å°† AlgVex SignalGenerator é›†æˆåˆ° Hummingbot V2 æ¶æ„

    æ•°æ®æµ:
    SignalGenerator â†’ AlgVexController â†’ PositionExecutor â†’ Connector
    """

    def __init__(
        self,
        config: AlgVexControllerConfig,
        signal_generator: 'SignalGenerator',
    ):
        super().__init__(config)
        self.config = config
        self.signal_generator = signal_generator
        self._latest_signals = {}

    async def update_processed_data(self):
        """
        æ›´æ–°å¤„ç†åçš„æ•°æ®

        æ¯ä¸ª tick è°ƒç”¨ï¼Œè·å–æœ€æ–°çš„ AlgVex ä¿¡å·
        """
        for trading_pair in self.config.trading_pairs:
            try:
                signal = await self.signal_generator.get_signal(trading_pair)
                self._latest_signals[trading_pair] = signal
            except Exception as e:
                self.logger().warning(f"Failed to get signal for {trading_pair}: {e}")

    def determine_executor_actions(self) -> List:
        """
        ç¡®å®šæ‰§è¡Œå™¨åŠ¨ä½œ

        åŸºäº AlgVex ä¿¡å·å†³å®šæ˜¯å¦å¼€ä»“/å¹³ä»“
        """
        actions = []

        for trading_pair, signal in self._latest_signals.items():
            if signal is None:
                continue

            # æ£€æŸ¥ä¿¡å·å¼ºåº¦
            if abs(signal.final_signal) < self.config.signal_threshold:
                continue

            # ç¡®å®šæ–¹å‘
            is_long = signal.final_signal > 0

            # åˆ›å»ºä»“ä½é…ç½®
            position_config = PositionConfig(
                trading_pair=trading_pair,
                side="LONG" if is_long else "SHORT",
                amount=self._calculate_position_size(signal),
                leverage=self.config.leverage,
                stop_loss=Decimal("0.03"),   # 3% æ­¢æŸ
                take_profit=Decimal("0.06"), # 6% æ­¢ç›ˆ
            )

            actions.append({
                "type": "create_position",
                "config": position_config,
                "signal": signal,
            })

        return actions

    def _calculate_position_size(self, signal) -> Decimal:
        """è®¡ç®—ä»“ä½å¤§å°"""
        base_size = self.config.max_position_per_pair
        signal_weight = Decimal(str(abs(signal.final_signal)))
        return base_size * signal_weight
```

### 6.7 äº‹ä»¶å¤„ç†å™¨

```python
# algvex/core/execution/event_handlers.py

from hummingbot.core.event.events import (
    BuyOrderCreatedEvent,
    SellOrderCreatedEvent,
    OrderFilledEvent,
    OrderCancelledEvent,
    MarketOrderFailureEvent,
    FundingPaymentCompletedEvent,
)


class AlgVexEventHandler:
    """
    Hummingbot äº‹ä»¶å¤„ç†å™¨

    äº‹ä»¶ç±»å‹æ˜ å°„:
    - BuyOrderCreatedEvent â†’ order_created trace
    - OrderFilledEvent â†’ order_filled trace, æ›´æ–°ä»“ä½
    - OrderCancelledEvent â†’ order_cancelled trace
    - MarketOrderFailureEvent â†’ order_failed trace, å‘Šè­¦
    - FundingPaymentCompletedEvent â†’ funding_payment trace
    """

    def __init__(self, bridge: HummingbotBridge, trace_writer: 'TraceWriter'):
        self.bridge = bridge
        self.trace_writer = trace_writer

    def register_events(self, connector: ConnectorBase):
        """æ³¨å†Œäº‹ä»¶ç›‘å¬"""
        connector.add_listener(BuyOrderCreatedEvent, self.on_buy_order_created)
        connector.add_listener(SellOrderCreatedEvent, self.on_sell_order_created)
        connector.add_listener(OrderFilledEvent, self.on_order_filled)
        connector.add_listener(OrderCancelledEvent, self.on_order_cancelled)
        connector.add_listener(MarketOrderFailureEvent, self.on_order_failure)
        connector.add_listener(FundingPaymentCompletedEvent, self.on_funding_payment)

    async def on_buy_order_created(self, event: BuyOrderCreatedEvent):
        """ä¹°å•åˆ›å»º"""
        await self._handle_order_created(event, "BUY")

    async def on_sell_order_created(self, event: SellOrderCreatedEvent):
        """å–å•åˆ›å»º"""
        await self._handle_order_created(event, "SELL")

    async def _handle_order_created(self, event, side: str):
        """å¤„ç†è®¢å•åˆ›å»º"""
        trace = {
            "type": "order_created",
            "client_order_id": event.order_id,
            "trading_pair": event.trading_pair,
            "side": side,
            "amount": str(event.amount),
            "price": str(event.price) if event.price else None,
            "order_type": event.type.name,
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }
        self.trace_writer.write(trace)

    async def on_order_filled(self, event: OrderFilledEvent):
        """è®¢å•æˆäº¤"""
        await self.bridge.on_order_filled(event)

    async def on_order_cancelled(self, event: OrderCancelledEvent):
        """è®¢å•å–æ¶ˆ"""
        await self.bridge.on_order_cancelled(event)

    async def on_order_failure(self, event: MarketOrderFailureEvent):
        """è®¢å•å¤±è´¥ - éœ€è¦å‘Šè­¦"""
        trace = {
            "type": "order_failed",
            "order_id": event.order_id,
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }
        self.trace_writer.write(trace)
        # TODO: å‘é€å‘Šè­¦

    async def on_funding_payment(self, event: FundingPaymentCompletedEvent):
        """èµ„é‡‘è´¹ç‡æ”¯ä»˜"""
        trace = {
            "type": "funding_payment",
            "trading_pair": event.trading_pair,
            "amount": str(event.amount),
            "funding_rate": str(event.funding_rate),
            "timestamp": datetime.utcnow().isoformat() + "Z",
        }
        self.trace_writer.write(trace)
```

### 6.8 æ‰§è¡Œå±‚éªŒæ”¶æ ‡å‡†

| éªŒæ”¶é¡¹ | æè¿° | æµ‹è¯•æ–¹æ³• | çŠ¶æ€ |
|--------|------|----------|------|
| HummingbotBridge | ä¿¡å· â†’ è®¢å•è½¬æ¢æ­£ç¡® | å•å…ƒæµ‹è¯• | â¬œ |
| å¹‚ç­‰æ€§ | ç›¸åŒä¿¡å·ç”Ÿæˆç›¸åŒ order_id | é‡å¤è°ƒç”¨æµ‹è¯• | â¬œ |
| InFlightOrder | è®¢å•çŠ¶æ€è¿½è¸ªæ­£ç¡® | é›†æˆæµ‹è¯• | â¬œ |
| çŠ¶æ€åŒæ­¥ | ä»“ä½å¯¹è´¦æ— å·®å¼‚ | å¯¹è´¦æµ‹è¯• | â¬œ |
| äº‹ä»¶å¤„ç† | æ‰€æœ‰äº‹ä»¶æ­£ç¡®å†™å…¥ trace | äº‹ä»¶æ¨¡æ‹Ÿæµ‹è¯• | â¬œ |
| AlgVexController | V2 ç­–ç•¥é›†æˆæ­£å¸¸ | é›†æˆæµ‹è¯• | â¬œ |
| æ–­çº¿æ¢å¤ | æ–­çº¿åèƒ½æ­£ç¡®æ¢å¤çŠ¶æ€ | æ–­çº¿æ¨¡æ‹Ÿæµ‹è¯• | â¬œ |
| Paper Trading | æ¨¡æ‹Ÿäº¤æ˜“éªŒè¯é€šè¿‡ | 24h æ¨¡æ‹Ÿè¿è¡Œ | â¬œ |

---

## 7. é£æ§å±‚

> âœ… **MVPåŒ…å«** - ä¸‰å±‚é£æ§(é¢„äº¤æ˜“/äº¤æ˜“ä¸­/äº‹å)ä¸ºæ ¸å¿ƒï¼Œ**ä¸å¯ç²¾ç®€**ã€‚
> ğŸ“ **å…³é”®** - é£æ§æ˜¯ç³»ç»Ÿç¨³å®šæ€§çš„å…³é”®ä¿éšœï¼Œå¿…é¡»å®Œæ•´å®ç°ã€‚

### 7.1 å¤šå±‚é£æ§ä½“ç³»

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                           é£æ§å±‚çº§ç»“æ„                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                         â”‚
â”‚  Level 1: é¢„äº¤æ˜“é£æ§ (Pre-Trade)                                        â”‚
â”‚  â”œâ”€ æ æ†æ£€æŸ¥: leverage <= max_leverage                                  â”‚
â”‚  â”œâ”€ ä»“ä½ä»·å€¼æ£€æŸ¥: position_value <= max_position_value                  â”‚
â”‚  â”œâ”€ æ€»æ•å£æ£€æŸ¥: total_exposure <= max_total_exposure                    â”‚
â”‚  â”œâ”€ æŒä»“æ•°é‡æ£€æŸ¥: positions_count <= max_positions                      â”‚
â”‚  â”œâ”€ æ—¥äºæŸæ£€æŸ¥: daily_pnl > -max_daily_loss                            â”‚
â”‚  â””â”€ é»‘åå•æ£€æŸ¥: symbol not in blocked_symbols                          â”‚
â”‚                                                                         â”‚
â”‚  Level 2: äº¤æ˜“ä¸­é£æ§ (In-Trade)                                         â”‚
â”‚  â”œâ”€ æ­¢æŸè®¾ç½®: é»˜è®¤ 3% (å¯åŸºäºATRåŠ¨æ€è°ƒæ•´)                               â”‚
â”‚  â”œâ”€ æ­¢ç›ˆè®¾ç½®: åŸºäºé£é™©æ”¶ç›Šæ¯” 1.5:1                                       â”‚
â”‚  â”œâ”€ ç§»åŠ¨æ­¢æŸ: è·Ÿè¸ªä»·æ ¼ 2%                                               â”‚
â”‚  â””â”€ èµ„é‡‘è´¹ç‡ç›‘æ§: funding_rate > threshold æ—¶é¢„è­¦                       â”‚
â”‚                                                                         â”‚
â”‚  Level 3: äº‹åé£æ§ (Post-Trade)                                         â”‚
â”‚  â”œâ”€ å›æ’¤ç›‘æ§: max_drawdown > 15% æ—¶ç†”æ–­                                 â”‚
â”‚  â”œâ”€ æ—¥äºæŸé™åˆ¶: daily_loss > 5% æ—¶åœæ­¢äº¤æ˜“                              â”‚
â”‚  â”œâ”€ å‘¨äºæŸé™åˆ¶: weekly_loss > 10% æ—¶æš‚åœä¸€å¤©                            â”‚
â”‚  â””â”€ å¼‚å¸¸æ£€æµ‹: å¤§é¢äºæŸã€é¢‘ç¹äº¤æ˜“ç­‰                                       â”‚
â”‚                                                                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 7.2 RiskManager

```python
from algvex.core.execution import RiskManager, RiskConfig

config = RiskConfig(
    max_position_value=10000.0,     # å•ä»“æœ€å¤§ä»·å€¼ $10k
    max_total_exposure=50000.0,     # æ€»æ•å£ä¸Šé™ $50k
    max_positions=10,                # æœ€å¤§æŒä»“æ•° 10ä¸ª
    max_leverage=10,                 # æœ€å¤§æ æ† 10x
    max_daily_loss=0.05,            # æ—¥æœ€å¤§äºæŸ 5%
    max_weekly_loss=0.10,           # å‘¨æœ€å¤§äºæŸ 10%
    max_drawdown=0.15,              # æœ€å¤§å›æ’¤ 15%
    max_single_trade_risk=0.02,     # å•ç¬”æœ€å¤§é£é™© 2%
    min_risk_reward_ratio=1.5,      # æœ€å°é£é™©æ”¶ç›Šæ¯” 1.5
    default_stop_loss=0.03,         # é»˜è®¤æ­¢æŸ 3%
    trailing_stop=0.02,             # ç§»åŠ¨æ­¢æŸ 2%
    max_funding_rate=0.001,         # æœ€å¤§èµ„é‡‘è´¹ç‡ 0.1%
)

risk_manager = RiskManager(config)
```

### 7.3 PositionManager

```python
from algvex.core.execution import PositionManager, RebalanceMethod

pm = PositionManager(
    total_capital=100000,
    max_positions=10,
    min_position_weight=0.05,
    max_position_weight=0.25,
    rebalance_threshold=0.05,
)

targets = pm.calculate_targets(signals=signals, method=RebalanceMethod.SIGNAL_WEIGHT)
orders = pm.generate_rebalance_orders(current_prices)
```

---

## 8. æŠ€æœ¯æ ˆ

> âœ… **MVPåŒ…å«** - æ ¸å¿ƒæŠ€æœ¯æ ˆå¿…é¡»ç¡®å®šï¼Œç‰ˆæœ¬é”å®šã€‚
> ğŸ“ **MVPç²¾ç®€** - torchä¸ºå¯é€‰ï¼ŒMVPä»…ç”¨LightGBMï¼›å‰ç«¯å¯Phase 2å†ç²¾ç»†æ‰“ç£¨ã€‚

### 8.1 åç«¯

```yaml
æ ¸å¿ƒè¯­è¨€: Python 3.11+

é‡åŒ–å¼•æ“:
  - qlib: 0.9.7              # Microsoft é‡åŒ–æ¡†æ¶
  - hummingbot: 2.11.0       # æ‰§è¡Œå¼•æ“
  - ccxt: 4.4+               # äº¤æ˜“æ‰€API

Webæ¡†æ¶:
  - fastapi: 0.100+
  - uvicorn: 0.23+
  - websockets: 11.0+

æ•°æ®åº“:
  - sqlalchemy: 2.0+
  - alembic: 1.12+
  - asyncpg: 0.28+

ä»»åŠ¡é˜Ÿåˆ—:
  - celery: 5.3+
  - redis: 4.6+

æ•°æ®å¤„ç†:
  - pandas: 2.0+
  - numpy: 1.24+
  - pyarrow: 13.0+

MLæ¡†æ¶:
  - lightgbm: 4.0+
  - xgboost: 2.0+
  - torch: 2.0+ (å¯é€‰)
```

### 8.2 å‰ç«¯

```yaml
æ¡†æ¶:
  - react: 18+
  - typescript: 5.0+
  - vite: 5.0+

UIç»„ä»¶:
  - tailwindcss: 3.4+
  - shadcn/ui: latest

å›¾è¡¨:
  - lightweight-charts: 4.0+    # TradingView Kçº¿
  - recharts: 2.10+

çŠ¶æ€ç®¡ç†:
  - zustand: 4.4+

æ•°æ®è·å–:
  - axios: 1.6+
  - @tanstack/react-query: 5.0+
  - socket.io-client: 4.7+
```

### 8.3 åŸºç¡€è®¾æ–½

```yaml
æ•°æ®åº“:
  - PostgreSQL 15 + TimescaleDB 2.12
  - Redis 7

WebæœåŠ¡å™¨:
  - Nginx 1.25+

CDN/DNS:
  - Cloudflare

ç›‘æ§:
  - Prometheus + Grafana
  - Sentry
```

---

## 9. ç›®å½•ç»“æ„

> âœ… **MVPåŒ…å«** - ç›®å½•ç»“æ„ä¸ºå‚è€ƒï¼Œå¯æ ¹æ®å®é™…éœ€æ±‚è°ƒæ•´ã€‚
> ğŸ“ **MVPç²¾ç®€** - ä»…éœ€production/å’Œcore/ç›®å½•ï¼Œresearch/ç›®å½•å¯Phase 2å»ºç«‹ã€‚

```
algvex/
â”œâ”€â”€ core/                           # æ ¸å¿ƒå¼•æ“
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ engine.py                   # AlgVexä¸»å¼•æ“
â”‚   â”œâ”€â”€ data/                       # æ•°æ®å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ collector.py            # å¸å®‰æ•°æ®é‡‡é›†
â”‚   â”‚   â”œâ”€â”€ handler.py              # Qlibæ ¼å¼è½¬æ¢
â”‚   â”‚   â”œâ”€â”€ validator.py            # æ•°æ®éªŒè¯
â”‚   â”‚   â”œâ”€â”€ realtime.py             # WebSocketå®æ—¶æ•°æ®
â”‚   â”‚   â””â”€â”€ multi_source_manager.py # å¤šæ•°æ®æºç®¡ç†
â”‚   â”œâ”€â”€ factor/                     # å› å­å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ engine.py               # å› å­è®¡ç®—å¼•æ“
â”‚   â”œâ”€â”€ model/                      # æ¨¡å‹å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ qlib_models.py          # Qlibæ¨¡å‹é›†æˆ (v2.0.0æ–°å¢)
â”‚   â”‚   â””â”€â”€ trainer.py              # MLæ¨¡å‹è®­ç»ƒ
â”‚   â”œâ”€â”€ backtest/                   # å›æµ‹å±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ engine.py               # æ°¸ç»­åˆçº¦å›æµ‹
â”‚   â”œâ”€â”€ execution/                  # æ‰§è¡Œå±‚
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ exchange_connectors.py  # å¤šäº¤æ˜“æ‰€è¿æ¥å™¨ (v2.0.0æ–°å¢)
â”‚   â”‚   â”œâ”€â”€ executors.py            # æ‰§è¡Œç­–ç•¥ TWAP/VWAP/Grid (v2.0.0æ–°å¢)
â”‚   â”‚   â”œâ”€â”€ hummingbot_bridge.py    # Hummingbotæ¡¥æ¥ (v2.0.0é‡å†™)
â”‚   â”‚   â”œâ”€â”€ risk_manager.py         # é£æ§ç®¡ç†
â”‚   â”‚   â””â”€â”€ position_manager.py     # ä»“ä½ç®¡ç†
â”‚   â””â”€â”€ strategy/                   # ç­–ç•¥å±‚
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ signal.py               # ä¿¡å·ç”Ÿæˆ
â”œâ”€â”€ api/                            # APIå±‚
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                     # FastAPIå…¥å£
â”‚   â”œâ”€â”€ config.py                   # é…ç½®
â”‚   â”œâ”€â”€ database.py                 # æ•°æ®åº“è¿æ¥
â”‚   â””â”€â”€ routers/                    # APIè·¯ç”±
â”‚       â”œâ”€â”€ auth.py
â”‚       â”œâ”€â”€ users.py
â”‚       â”œâ”€â”€ strategies.py
â”‚       â”œâ”€â”€ backtests.py
â”‚       â”œâ”€â”€ trades.py
â”‚       â””â”€â”€ market.py
â”œâ”€â”€ web/                            # å‰ç«¯
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ ...
â”œâ”€â”€ scripts/                        # è„šæœ¬
â”‚   â”œâ”€â”€ init_server.sh
â”‚   â”œâ”€â”€ setup.sh
â”‚   â””â”€â”€ deploy.sh
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

---

## 10. éƒ¨ç½²æ–¹æ¡ˆ

> âœ… **MVPåŒ…å«** - ç›´æ¥ Python éƒ¨ç½²å³å¯ï¼Œå•å®ä¾‹è¿è¡Œã€‚
> ğŸ“ **MVPç²¾ç®€** - ä½¿ç”¨æœ€ä½é…ç½®(4æ ¸8G)å¯åŠ¨ï¼Œæ— éœ€é«˜å¯ç”¨æ¶æ„ã€‚

### 10.1 æœåŠ¡å™¨è¦æ±‚

```yaml
æœ€ä½é…ç½®:
  CPU: 4æ ¸
  RAM: 8GB
  SSD: 100GB
  å¸¦å®½: 100Mbps

æ¨èé…ç½®:
  CPU: 8æ ¸
  RAM: 16GB
  SSD: 500GB
  å¸¦å®½: 1Gbps

æ“ä½œç³»ç»Ÿ: Ubuntu 22.04 LTS / Windows 10+
Python: 3.10+
```

### 10.2 ç›´æ¥éƒ¨ç½² (æ¨è)

**ä¼˜ç‚¹**: ç®€å•ã€è°ƒè¯•æ–¹ä¾¿ã€èµ„æºå¼€é”€å°ã€é€‚åˆå•å®ä¾‹åœºæ™¯

```bash
# 1. å…‹éš†é¡¹ç›®
git clone https://github.com/your-org/algvex.git
cd algvex

# 2. åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# 3. å®‰è£…ä¾èµ–
pip install -r requirements.txt

# 4. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶

# 5. è¿è¡Œå›æµ‹
python scripts/run_backtest.py --symbols BTCUSDT,ETHUSDT

# 6. è¿è¡Œ API æœåŠ¡ (å¯é€‰)
uvicorn api.main:app --host 0.0.0.0 --port 8000

# 7. è¿è¡Œå®šæ—¶ä»»åŠ¡ (å¯é€‰)
python scripts/daily_alignment.py
```

### 10.3 åå°è¿è¡Œ (Linux)

```bash
# ä½¿ç”¨ nohup
nohup python scripts/run_backtest.py > backtest.log 2>&1 &

# ä½¿ç”¨ screen
screen -S algvex
python scripts/run_backtest.py
# Ctrl+A, D åˆ†ç¦»

# ä½¿ç”¨ systemd (æ¨èç”Ÿäº§ç¯å¢ƒ)
# åˆ›å»º /etc/systemd/system/algvex.service
```

### 10.4 systemd æœåŠ¡é…ç½® (å¯é€‰)

```ini
# /etc/systemd/system/algvex.service
[Unit]
Description=AlgVex Quantitative Trading Service
After=network.target

[Service]
Type=simple
User=algvex
WorkingDirectory=/home/algvex/algvex
Environment="PYTHONHASHSEED=42"
ExecStart=/home/algvex/algvex/venv/bin/python scripts/run_backtest.py
Restart=always
RestartSec=10

[Install]
WantedBy=multi-user.target
```

```bash
# å¯ç”¨æœåŠ¡
sudo systemctl enable algvex
sudo systemctl start algvex
sudo systemctl status algvex
```

### 10.5 æ•°æ®åº“é…ç½® (å¯é€‰)

å¦‚æœéœ€è¦æŒä¹…åŒ–å­˜å‚¨ï¼Œå¯ä»¥æœ¬åœ°å®‰è£… PostgreSQL å’Œ Redisï¼š

```bash
# Ubuntu
sudo apt install postgresql redis-server

# åˆ›å»ºæ•°æ®åº“
sudo -u postgres createdb algvex
sudo -u postgres createuser algvex

# é…ç½® .env
DATABASE_URL=postgresql://algvex:password@localhost/algvex
REDIS_URL=redis://localhost:6379
```

---

## 11. P0 éªŒæ”¶æ ‡å‡† (ä¸Šçº¿å‰å¿…é¡»å®Œæˆ)

> âœ… **MVPå…³é”®** - P0éªŒæ”¶æ ‡å‡†æ˜¯MVPä¸Šçº¿çš„**ç¡¬æ€§é—¨æ§›**ï¼Œæ¯ä¸€é¡¹éƒ½ä¸å¯è·³è¿‡ã€‚
> ğŸ“ **æ‰§è¡Œè¦æ±‚** - æ¯é¡¹å¿…é¡»å¸¦å•å…ƒæµ‹è¯• + Replayå¯¹é½æµ‹è¯•ï¼Œå¦åˆ™ä¸å¾—ä¸Šçº¿ã€‚

> **å…³é”®åŸåˆ™**: ä»¥ä¸‹ 4 é¡¹ P0 æ ‡å‡†æ˜¯ç³»ç»Ÿä»"çœ‹èµ·æ¥ä¸“ä¸š"å˜æˆ"çœŸçš„ä¸“ä¸šã€å¯é•¿æœŸèµšé’±"çš„å…³é”®ã€‚æ¯é¡¹å¿…é¡»å¸¦å•å…ƒæµ‹è¯•/å›æ”¾å¯¹é½æµ‹è¯•ã€‚

### 11.1 P0-1: æ•°æ®å¯è§æ€§ä¸æ³„éœ²é˜²æŠ¤

**æ ¸å¿ƒé—®é¢˜**: å›æµ‹æ—¶å¿…é¡»ç¡®ä¿æ¨¡å‹åªèƒ½"çœ‹åˆ°"å½“æ—¶çœŸå®å¯è·å¾—çš„æ•°æ®ï¼Œé˜²æ­¢æœªæ¥æ•°æ®æ³„éœ²ã€‚

**âš ï¸ ç‰¹åˆ«æ³¨æ„: Barèšåˆç‰¹å¾çš„å¯è§æ€§é™·é˜±**

> CVDã€taker_deltaã€OIå˜åŒ–ã€basis ç­‰"barèšåˆç‰¹å¾"å®¹æ˜“äº§ç”Ÿå¾®å¦™çš„æœªæ¥æ³„éœ²ï¼š
> - 1h bar çš„ CVD åªæœ‰åœ¨ bar æ”¶ç›˜åæ‰å®Œæ•´å¯è§
> - å¦‚æœæŠŠå®ƒå½“ä½œ"å®æ—¶æµ"åˆå¹¶ï¼Œä¼šæŠŠ"æœªæ¥ä¸€å°æ—¶çš„æˆäº¤"æ··è¿›å½“å‰ç‰¹å¾
> - **è§„åˆ™**: æ‰€æœ‰ bar èšåˆç‰¹å¾çš„å¯è§æ—¶é—´ = bar_close_time + publication_delay

```python
# æ•°æ®å¯è§æ€§æ£€æŸ¥å™¨
class DataVisibilityChecker:
    """ç¡®ä¿æ¯ä¸ªç‰¹å¾åœ¨ä¿¡å·ç”Ÿæˆæ—¶åˆ»æ˜¯çœŸå®å¯è§çš„"""

    # ==================== å…³é”®: åŒºåˆ†å®æ—¶æ•°æ® vs Barèšåˆæ•°æ® ====================

    # å®æ—¶æ•°æ®æºå»¶è¿Ÿ (å¯åœ¨barå†…éƒ¨æ›´æ–°)
    REALTIME_DELAYS = {
        "binance_mark_price": timedelta(seconds=1),    # æ ‡è®°ä»·æ ¼å®æ—¶
        "binance_last_price": timedelta(seconds=1),    # æœ€æ–°æˆäº¤å®æ—¶
    }

    # Barèšåˆæ•°æ®å»¶è¿Ÿ (åªæœ‰baræ”¶ç›˜åæ‰å®Œæ•´å¯è§ï¼)
    BAR_AGGREGATED_DELAYS = {
        "binance_ohlcv": "bar_close",           # Kçº¿æ•°æ® = baræ”¶ç›˜åå¯è§
        "binance_taker_volume": "bar_close",    # Takeræˆäº¤é‡ = baræ”¶ç›˜åå¯è§ (CVDåŸºäºæ­¤ï¼)
        "binance_oi_change": "bar_close + 5min", # OIå˜åŒ– = baræ”¶ç›˜ + 5åˆ†é’Ÿå»¶è¿Ÿ
        "binance_ls_ratio": "bar_close + 5min", # å¤šç©ºæ¯” = baræ”¶ç›˜ + 5åˆ†é’Ÿå»¶è¿Ÿ
    }

    # å®šæ—¶å‘å¸ƒæ•°æ®å»¶è¿Ÿ
    SCHEDULED_DELAYS = {
        "binance_funding_rate": timedelta(hours=8),  # æ¯8å°æ—¶ç»“ç®—åå¯è§
        "defilama_onchain": timedelta(hours=1),      # çº¦1å°æ—¶å»¶è¿Ÿ
        "deribit_options": timedelta(minutes=5),     # çº¦5åˆ†é’Ÿå»¶è¿Ÿ
        "fear_greed_index": timedelta(hours=24),     # æ¯æ—¥æ›´æ–°
        "macro_dxy": timedelta(hours=1),             # çº¦1å°æ—¶å»¶è¿Ÿ
    }

    def get_visible_time(
        self,
        data_source: str,
        bar_freq: str,
        bar_close_time: datetime,
        event_time: Optional[datetime] = None,
        scheduled_time: Optional[datetime] = None
    ) -> datetime:
        """
        è®¡ç®—ç‰¹å¾çš„å¯è§æ—¶é—´ - è¿™æ˜¯é˜²æ³„éœ²çš„æ ¸å¿ƒï¼

        å…³é”®åŒºåˆ†:
        - realtime: åŸºäº event_time (æ•°æ®äº§ç”Ÿæ—¶é—´)
        - bar_agg: åŸºäº bar_close_time (baræ”¶ç›˜æ—¶é—´)
        - scheduled: åŸºäº scheduled_time (å®šæ—¶å‘å¸ƒæ—¶é—´)
        """

        if data_source in self.REALTIME_DELAYS:
            # å®æ—¶æ•°æ®: å¯è§æ—¶é—´ = event_time + å›ºå®šå»¶è¿Ÿ
            # å…³é”®ä¿®å¤: ä¸èƒ½ç”¨bar_close_time! å¿…é¡»ç”¨event_time!
            base_time = event_time if event_time else bar_close_time
            return base_time + self.REALTIME_DELAYS[data_source]

        elif data_source in self.BAR_AGGREGATED_DELAYS:
            # Barèšåˆæ•°æ®: å¯è§æ—¶é—´ = bar_close_time + é¢å¤–å»¶è¿Ÿ
            delay_spec = self.BAR_AGGREGATED_DELAYS[data_source]
            if delay_spec == "bar_close":
                return bar_close_time  # baræ”¶ç›˜å³å¯è§
            elif "+" in delay_spec:
                extra_delay = self._parse_delay(delay_spec.split("+")[1].strip())
                return bar_close_time + extra_delay

        elif data_source in self.SCHEDULED_DELAYS:
            # å®šæ—¶æ•°æ®: åŸºäº scheduled_time
            base_time = scheduled_time if scheduled_time else bar_close_time
            return base_time + self.SCHEDULED_DELAYS[data_source]

        else:
            # æœªçŸ¥æ•°æ®æºï¼Œä¿å®ˆå¤„ç† (24å°æ—¶å»¶è¿Ÿ)
            return bar_close_time + timedelta(hours=24)

# ==================== Barèšåˆç‰¹å¾çš„æ­£ç¡®åˆå¹¶æ–¹å¼ ====================

def safe_merge_bar_features(signal_df, feature_df, bar_freq: str):
    """
    å®‰å…¨åˆå¹¶ Bar èšåˆç‰¹å¾ - é˜²æ­¢ CVD ç­‰ç‰¹å¾æ³„éœ²

    å…³é”®è§„åˆ™:
    - signal_time å®šä¹‰ä¸º bar_close_time (UTC)
    - ç‰¹å¾åªèƒ½ä½¿ç”¨ <= signal_time çš„å·²æ”¶ç›˜ bar çš„æ•°æ®
    - ä¾‹å¦‚: 1h ä¿¡å·åœ¨ 12:00 ç”Ÿæˆæ—¶ï¼Œåªèƒ½ä½¿ç”¨ 11:00 æ”¶ç›˜çš„ bar çš„ CVD
    """
    # ç¡®ä¿ç‰¹å¾æ—¶é—´æˆ³æ˜¯ bar_close_time
    # ä¿¡å·æ—¶é—´ = å½“å‰ bar æ”¶ç›˜æ—¶é—´
    # å¯ç”¨ç‰¹å¾ = ä¸Šä¸€ä¸ª bar çš„æ•°æ® (å› ä¸ºå½“å‰ bar è¿˜æ²¡æ”¶ç›˜)

    bar_duration = _parse_bar_freq(bar_freq)

    # æ ¸å¿ƒ: ä¿¡å·æ—¶åˆ»åªèƒ½çœ‹åˆ° "å‰ä¸€ä¸ªbar" çš„èšåˆæ•°æ®
    # å› ä¸º "å½“å‰bar" è¿˜åœ¨è¿›è¡Œä¸­ï¼ŒCVD ä¸å®Œæ•´
    return pd.merge_asof(
        signal_df.sort_index(),
        feature_df.sort_index(),
        left_index=True,
        right_index=True,
        direction='backward',
        tolerance=bar_duration  # åªåŒ¹é…æœ€è¿‘ä¸€ä¸ª bar
    )

# CVD ç‰¹å¾çš„æ­£ç¡®è®¡ç®—æ–¹å¼
def calculate_cvd_safe(df: pd.DataFrame, bar_freq: str = "1h") -> pd.Series:
    """
    è®¡ç®— CVD (ç´¯è®¡æˆäº¤é‡å·®) - ç¡®ä¿ä¸æ³„éœ²

    é‡è¦: CVD = cumsum(taker_buy_volume - taker_sell_volume)
    - taker_buy_volume å’Œ taker_sell_volume æ˜¯ bar èšåˆæ•°æ®
    - åªæœ‰ bar æ”¶ç›˜åæ‰çŸ¥é“è¿™ä¸ª bar çš„å®Œæ•´æˆäº¤é‡
    - å› æ­¤ CVD(T) åªèƒ½åœ¨ T bar æ”¶ç›˜åæ‰èƒ½è®¡ç®—
    """
    cvd = (df['taker_buy_volume'] - df['taker_sell_volume']).cumsum()

    # æ ‡è®°: è¿™ä¸ª CVD çš„æ—¶é—´æˆ³æ˜¯ bar_close_time
    # åœ¨ä¿¡å·ç”Ÿæˆæ—¶ï¼Œåªèƒ½ä½¿ç”¨ <= å½“å‰æ—¶é—´ - bar_duration çš„ CVD
    cvd.name = 'cvd'
    cvd.attrs['visibility'] = 'bar_close'
    cvd.attrs['bar_freq'] = bar_freq

    return cvd
```

**éªŒè¯æµ‹è¯•**:
```python
def test_no_future_data_leakage():
    """æ³„éœ²æ£€æµ‹æµ‹è¯• - å¿…é¡»é€šè¿‡"""
    # 1. å‡†å¤‡æµ‹è¯•æ•°æ®ï¼šT æ—¶åˆ»çš„ä¿¡å· (å‡è®¾ 1h bar)
    signal_time = datetime(2024, 6, 15, 12, 0, 0, tzinfo=timezone.utc)

    # 2. éªŒè¯æ‰€æœ‰ bar èšåˆç‰¹å¾ä½¿ç”¨çš„æ˜¯ "ä¸Šä¸€ä¸ªbar" çš„æ•°æ®
    for feature in bar_aggregated_features:
        # CVD ç­‰ç‰¹å¾åº”è¯¥ä½¿ç”¨ 11:00 æ”¶ç›˜çš„ bar çš„æ•°æ®
        assert feature.bar_close_time <= signal_time - timedelta(hours=1), \
            f"Barèšåˆç‰¹å¾æ³„éœ²! {feature.name} ä½¿ç”¨äº†æœªæ”¶ç›˜barçš„æ•°æ®"

    # 3. éªŒè¯å®æ—¶ç‰¹å¾çš„å»¶è¿Ÿ
    for feature in realtime_features:
        assert feature.timestamp + REALTIME_DELAYS[feature.source] <= signal_time, \
            f"å®æ—¶ç‰¹å¾æ³„éœ²: {feature.name}"

    # 4. éšæœºæŠ½æ ·å›æ”¾éªŒè¯ (æ›´ä¸¥æ ¼)
    for _ in range(1000):
        random_time = get_random_historical_time()
        features = get_features_at_time(random_time)
        for f in features:
            visible_time = checker.get_visible_time(f.source, f.bar_freq, f.bar_close_time)
            assert visible_time <= random_time, \
                f"å‘ç°æ³„éœ²: {f.name} visible_time={visible_time} > signal_time={random_time}"

def test_cvd_visibility():
    """CVD å¯è§æ€§ä¸“é¡¹æµ‹è¯•"""
    # å‡è®¾ 1h barï¼Œä¿¡å·åœ¨ 12:00 ç”Ÿæˆ
    signal_time = datetime(2024, 6, 15, 12, 0, 0, tzinfo=timezone.utc)

    # CVD åº”è¯¥ä½¿ç”¨ 11:00 æ”¶ç›˜ bar çš„ç´¯è®¡å€¼
    cvd_data = get_cvd_at_time(signal_time, bar_freq="1h")

    # æœ€æ–°å¯ç”¨çš„ CVD åº”è¯¥æ˜¯ 11:00 bar çš„å€¼
    assert cvd_data.index.max() == datetime(2024, 6, 15, 11, 0, 0, tzinfo=timezone.utc), \
        "CVD ä½¿ç”¨äº†å½“å‰æœªæ”¶ç›˜ bar çš„æ•°æ®ï¼Œå­˜åœ¨æ³„éœ²ï¼"
```

---

### 11.2 P0-2: æ°¸ç»­åˆçº¦ä»·æ ¼è¯­ä¹‰ç»Ÿä¸€

**æ ¸å¿ƒé—®é¢˜**: æ°¸ç»­åˆçº¦æœ‰å¤šç§ä»·æ ¼ (mark/index/last/close)ï¼Œå¿…é¡»æ˜ç¡®æ¯ä¸ªåœºæ™¯ä½¿ç”¨å“ªç§ä»·æ ¼ã€‚

```python
class PriceSemantics:
    """ä»·æ ¼è¯­ä¹‰ç»Ÿä¸€å™¨ - æ°¸ç»­åˆçº¦ä¸“ç”¨"""

    # ä»·æ ¼ç±»å‹å®šä¹‰
    PRICE_TYPES = {
        "mark_price": "æ ‡è®°ä»·æ ¼ - ç”¨äºè®¡ç®—ç›ˆäºå’Œå¼ºå¹³",
        "index_price": "æŒ‡æ•°ä»·æ ¼ - å¤šäº¤æ˜“æ‰€åŠ æƒ",
        "last_price": "æœ€æ–°æˆäº¤ä»· - å®é™…äº¤æ˜“ä»·æ ¼",
        "close_price": "æ”¶ç›˜ä»· - Kçº¿æ”¶ç›˜",
    }

    # åœºæ™¯-ä»·æ ¼æ˜ å°„ (å¿…é¡»ä¸¥æ ¼éµå®ˆ)
    PRICE_USAGE_MAP = {
        "pnl_calculation": "mark_price",      # PnLè®¡ç®—ç”¨mark
        "liquidation_check": "mark_price",    # çˆ†ä»“æ£€æµ‹ç”¨mark
        "entry_exit_signal": "close_price",   # å…¥åœºå‡ºåœºä¿¡å·ç”¨close
        "order_execution": "last_price",      # ä¸‹å•æ—¶ç”¨last
        "backtest_fill": "close_price",       # å›æµ‹æˆäº¤ç”¨close
        "funding_settlement": "mark_price",   # èµ„é‡‘è´¹ç‡ç»“ç®—ç”¨mark
    }

    def get_price(self, scenario: str, data: dict) -> float:
        """æ ¹æ®åœºæ™¯è·å–æ­£ç¡®çš„ä»·æ ¼"""
        price_type = self.PRICE_USAGE_MAP[scenario]
        return data[price_type]

# èµ„é‡‘è´¹ç‡æ—¶é—´æˆ³å¯¹é½
class FundingRateHandler:
    """èµ„é‡‘è´¹ç‡å¤„ç†å™¨ - å¿…é¡»ç²¾ç¡®å¯¹é½ç»“ç®—æ—¶é—´"""

    SETTLEMENT_HOURS = [0, 8, 16]  # UTC ç»“ç®—æ—¶é—´

    def get_applicable_funding_rate(self, position_time: datetime) -> float:
        """è·å–é€‚ç”¨äºå½“å‰æŒä»“çš„èµ„é‡‘è´¹ç‡"""
        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªç»“ç®—æ—¶é—´
        next_settlement = self._next_settlement_time(position_time)

        # æŒä»“å¿…é¡»è·¨è¶Šç»“ç®—æ—¶é—´æ‰éœ€æ”¯ä»˜èµ„é‡‘è´¹
        if self.position_held_through(next_settlement):
            return self._get_rate_at_settlement(next_settlement)
        return 0.0

    def validate_backtest_funding(self, backtest_results):
        """éªŒè¯å›æµ‹èµ„é‡‘è´¹ç‡è®¡ç®—æ˜¯å¦æ­£ç¡®"""
        for trade in backtest_results.trades:
            expected_funding = self._calculate_expected_funding(trade)
            actual_funding = trade.funding_paid
            assert abs(expected_funding - actual_funding) < 1e-6, \
                f"èµ„é‡‘è´¹ç‡è®¡ç®—é”™è¯¯: expected={expected_funding}, actual={actual_funding}"
```

**ä»·æ ¼ä¸€è‡´æ€§æµ‹è¯•**:
```python
def test_price_semantics_consistency():
    """ä»·æ ¼è¯­ä¹‰ä¸€è‡´æ€§æµ‹è¯•"""
    # 1. éªŒè¯å›æµ‹å’Œå®ç›˜ä½¿ç”¨ç›¸åŒçš„ä»·æ ¼è¯­ä¹‰
    backtest_engine = CryptoPerpetualBacktest()
    live_engine = HummingbotBridge()

    for scenario in PriceSemantics.PRICE_USAGE_MAP:
        bt_price_type = backtest_engine.get_price_type(scenario)
        live_price_type = live_engine.get_price_type(scenario)
        assert bt_price_type == live_price_type, \
            f"ä»·æ ¼è¯­ä¹‰ä¸ä¸€è‡´: {scenario} å›æµ‹ç”¨ {bt_price_type}, å®ç›˜ç”¨ {live_price_type}"
```

---

### 11.3 P0-3: è®¢å•/æŒä»“å¼ºä¸€è‡´æ€§

**æ ¸å¿ƒé—®é¢˜**: åˆ†å¸ƒå¼ç³»ç»Ÿä¸­è®¢å•å’ŒæŒä»“çŠ¶æ€å¿…é¡»å¼ºä¸€è‡´ï¼Œé˜²æ­¢é‡å¤ä¸‹å•å’ŒçŠ¶æ€ä¸åŒæ­¥ã€‚

```python
class OrderConsistencyManager:
    """è®¢å•ä¸€è‡´æ€§ç®¡ç†å™¨"""

    def __init__(self):
        self.order_cache = {}  # client_order_id -> order_state
        self.position_cache = {}  # symbol -> position

    # P0-3.1: å®¢æˆ·ç«¯è®¢å•IDå¹‚ç­‰æ€§
    def create_order(self, signal: Signal) -> Order:
        """åˆ›å»ºè®¢å• - å¿…é¡»ä½¿ç”¨å¹‚ç­‰çš„ client_order_id"""
        # ç”Ÿæˆç¡®å®šæ€§çš„ client_order_id (åŸºäºä¿¡å·å†…å®¹hash)
        client_order_id = self._generate_idempotent_id(signal)

        # æ£€æŸ¥æ˜¯å¦å·²å¤„ç†è¿‡
        if client_order_id in self.order_cache:
            existing = self.order_cache[client_order_id]
            if existing.status in ["FILLED", "PENDING"]:
                return existing  # å¹‚ç­‰è¿”å›ï¼Œä¸é‡å¤ä¸‹å•

        # æ–°è®¢å•
        order = Order(
            client_order_id=client_order_id,
            symbol=signal.symbol,
            side=signal.side,
            quantity=signal.quantity,
        )
        self.order_cache[client_order_id] = order
        return order

    def _generate_idempotent_id(self, signal: Signal) -> str:
        """ç”Ÿæˆå¹‚ç­‰ID - ç›¸åŒä¿¡å·å¿…é¡»ç”Ÿæˆç›¸åŒID"""
        content = f"{signal.symbol}_{signal.side}_{signal.timestamp}_{signal.score}"
        return hashlib.sha256(content.encode()).hexdigest()[:16]

    # P0-3.2: å®šæœŸå¯¹è´¦
    def reconcile_positions(self):
        """ä¸äº¤æ˜“æ‰€å®šæœŸå¯¹è´¦ - æ¯5åˆ†é’Ÿæ‰§è¡Œ"""
        exchange_positions = self.exchange.get_positions()
        local_positions = self.position_cache

        for symbol in set(exchange_positions.keys()) | set(local_positions.keys()):
            exchange_qty = exchange_positions.get(symbol, {}).get("quantity", 0)
            local_qty = local_positions.get(symbol, {}).get("quantity", 0)

            if abs(exchange_qty - local_qty) > 1e-8:
                self._handle_position_mismatch(symbol, exchange_qty, local_qty)

    def _handle_position_mismatch(self, symbol, exchange_qty, local_qty):
        """å¤„ç†æŒä»“ä¸ä¸€è‡´"""
        logger.error(f"æŒä»“ä¸ä¸€è‡´! {symbol}: äº¤æ˜“æ‰€={exchange_qty}, æœ¬åœ°={local_qty}")

        # ä»¥äº¤æ˜“æ‰€ä¸ºå‡†ï¼Œå¼ºåˆ¶åŒæ­¥
        self.position_cache[symbol]["quantity"] = exchange_qty

        # è§¦å‘å‘Šè­¦
        self.alert_manager.send_critical(
            f"æŒä»“ä¸ä¸€è‡´å·²è‡ªåŠ¨ä¿®å¤: {symbol}"
        )

    # P0-3.3: ç½‘ç»œæ–­å¼€ä¿æŠ¤
    def enter_protection_mode(self):
        """ç½‘ç»œæ–­å¼€æ—¶è¿›å…¥ä¿æŠ¤æ¨¡å¼"""
        logger.warning("ç½‘ç»œæ–­å¼€ï¼Œè¿›å…¥ä¿æŠ¤æ¨¡å¼")

        # 1. åœæ­¢æ–°ä¿¡å·å¤„ç†
        self.signal_processor.pause()

        # 2. ä¸ä¸»åŠ¨å¹³ä»“ (é¿å…é‡è¿åçŠ¶æ€æ··ä¹±)
        # 3. è®°å½•æ–­å¼€æ—¶åˆ»çš„æœ¬åœ°çŠ¶æ€
        self.save_snapshot()

        # 4. é‡è¿åå¼ºåˆ¶å¯¹è´¦
        self.on_reconnect = self.force_reconcile
```

**ä¸€è‡´æ€§æµ‹è¯•**:
```python
def test_order_idempotency():
    """è®¢å•å¹‚ç­‰æ€§æµ‹è¯•"""
    signal = Signal(symbol="BTCUSDT", score=0.8, timestamp=now())

    order1 = manager.create_order(signal)
    order2 = manager.create_order(signal)  # ç›¸åŒä¿¡å·

    assert order1.client_order_id == order2.client_order_id
    assert order1 is order2  # åº”è¯¥è¿”å›åŒä¸€ä¸ªå¯¹è±¡

def test_position_reconciliation():
    """æŒä»“å¯¹è´¦æµ‹è¯•"""
    # æ¨¡æ‹Ÿæœ¬åœ°å’Œäº¤æ˜“æ‰€çŠ¶æ€ä¸ä¸€è‡´
    manager.position_cache["BTCUSDT"] = {"quantity": 1.0}
    mock_exchange.set_position("BTCUSDT", quantity=1.1)  # äº¤æ˜“æ‰€å¤šäº†0.1

    manager.reconcile_positions()

    # åº”è¯¥ä»¥äº¤æ˜“æ‰€ä¸ºå‡†
    assert manager.position_cache["BTCUSDT"]["quantity"] == 1.1
```

---

### 11.4 P0-4: ç ”ç©¶éªŒè¯æ ‡å‡† (Walk-Forward)

**æ ¸å¿ƒé—®é¢˜**: æ—¶åºæ•°æ®ä¸èƒ½éšæœºåˆ‡åˆ†ï¼Œå¿…é¡»ä½¿ç”¨ Walk-Forward éªŒè¯ã€‚

```python
class WalkForwardValidator:
    """Walk-Forward éªŒè¯å™¨ - é˜²æ­¢è¿‡æ‹Ÿåˆ"""

    def __init__(self,
                 train_months: int = 12,
                 test_months: int = 3,
                 min_train_samples: int = 1000):
        self.train_months = train_months
        self.test_months = test_months
        self.min_train_samples = min_train_samples

    def create_folds(self, data: pd.DataFrame) -> List[Tuple[pd.DataFrame, pd.DataFrame]]:
        """åˆ›å»º Walk-Forward æŠ˜å  - ä¸¥ç¦éšæœºåˆ‡åˆ†"""
        folds = []
        start_date = data.index.min()
        end_date = data.index.max()

        current_train_start = start_date

        while True:
            train_end = current_train_start + pd.DateOffset(months=self.train_months)
            test_start = train_end
            test_end = test_start + pd.DateOffset(months=self.test_months)

            if test_end > end_date:
                break

            train_data = data[current_train_start:train_end]
            test_data = data[test_start:test_end]

            # éªŒè¯è®­ç»ƒé›†æ ·æœ¬é‡
            if len(train_data) >= self.min_train_samples:
                folds.append((train_data, test_data))

            # æ»šåŠ¨å‘å‰
            current_train_start += pd.DateOffset(months=self.test_months)

        return folds

    def validate_model(self, model, data: pd.DataFrame) -> dict:
        """æ‰§è¡Œ Walk-Forward éªŒè¯"""
        folds = self.create_folds(data)
        results = []

        for i, (train, test) in enumerate(folds):
            # åœ¨è®­ç»ƒé›†ä¸Šè®­ç»ƒ
            model.fit(train)

            # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼° (å®Œå…¨ Out-of-Sample)
            metrics = model.evaluate(test)
            metrics["fold"] = i
            metrics["train_period"] = f"{train.index.min()} ~ {train.index.max()}"
            metrics["test_period"] = f"{test.index.min()} ~ {test.index.max()}"
            results.append(metrics)

        return self._aggregate_results(results)

# è¿‡æ‹Ÿåˆæ£€æµ‹
class OverfittingDetector:
    """è¿‡æ‹Ÿåˆæ£€æµ‹å™¨"""

    MAX_TRAIN_TEST_GAP = 0.3  # è®­ç»ƒé›†å’Œæµ‹è¯•é›†å¤æ™®æ¯”å·®è·ä¸Šé™

    def check_overfitting(self, train_sharpe: float, test_sharpe: float) -> bool:
        """æ£€æµ‹æ˜¯å¦è¿‡æ‹Ÿåˆ"""
        gap = train_sharpe - test_sharpe

        if gap > self.MAX_TRAIN_TEST_GAP:
            logger.warning(f"ç–‘ä¼¼è¿‡æ‹Ÿåˆ! è®­ç»ƒå¤æ™®={train_sharpe:.2f}, æµ‹è¯•å¤æ™®={test_sharpe:.2f}")
            return True
        return False

    def calculate_deflated_sharpe(self, sharpe: float, num_trials: int) -> float:
        """è®¡ç®— Deflated Sharpe Ratio (è°ƒæ•´åçš„å¤æ™®æ¯”)"""
        # è€ƒè™‘å¤šæ¬¡å°è¯•çš„å½±å“ (é˜²æ­¢æ•°æ®æŒ–æ˜åå·®)
        from scipy import stats

        # ä½¿ç”¨ Bailey-Lopez de Prado å…¬å¼
        expected_max_sharpe = stats.norm.ppf(1 - 1/num_trials)
        deflated = sharpe - expected_max_sharpe
        return max(0, deflated)
```

**éªŒè¯æ ‡å‡†æ£€æŸ¥**:
```python
def test_walk_forward_validation():
    """Walk-Forward éªŒè¯æµ‹è¯•"""
    validator = WalkForwardValidator(train_months=12, test_months=3)

    # ä½¿ç”¨2å¹´æ•°æ®
    data = load_data("2022-01-01", "2024-01-01")
    folds = validator.create_folds(data)

    # åº”è¯¥æœ‰çº¦ 4 ä¸ªæŠ˜å  (24ä¸ªæœˆ / 3ä¸ªæœˆæ­¥é•¿ - åˆå§‹12ä¸ªæœˆè®­ç»ƒ)
    assert len(folds) >= 3

    for train, test in folds:
        # è®­ç»ƒé›†å¿…é¡»åœ¨æµ‹è¯•é›†ä¹‹å‰
        assert train.index.max() < test.index.min()

        # ä¸èƒ½æœ‰é‡å 
        assert len(set(train.index) & set(test.index)) == 0

def test_no_random_split():
    """ç¦æ­¢éšæœºåˆ‡åˆ†æµ‹è¯•"""
    # å¦‚æœä»£ç ä¸­ä½¿ç”¨äº† train_test_split(shuffle=True)ï¼Œæµ‹è¯•åº”è¯¥å¤±è´¥
    with pytest.raises(ValueError, match="ç¦æ­¢éšæœºåˆ‡åˆ†æ—¶åºæ•°æ®"):
        model.split_data(shuffle=True)
```

---

### 11.5 P0-5: æ•°æ®è¡€ç¼˜ä¸å¿«ç…§ (ç ”ç©¶å¯å¤ç°)

**æ ¸å¿ƒé—®é¢˜**: æ²¡æœ‰æ•°æ®è¡€ç¼˜ï¼Œæ— æ³•è¯æ˜æŸæ¬¡æ”¶ç›Šæ¥è‡ªå“ªä»½æ•°æ®ä¸å“ªä»½å› å­ï¼Œçº¿ä¸Šå´©äº†ä¹Ÿæ— æ³•å›æ»šã€‚

```python
class DataLineageManager:
    """æ•°æ®è¡€ç¼˜ç®¡ç†å™¨ - ç¡®ä¿å®éªŒå¯å¤ç°"""

    def create_snapshot(self,
                       symbols: List[str],
                       start_date: str,
                       end_date: str) -> str:
        """åˆ›å»ºæ•°æ®å¿«ç…§ - æ¯æ¬¡è®­ç»ƒ/å›æµ‹å‰å¿…é¡»è°ƒç”¨"""

        snapshot = DataSnapshot(
            snapshot_id=generate_uuid(),
            created_at=datetime.now(timezone.utc),
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            source_versions=self._get_all_source_versions(),
            delay_config_hash=hash_config(DataVisibilityChecker.get_all_delays()),
            backfill_strategy_hash=hash_config(self.backfill_strategies),
        )

        # æŒä¹…åŒ–åˆ°æ•°æ®åº“
        self.db.save_snapshot(snapshot)
        return snapshot.snapshot_id

    def record_experiment(self,
                         snapshot_id: str,
                         feature_set_id: str,
                         model_config: dict,
                         train_metrics: dict,
                         test_metrics: dict) -> str:
        """è®°å½•å®éªŒ - å»ºç«‹å®Œæ•´è¡€ç¼˜é“¾"""

        record = ExperimentRecord(
            experiment_id=generate_uuid(),
            data_snapshot_id=snapshot_id,
            feature_set_id=feature_set_id,
            model_config_hash=hash_config(model_config),
            random_seed=model_config.get('random_seed', 42),
            train_metrics=train_metrics,
            test_metrics=test_metrics,
            git_commit=get_current_git_commit(),
            created_at=datetime.now(timezone.utc),
        )

        self.db.save_experiment(record)
        return record.experiment_id

    def reproduce_experiment(self, experiment_id: str) -> dict:
        """å¤ç°å®éªŒ - ä½¿ç”¨ç›¸åŒçš„æ•°æ®å¿«ç…§å’Œé…ç½®"""
        record = self.db.get_experiment(experiment_id)
        snapshot = self.db.get_snapshot(record.data_snapshot_id)

        # ä½¿ç”¨å†å²å¿«ç…§é‡æ–°åŠ è½½æ•°æ®
        data = self.load_snapshot_data(snapshot)

        # ä½¿ç”¨ç›¸åŒé…ç½®é‡æ–°è®­ç»ƒ
        # ...

        return {"original": record.test_metrics, "reproduced": new_metrics}
```

**éªŒè¯æµ‹è¯•**:
```python
def test_experiment_reproducibility():
    """å®éªŒå¯å¤ç°æ€§æµ‹è¯•"""
    # 1. åˆ›å»ºå¿«ç…§å¹¶è®­ç»ƒ
    snapshot_id = lineage.create_snapshot(["BTCUSDT"], "2023-01-01", "2024-01-01")
    model1 = train_model(snapshot_id, random_seed=42)
    exp1_id = lineage.record_experiment(snapshot_id, ...)

    # 2. ä½¿ç”¨ç›¸åŒå¿«ç…§é‡æ–°è®­ç»ƒ
    model2 = train_model(snapshot_id, random_seed=42)

    # 3. ç»“æœåº”è¯¥å®Œå…¨ä¸€è‡´
    assert model1.test_sharpe == model2.test_sharpe, \
        "ç›¸åŒå¿«ç…§+ç›¸åŒç§å­ï¼Œç»“æœä¸ä¸€è‡´ï¼"

def test_snapshot_immutability():
    """å¿«ç…§ä¸å¯å˜æ€§æµ‹è¯•"""
    snapshot_id = lineage.create_snapshot(["BTCUSDT"], "2023-01-01", "2024-01-01")
    data1 = lineage.load_snapshot_data(snapshot_id)

    # å³ä½¿åŸå§‹æ•°æ®æ›´æ–°äº†
    update_raw_data()

    # å¿«ç…§æ•°æ®åº”è¯¥ä¸å˜
    data2 = lineage.load_snapshot_data(snapshot_id)
    assert data1.equals(data2), "å¿«ç…§æ•°æ®è¢«ä¿®æ”¹ï¼"
```

---

### 11.6 P0-6: å›æµ‹-å®ç›˜æˆäº¤å¯¹é½

**æ ¸å¿ƒé—®é¢˜**: å›æµ‹çš„æˆäº¤æ¨¡å‹å¦‚æœä¸å®ç›˜ä¸ä¸€è‡´ï¼Œå›æµ‹æ”¶ç›Šå°±æ˜¯å¹»è§‰ã€‚

```python
class ExecutionModelValidator:
    """æˆäº¤æ¨¡å‹éªŒè¯å™¨ - ç¡®ä¿å›æµ‹ä¸å®ç›˜ä¸€è‡´"""

    # éœ€è¦å¯¹é½çš„æˆäº¤æ¨¡å‹è¦ç´ 
    ALIGNMENT_CHECKLIST = {
        "fill_price": "æˆäº¤ä»·æ ¼æ¨¡å‹ (last vs close vs mid)",
        "partial_fill": "éƒ¨åˆ†æˆäº¤å¤„ç†",
        "fee_model": "è´¹ç‡æ¨¡å‹ (maker/taker, VIPç­‰çº§)",
        "slippage_model": "æ»‘ç‚¹æ¨¡å‹ (é™æ€ vs åŠ¨æ€ vs å†²å‡»æˆæœ¬)",
        "reduce_only": "ä»…å‡ä»“è®¢å•å¤„ç†",
        "position_mode": "ä»“ä½æ¨¡å¼ (å•å‘ vs åŒå‘)",
        "trigger_logic": "è§¦å‘å•é€»è¾‘ (æ­¢æŸ/æ­¢ç›ˆè§¦å‘æ¡ä»¶)",
        "leverage_handling": "æ æ†å¤„ç† (ä¿è¯é‡‘è®¡ç®—)",
        "liquidation_logic": "çˆ†ä»“é€»è¾‘ (ä¸äº¤æ˜“æ‰€ä¸€è‡´)",
    }

    def validate_alignment(self, backtest_engine, live_engine) -> dict:
        """éªŒè¯å›æµ‹ä¸å®ç›˜çš„æˆäº¤æ¨¡å‹å¯¹é½"""
        results = {}

        for item, description in self.ALIGNMENT_CHECKLIST.items():
            bt_impl = getattr(backtest_engine, f"get_{item}_impl")()
            live_impl = getattr(live_engine, f"get_{item}_impl")()

            results[item] = {
                "description": description,
                "backtest": bt_impl,
                "live": live_impl,
                "aligned": bt_impl == live_impl,
            }

        return results

# æ›´çœŸå®çš„æ»‘ç‚¹æ¨¡å‹ (é™æ€ 0.01% å¤ªä¹è§‚)
class DynamicSlippageModel:
    """åŠ¨æ€æ»‘ç‚¹æ¨¡å‹ - è€ƒè™‘å¸‚åœºæ¡ä»¶"""

    def estimate_slippage(self,
                         symbol: str,
                         order_size_usd: float,
                         market_conditions: dict) -> float:
        """ä¼°è®¡æ»‘ç‚¹ - åŸºäºè®¢å•å¤§å°å’Œå¸‚åœºæ¡ä»¶"""

        # åŸºç¡€æ»‘ç‚¹
        base_slippage = 0.0001  # 0.01%

        # è®¢å•å¤§å°å½±å“ (å¤§å•å†²å‡»æˆæœ¬)
        avg_daily_volume = market_conditions['avg_daily_volume']
        size_ratio = order_size_usd / avg_daily_volume
        size_impact = size_ratio * 0.1  # å æ—¥æˆäº¤é‡æ¯”ä¾‹çš„10%

        # æ³¢åŠ¨ç‡å½±å“
        current_volatility = market_conditions['volatility']
        normal_volatility = 0.02  # å‡è®¾æ­£å¸¸æ³¢åŠ¨ç‡2%
        vol_multiplier = current_volatility / normal_volatility

        # æµåŠ¨æ€§å½±å“
        bid_ask_spread = market_conditions['bid_ask_spread']
        spread_impact = bid_ask_spread / 2

        total_slippage = (base_slippage + size_impact + spread_impact) * vol_multiplier

        return min(total_slippage, 0.01)  # ä¸Šé™1%

# è´¹ç‡æ¨¡å‹ (è€ƒè™‘VIPç­‰çº§)
class FeeModel:
    """è´¹ç‡æ¨¡å‹ - è€ƒè™‘VIPç­‰çº§å’Œmaker/taker"""

    FEE_TIERS = {
        "VIP0": {"maker": 0.0002, "taker": 0.0004},
        "VIP1": {"maker": 0.00016, "taker": 0.0004},
        "VIP2": {"maker": 0.00014, "taker": 0.00035},
        "VIP3": {"maker": 0.00012, "taker": 0.00032},
        # ...
    }

    def __init__(self, vip_level: str = "VIP0"):
        self.vip_level = vip_level

    def get_fee(self, is_maker: bool) -> float:
        tier = self.FEE_TIERS[self.vip_level]
        return tier["maker"] if is_maker else tier["taker"]
```

**éªŒè¯æµ‹è¯•**:
```python
def test_execution_model_alignment():
    """æˆäº¤æ¨¡å‹å¯¹é½æµ‹è¯•"""
    validator = ExecutionModelValidator()
    results = validator.validate_alignment(BacktestEngine(), LiveEngine())

    for item, result in results.items():
        assert result["aligned"], \
            f"æˆäº¤æ¨¡å‹ä¸ä¸€è‡´: {item} - å›æµ‹={result['backtest']}, å®ç›˜={result['live']}"

def test_slippage_realistic():
    """æ»‘ç‚¹æ¨¡å‹çœŸå®æ€§æµ‹è¯•"""
    model = DynamicSlippageModel()

    # å°å•æ»‘ç‚¹åº”è¯¥å¾ˆå°
    small_slippage = model.estimate_slippage("BTCUSDT", 1000, normal_conditions)
    assert small_slippage < 0.0005, "å°å•æ»‘ç‚¹è¿‡å¤§"

    # å¤§å•æ»‘ç‚¹åº”è¯¥æ›´å¤§
    large_slippage = model.estimate_slippage("BTCUSDT", 1000000, normal_conditions)
    assert large_slippage > small_slippage, "å¤§å•æ»‘ç‚¹åº”å¤§äºå°å•"

    # é«˜æ³¢åŠ¨æ—¶æ»‘ç‚¹åº”è¯¥æ›´å¤§
    volatile_slippage = model.estimate_slippage("BTCUSDT", 1000, high_vol_conditions)
    assert volatile_slippage > small_slippage, "é«˜æ³¢åŠ¨æ—¶æ»‘ç‚¹åº”æ›´å¤§"
```

---

### 11.7 P0 éªŒæ”¶æ¸…å•

| P0 æ ‡å‡† | æè¿° | éªŒæ”¶æ¡ä»¶ | æµ‹è¯•æ–¹æ³• |
|---------|------|----------|----------|
| P0-1 | æ•°æ®å¯è§æ€§ | æ‰€æœ‰ç‰¹å¾éƒ½æœ‰æ˜ç¡®çš„å‘å¸ƒå»¶è¿Ÿé…ç½® | æ³„éœ²æ£€æµ‹å•å…ƒæµ‹è¯• |
| P0-1 | Barèšåˆå¯è§æ€§ | CVDç­‰barç‰¹å¾åªç”¨å·²æ”¶ç›˜baræ•°æ® | CVDå¯è§æ€§æµ‹è¯• |
| P0-1 | As-of Merge | æ‰€æœ‰ç‰¹å¾åˆå¹¶ä½¿ç”¨ merge_asof | ä»£ç å®¡æŸ¥ + å•å…ƒæµ‹è¯• |
| P0-2 | ä»·æ ¼è¯­ä¹‰ | mark/index/last/close ä½¿ç”¨åœºæ™¯æ˜ç¡® | ä»·æ ¼ä¸€è‡´æ€§æµ‹è¯• |
| P0-2 | èµ„é‡‘è´¹ç‡ | ç»“ç®—æ—¶é—´ç²¾ç¡®å¯¹é½ (0/8/16 UTC) | å›æ”¾å¯¹é½æµ‹è¯• |
| P0-3 | å¹‚ç­‰æ€§ | client_order_id åŸºäºä¿¡å·å†…å®¹hash | å¹‚ç­‰æ€§å•å…ƒæµ‹è¯• |
| P0-3 | å¯¹è´¦ | æ¯5åˆ†é’Ÿä¸äº¤æ˜“æ‰€å¯¹è´¦ | å¯¹è´¦æµ‹è¯• |
| P0-3 | ä¿æŠ¤æ¨¡å¼ | ç½‘ç»œæ–­å¼€æ—¶æ­£ç¡®è¿›å…¥ä¿æŠ¤æ¨¡å¼ | ç½‘ç»œä¸­æ–­æ¨¡æ‹Ÿæµ‹è¯• |
| P0-4 | Walk-Forward | ç¦æ­¢éšæœºåˆ‡åˆ†ï¼Œå›ºå®šOOSå‘¨æœŸ | éªŒè¯æµç¨‹æµ‹è¯• |
| P0-4 | è¿‡æ‹Ÿåˆæ£€æµ‹ | è®­ç»ƒ/æµ‹è¯•å¤æ™®å·® < 0.3 | è¿‡æ‹Ÿåˆæ£€æµ‹æµ‹è¯• |
| P0-5 | æ•°æ®å¿«ç…§ | æ¯æ¬¡è®­ç»ƒè®°å½•å®Œæ•´æ•°æ®è¡€ç¼˜ | å¯å¤ç°æ€§æµ‹è¯• |
| P0-5 | å®éªŒè®°å½• | snapshot_id + feature_set_id + model_config | è¡€ç¼˜é“¾å®Œæ•´æ€§æµ‹è¯• |
| P0-6 | æˆäº¤æ¨¡å‹ | å›æµ‹ä¸å®ç›˜ä½¿ç”¨ç›¸åŒæˆäº¤é€»è¾‘ | å¯¹é½æµ‹è¯• |
| P0-6 | æ»‘ç‚¹æ¨¡å‹ | è€ƒè™‘è®¢å•å¤§å°/æ³¢åŠ¨ç‡/æµåŠ¨æ€§ | çœŸå®æ€§æµ‹è¯• |
| P0-6 | è´¹ç‡æ¨¡å‹ | è€ƒè™‘VIPç­‰çº§å’Œmaker/taker | è´¹ç‡ä¸€è‡´æ€§æµ‹è¯• |

---

## 12. å¼€å‘è·¯çº¿å›¾

> ğŸ“‹ **å‚è€ƒæ–‡æ¡£** - æ­¤è·¯çº¿å›¾ä¸ºå…¨æ™¯è§„åˆ’ï¼Œ**MVPä»…éœ€å®ŒæˆPhase 0 + Phase 1æ ¸å¿ƒéƒ¨åˆ†**ã€‚
> â¸ï¸ **MVPä¸åŒ…å«** - Phase 2/3çš„180å› å­æ‰©å±•ã€é“¾ä¸Šæ•°æ®ã€ç¤¾åª’æ–°é—»ç­‰å»¶åå®ç°ã€‚

> **åŸåˆ™**: å…ˆè®©ç³»ç»Ÿ"å¯ä¿¡"ï¼ˆæ•°æ®å¯å¤ç°ï¼‰ï¼Œå†åš"å¯ç”¨"ï¼ˆæœ€å°å¯äº¤æ˜“ï¼‰ï¼Œæœ€ååš"ä¸°å¯Œ"ï¼ˆ180å› å­ï¼‰ã€‚

### 12.1 é˜¶æ®µæ€»è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                          å¼€å‘é˜¶æ®µä¸ä¾èµ–å…³ç³»                                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  Phase 0: æ•°æ®åŸºç¡€è®¾æ–½ (è®©ç³»ç»Ÿ"å¯ä¿¡")                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Step 1: æ•°æ®é‡‡é›†å™¨å®ç°                                               â”‚   â”‚
â”‚  â”‚ Step 2: B/Cæ¡£æ•°æ®è½ç›˜                                                â”‚   â”‚
â”‚  â”‚ Step 3: æ•°æ®è¡€ç¼˜ä¸å¿«ç…§                                               â”‚   â”‚
â”‚  â”‚ Step 7: æ•°æ®è´¨é‡ç›‘æ§                                                 â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                              â”‚
â”‚  Phase 1: å›æµ‹å¯ä¿¡æ€§ + P1æ•°æ®æ‰©å±• (è®©å›æµ‹"å¯ä¿¡")                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Step 4: å›æµ‹-å®ç›˜æˆäº¤å¯¹é½ (DynamicSlippageModel)                     â”‚   â”‚
â”‚  â”‚ Step 5: Walk-ForwardéªŒè¯æµç¨‹                                         â”‚   â”‚
â”‚  â”‚ â˜… Step 9: L2æ·±åº¦èšåˆ + æ»‘ç‚¹æ ¡å‡† (CalibratedSlippageModel)            â”‚   â”‚
â”‚  â”‚ â˜… Step 10: æ¸…ç®—æ•°æ® (LiquidationCollector + çº§è”æ£€æµ‹)                â”‚   â”‚
â”‚  â”‚ â˜… Step 11: å¤šäº¤æ˜“æ‰€Basis (Binance/Bybit/OKX ä»·å·®çŸ©é˜µ)                â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                              â”‚
â”‚  Phase 2: P0éªŒæ”¶ä¸CI/CD                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ Step 6: P0å•å…ƒæµ‹è¯•                                                   â”‚   â”‚
â”‚  â”‚ Step 8: CI/CDé›†æˆ                                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                              â†“                                              â”‚
â”‚  Phase 3: æœ€å°å¯äº¤æ˜“ç³»ç»Ÿ                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚ ä½¿ç”¨30-60ä¸ªç¨³å®šå› å­è®­ç»ƒbaselineæ¨¡å‹                                  â”‚   â”‚
â”‚  â”‚ å®ç›˜å½±å­æ¨¡å¼ (paper trading) éªŒè¯                                    â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â”‚  â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„ åç»­æ‰©å±• (è§12.14) â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„â”„        â”‚
â”‚  P2: é“¾ä¸Šæµå‘äº¤æ˜“æ‰€ | P2: æ›´ç»†IVç»“æ„ | P3: ç¤¾åª’/æ–°é—»                        â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Step 9 ä¸ºä½•ä¼˜å…ˆ**:
1. **ç›´æ¥æå‡ P0-6 å¯ä¿¡åº¦** - å½“å‰ DynamicSlippageModel åŸºäºç»éªŒå…¬å¼ä¼°ç®—ï¼Œæœ‰çœŸå®æ·±åº¦æ•°æ®å¯éªŒè¯/æ ¡å‡†
2. **å·¥ç¨‹å¤æ‚åº¦å¯æ§** - åªéœ€ bar èšåˆç‰ˆ (1m/5m)ï¼Œä¸éœ€è¦æ¯«ç§’çº§
3. **å›æµ‹/å®ç›˜åŒå‘å—ç›Š** - æ—¢èƒ½æ”¹è¿›å›æµ‹æ»‘ç‚¹æ¨¡å‹ï¼Œä¹Ÿèƒ½ç”¨äºå®ç›˜ä¸‹å•å‰é¢„ä¼°

### 12.2 Step 1: æ•°æ®é‡‡é›†å™¨å®ç°

**ç›®æ ‡**: å®ç°æ‰€æœ‰ Collector ç±»ï¼Œç¡®ä¿ fetch_historical å’Œ subscribe_realtime æ–¹æ³•ç¬¦åˆ DataManager è§„èŒƒã€‚

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/collectors/`

```python
# éœ€è¦å®ç°çš„é‡‡é›†å™¨
algvex/core/data/collectors/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py              # BaseCollector æŠ½è±¡ç±»
â”œâ”€â”€ binance.py           # BinanceCollector (OHLCV, OI, LS, Taker, Funding)
â”œâ”€â”€ deribit.py           # DeribitCollector (DVOL, IV, Put/Call, MaxPain)
â”œâ”€â”€ defilama.py          # DefiLlamaCollector (TVL, Stablecoin)
â”œâ”€â”€ sentiment.py         # SentimentCollector (Fear&Greed, Google Trends)
â””â”€â”€ macro.py             # MacroCollector (DXY, Yields, SPX, VIX)
```

**å…³é”®å®ç°è¦ç‚¹**:

```python
class BinanceCollector(BaseCollector):
    """å¸å®‰æ•°æ®é‡‡é›†å™¨"""

    # 1. APIé™æµé…ç½® (å¿…é¡»éµå®ˆï¼Œå¦åˆ™ä¼šè¢«å°IP)
    RATE_LIMITS = {
        "klines": {"weight": 1, "limit": 1200, "window": 60},  # 1200/åˆ†é’Ÿ
        "openInterest": {"weight": 1, "limit": 1200, "window": 60},
        "topLongShortRatio": {"weight": 1, "limit": 1200, "window": 60},
    }

    # 2. é‡è¯•é…ç½®
    RETRY_CONFIG = {
        "max_retries": 3,
        "backoff_factor": 2,  # 2s, 4s, 8s
        "retry_on": [429, 500, 502, 503, 504],
    }

    # 3. é”™è¯¯å¤„ç†
    async def fetch_historical(self, symbol: str, start: str, end: str) -> pd.DataFrame:
        """è·å–å†å²æ•°æ® - å¸¦é™æµå’Œé‡è¯•"""
        try:
            await self._check_rate_limit("klines")
            data = await self._fetch_with_retry(...)
            return self._validate_and_clean(data)
        except RateLimitExceeded:
            await asyncio.sleep(self._get_backoff_time())
            return await self.fetch_historical(symbol, start, end)
        except Exception as e:
            self.logger.error(f"Fetch failed: {e}")
            raise DataFetchError(f"Failed to fetch {symbol}: {e}")

    # 4. æ•°æ®éªŒè¯
    def _validate_and_clean(self, df: pd.DataFrame) -> pd.DataFrame:
        """éªŒè¯æ•°æ®å®Œæ•´æ€§"""
        # æ£€æŸ¥ç¼ºå¤±å€¼
        missing_ratio = df.isnull().sum() / len(df)
        if missing_ratio.max() > 0.1:  # è¶…è¿‡10%ç¼ºå¤±
            self.logger.warning(f"High missing ratio: {missing_ratio.max():.2%}")

        # æ£€æŸ¥å¼‚å¸¸å€¼
        # æ£€æŸ¥æ—¶é—´è¿ç»­æ€§
        # ...
        return df
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ‰€æœ‰ 5 ä¸ª Collector å®ç°å®Œæˆ
- [ ] æ¯ä¸ª Collector æœ‰å¯¹åº”çš„å•å…ƒæµ‹è¯•
- [ ] API é™æµé€»è¾‘é€šè¿‡å‹åŠ›æµ‹è¯•
- [ ] é”™è¯¯é‡è¯•é€»è¾‘è¦†ç›–å¸¸è§å¼‚å¸¸

---

### 12.3 Step 2: B/Cæ¡£æ•°æ®è½ç›˜

**ç›®æ ‡**: å°† B/C æ¡£æ•°æ®æºçš„æ•°æ®å®šæœŸæ‹‰å–å¹¶å­˜å…¥ TimescaleDBï¼Œå½¢æˆé•¿æœŸå†å²ã€‚

**è°ƒåº¦æ–¹æ¡ˆ**: ä½¿ç”¨ Celery Beat å®šæ—¶ä»»åŠ¡

```python
# algvex/tasks/data_collection.py

from celery import Celery
from celery.schedules import crontab

app = Celery('algvex')

# å®šæ—¶ä»»åŠ¡é…ç½®
app.conf.beat_schedule = {
    # Bæ¡£æ•°æ®: æ¯5åˆ†é’Ÿé‡‡é›†ä¸€æ¬¡
    'collect-oi-every-5min': {
        'task': 'tasks.collect_open_interest',
        'schedule': crontab(minute='*/5'),
        'args': (['BTCUSDT', 'ETHUSDT'],),
    },
    'collect-ls-ratio-every-5min': {
        'task': 'tasks.collect_long_short_ratio',
        'schedule': crontab(minute='*/5'),
        'args': (['BTCUSDT', 'ETHUSDT'],),
    },
    'collect-taker-volume-every-1min': {
        'task': 'tasks.collect_taker_volume',
        'schedule': crontab(minute='*/1'),
        'args': (['BTCUSDT', 'ETHUSDT'],),
    },

    # Bæ¡£æ•°æ®: æ¯å°æ—¶é‡‡é›†
    'collect-deribit-every-hour': {
        'task': 'tasks.collect_deribit_options',
        'schedule': crontab(minute=5),  # æ¯å°æ—¶ç¬¬5åˆ†é’Ÿ
        'args': (['BTC', 'ETH'],),
    },

    # Cæ¡£æ•°æ®: æ¯æ—¥é‡‡é›†
    'collect-google-trends-daily': {
        'task': 'tasks.collect_google_trends',
        'schedule': crontab(hour=1, minute=0),  # æ¯å¤©å‡Œæ™¨1ç‚¹
        'args': (['bitcoin', 'crypto'],),
    },

    # æ•°æ®è´¨é‡æ£€æŸ¥: æ¯å°æ—¶
    'check-data-quality-hourly': {
        'task': 'tasks.check_data_quality',
        'schedule': crontab(minute=30),
    },
}

@app.task(bind=True, max_retries=3)
def collect_open_interest(self, symbols: List[str]):
    """é‡‡é›†æŒä»“é‡æ•°æ®"""
    try:
        collector = BinanceCollector()
        for symbol in symbols:
            data = collector.fetch_open_interest(symbol)
            storage.save_to_timescale(data, table='binance_oi')
            logger.info(f"Collected OI for {symbol}: {len(data)} rows")
    except Exception as e:
        logger.error(f"OI collection failed: {e}")
        self.retry(exc=e, countdown=60)  # 1åˆ†é’Ÿåé‡è¯•
```

**TimescaleDB è¡¨ç»“æ„**:

```sql
-- Bæ¡£æ•°æ®è¡¨ (éœ€è¦é•¿æœŸç§¯ç´¯çš„æ•°æ®)
CREATE TABLE binance_oi (
    time        TIMESTAMPTZ NOT NULL,
    symbol      TEXT NOT NULL,
    open_interest DOUBLE PRECISION,
    open_interest_value DOUBLE PRECISION,
    collected_at TIMESTAMPTZ DEFAULT NOW()
);
SELECT create_hypertable('binance_oi', 'time');

CREATE TABLE binance_ls_ratio (
    time        TIMESTAMPTZ NOT NULL,
    symbol      TEXT NOT NULL,
    long_short_ratio DOUBLE PRECISION,
    long_account DOUBLE PRECISION,
    short_account DOUBLE PRECISION,
    collected_at TIMESTAMPTZ DEFAULT NOW()
);
SELECT create_hypertable('binance_ls_ratio', 'time');

-- æ•°æ®è½ç›˜å…ƒæ•°æ®è¡¨ (è¿½è¸ªé‡‡é›†çŠ¶æ€)
CREATE TABLE data_collection_log (
    id          SERIAL PRIMARY KEY,
    source      TEXT NOT NULL,
    symbol      TEXT NOT NULL,
    start_time  TIMESTAMPTZ NOT NULL,
    end_time    TIMESTAMPTZ NOT NULL,
    rows_collected INTEGER,
    status      TEXT,  -- 'success', 'partial', 'failed'
    error_message TEXT,
    created_at  TIMESTAMPTZ DEFAULT NOW()
);
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] Celery Beat å®šæ—¶ä»»åŠ¡é…ç½®å®Œæˆ
- [ ] TimescaleDB è¡¨ç»“æ„åˆ›å»ºå®Œæˆ
- [ ] Bæ¡£æ•°æ® (OI/LS/Taker) æ¯5åˆ†é’Ÿè‡ªåŠ¨é‡‡é›†
- [ ] Cæ¡£æ•°æ® (Google Trends) æ¯æ—¥è‡ªåŠ¨é‡‡é›†
- [ ] é‡‡é›†æ—¥å¿—å¯è¿½æº¯

---

### 12.4 Step 3: æ•°æ®è¡€ç¼˜ä¸å¿«ç…§

**ç›®æ ‡**: å®ç° DataSnapshot å’Œ ExperimentRecordï¼Œç¡®ä¿æ¯æ¬¡è®­ç»ƒ/å›æµ‹å¯å¤ç°ã€‚

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/lineage.py`

**å¿«ç…§å­˜å‚¨æ–¹æ¡ˆ**:
- å¿«ç…§å…ƒæ•°æ® â†’ PostgreSQL
- å¿«ç…§æ•°æ®æ–‡ä»¶ â†’ æœ¬åœ° Parquet (æœªæ¥å¯è¿ç§»åˆ° S3)

```python
# algvex/core/data/lineage.py

import hashlib
from pathlib import Path

class DataLineageManager:
    """æ•°æ®è¡€ç¼˜ç®¡ç†å™¨"""

    SNAPSHOT_DIR = Path("~/.algvex/snapshots").expanduser()

    def __init__(self, db_url: str):
        self.db = Database(db_url)
        self.SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)

    def create_snapshot(self,
                       symbols: List[str],
                       start_date: str,
                       end_date: str,
                       data_manager: DataManager) -> str:
        """
        åˆ›å»ºæ•°æ®å¿«ç…§

        1. ä» DataManager è·å–æ•°æ®
        2. è®¡ç®—æ•°æ®å†…å®¹ hash
        3. ä¿å­˜åˆ° Parquet æ–‡ä»¶
        4. è®°å½•å…ƒæ•°æ®åˆ°æ•°æ®åº“
        """
        # 1. è·å–æ•°æ®
        df = data_manager.get_historical(
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            fields="all",
        )

        # 2. ç”Ÿæˆå¿«ç…§ID (åŸºäºå†…å®¹hash)
        content_hash = hashlib.sha256(
            pd.util.hash_pandas_object(df).values.tobytes()
        ).hexdigest()[:16]
        snapshot_id = f"snap_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{content_hash}"

        # 3. ä¿å­˜æ•°æ®æ–‡ä»¶
        snapshot_path = self.SNAPSHOT_DIR / f"{snapshot_id}.parquet"
        df.to_parquet(snapshot_path, compression='zstd')

        # 4. è®°å½•å…ƒæ•°æ®
        snapshot = DataSnapshot(
            snapshot_id=snapshot_id,
            created_at=datetime.now(timezone.utc),
            symbols=symbols,
            start_date=start_date,
            end_date=end_date,
            source_versions=data_manager.get_source_versions(),
            delay_config_hash=self._hash_delay_config(),
            backfill_strategy_hash=self._hash_backfill_config(),
            file_path=str(snapshot_path),
            content_hash=content_hash,
            row_count=len(df),
            column_count=len(df.columns),
        )
        self.db.save_snapshot(snapshot)

        logger.info(f"Created snapshot: {snapshot_id} ({len(df)} rows)")
        return snapshot_id

    def load_snapshot(self, snapshot_id: str) -> pd.DataFrame:
        """åŠ è½½å†å²å¿«ç…§ - ç¡®ä¿æ•°æ®ä¸å¯å˜"""
        snapshot = self.db.get_snapshot(snapshot_id)
        df = pd.read_parquet(snapshot.file_path)

        # éªŒè¯æ•°æ®å®Œæ•´æ€§
        current_hash = hashlib.sha256(
            pd.util.hash_pandas_object(df).values.tobytes()
        ).hexdigest()[:16]

        if current_hash != snapshot.content_hash:
            raise DataIntegrityError(
                f"Snapshot {snapshot_id} has been corrupted! "
                f"Expected hash: {snapshot.content_hash}, Got: {current_hash}"
            )

        return df

    def record_experiment(self,
                         snapshot_id: str,
                         feature_set_id: str,
                         model_config: dict,
                         train_metrics: dict,
                         test_metrics: dict) -> str:
        """è®°å½•å®éªŒ - å®Œæ•´è¡€ç¼˜é“¾"""

        experiment = ExperimentRecord(
            experiment_id=f"exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid4().hex[:8]}",
            data_snapshot_id=snapshot_id,
            feature_set_id=feature_set_id,
            model_config_hash=hashlib.sha256(
                json.dumps(model_config, sort_keys=True).encode()
            ).hexdigest()[:16],
            random_seed=model_config.get('random_seed', 42),
            train_metrics=train_metrics,
            test_metrics=test_metrics,
            git_commit=self._get_git_commit(),
            created_at=datetime.now(timezone.utc),
        )

        self.db.save_experiment(experiment)
        return experiment.experiment_id
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] create_snapshot() å¯æ­£å¸¸åˆ›å»ºå¿«ç…§
- [ ] load_snapshot() å¯åŠ è½½å¹¶éªŒè¯å¿«ç…§å®Œæ•´æ€§
- [ ] record_experiment() å¯è®°å½•å®Œæ•´è¡€ç¼˜é“¾
- [ ] å¿«ç…§æ•°æ®ä¸å¯å˜æµ‹è¯•é€šè¿‡

---

### 12.5 Step 4: å›æµ‹-å®ç›˜æˆäº¤å¯¹é½

**ç›®æ ‡**: ç¡®ä¿å›æµ‹çš„ fill_price, fee_model, slippage_model ä¸å®ç›˜ä¸€è‡´ã€‚

**æ–‡ä»¶ä½ç½®**: `algvex/core/backtest/execution_model.py`

**å…³é”®å¯¹é½é¡¹**:

```python
# algvex/core/backtest/execution_model.py

class ExecutionModel:
    """ç»Ÿä¸€æˆäº¤æ¨¡å‹ - å›æµ‹å’Œå®ç›˜å…±ç”¨"""

    def __init__(self, config: ExecutionConfig):
        self.config = config
        self.fee_model = FeeModel(config.vip_level)
        self.slippage_model = DynamicSlippageModel()

    def calculate_fill_price(self,
                            side: str,
                            order_type: str,
                            market_data: dict) -> float:
        """
        è®¡ç®—æˆäº¤ä»·æ ¼

        è§„åˆ™ (å›æµ‹å’Œå®ç›˜å¿…é¡»ä¸€è‡´):
        - MARKET å•: last_price + slippage
        - LIMIT å•: limit_price (å‡è®¾å®Œå…¨æˆäº¤)
        """
        if order_type == "MARKET":
            base_price = market_data['last_price']
            slippage = self.slippage_model.estimate(
                symbol=market_data['symbol'],
                order_size_usd=market_data['order_size_usd'],
                conditions=market_data,
            )
            if side == "BUY":
                return base_price * (1 + slippage)
            else:
                return base_price * (1 - slippage)
        else:
            return market_data['limit_price']

    def calculate_fee(self,
                     notional: float,
                     is_maker: bool) -> float:
        """è®¡ç®—æ‰‹ç»­è´¹"""
        return notional * self.fee_model.get_fee(is_maker)

# ç¡®ä¿å›æµ‹å¼•æ“ä½¿ç”¨ç›¸åŒçš„æˆäº¤æ¨¡å‹
class CryptoPerpetualBacktest:
    def __init__(self, config: BacktestConfig):
        # ä½¿ç”¨ç»Ÿä¸€çš„æˆäº¤æ¨¡å‹
        self.execution_model = ExecutionModel(config.execution_config)

# ç¡®ä¿å®ç›˜æ¡¥æ¥å™¨ä½¿ç”¨ç›¸åŒçš„æˆäº¤æ¨¡å‹
class HummingbotBridge:
    def __init__(self, config: LiveConfig):
        # ä½¿ç”¨ç›¸åŒçš„æˆäº¤æ¨¡å‹è¿›è¡Œé¢„ä¼°
        self.execution_model = ExecutionModel(config.execution_config)
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] ExecutionModel ç±»å®ç°å®Œæˆ
- [ ] BacktestEngine å’Œ LiveEngine ä½¿ç”¨åŒä¸€ä¸ª ExecutionModel
- [ ] æˆäº¤ä»·æ ¼å¯¹é½æµ‹è¯•é€šè¿‡
- [ ] æ‰‹ç»­è´¹å¯¹é½æµ‹è¯•é€šè¿‡

---

### 12.6 Step 5: Walk-Forward éªŒè¯æµç¨‹

**ç›®æ ‡**: å®ç° Walk-Forward éªŒè¯ï¼Œç¦æ­¢éšæœºåˆ‡åˆ†æ—¶åºæ•°æ®ã€‚

**æ–‡ä»¶ä½ç½®**: `algvex/core/model/validation.py`

```python
# algvex/core/model/validation.py

class WalkForwardValidator:
    """Walk-Forward éªŒè¯å™¨"""

    def __init__(self,
                 train_months: int = 12,
                 test_months: int = 3,
                 min_train_samples: int = 1000,
                 purge_days: int = 7):  # è®­ç»ƒé›†å’Œæµ‹è¯•é›†ä¹‹é—´çš„éš”ç¦»å¤©æ•°
        self.train_months = train_months
        self.test_months = test_months
        self.min_train_samples = min_train_samples
        self.purge_days = purge_days

    def create_folds(self, data: pd.DataFrame) -> List[WalkForwardFold]:
        """åˆ›å»º Walk-Forward æŠ˜å """
        folds = []
        # ... å®ç°é€»è¾‘ (å·²åœ¨ P0-4 ä¸­å®šä¹‰)
        return folds

    def validate(self,
                model_class,
                model_params: dict,
                data: pd.DataFrame,
                target_col: str) -> WalkForwardResult:
        """æ‰§è¡Œ Walk-Forward éªŒè¯"""
        folds = self.create_folds(data)
        results = []

        for fold in folds:
            # è®­ç»ƒ
            model = model_class(**model_params)
            model.fit(fold.train_data, fold.train_data[target_col])

            # é¢„æµ‹
            predictions = model.predict(fold.test_data)

            # è®¡ç®—æŒ‡æ ‡
            metrics = self._calculate_metrics(
                fold.test_data[target_col],
                predictions,
            )
            results.append(metrics)

        return WalkForwardResult(
            folds=folds,
            metrics=results,
            aggregate=self._aggregate_metrics(results),
        )

# å¼ºåˆ¶ç¦æ­¢éšæœºåˆ‡åˆ†
def train_test_split(*args, shuffle=False, **kwargs):
    """é‡å†™ train_test_splitï¼Œç¦æ­¢ shuffle=True"""
    if shuffle:
        raise ValueError(
            "ç¦æ­¢éšæœºåˆ‡åˆ†æ—¶åºæ•°æ®ï¼è¯·ä½¿ç”¨ WalkForwardValidatorã€‚"
        )
    return sklearn_train_test_split(*args, shuffle=False, **kwargs)
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] WalkForwardValidator å®ç°å®Œæˆ
- [ ] ç¦æ­¢ shuffle=True çš„ä¿æŠ¤é€»è¾‘ç”Ÿæ•ˆ
- [ ] Walk-Forward ç»“æœå¯è§†åŒ–æŠ¥å‘Š

---

### 12.7 Step 6: P0 å•å…ƒæµ‹è¯•

**ç›®æ ‡**: ä¸ºæ‰€æœ‰ P0 æ ‡å‡†ç¼–å†™å•å…ƒæµ‹è¯•ã€‚

**æ–‡ä»¶ä½ç½®**: `tests/p0/`

```
tests/p0/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ test_p0_1_data_visibility.py     # æ•°æ®å¯è§æ€§æµ‹è¯•
â”œâ”€â”€ test_p0_2_price_semantics.py     # ä»·æ ¼è¯­ä¹‰æµ‹è¯•
â”œâ”€â”€ test_p0_3_order_consistency.py   # è®¢å•ä¸€è‡´æ€§æµ‹è¯•
â”œâ”€â”€ test_p0_4_walk_forward.py        # Walk-Forward æµ‹è¯•
â”œâ”€â”€ test_p0_5_data_lineage.py        # æ•°æ®è¡€ç¼˜æµ‹è¯•
â”œâ”€â”€ test_p0_6_execution_alignment.py # æˆäº¤å¯¹é½æµ‹è¯•
â””â”€â”€ conftest.py                      # pytest fixtures
```

```python
# tests/p0/test_p0_1_data_visibility.py

import pytest
from datetime import datetime, timezone, timedelta

class TestP0_1_DataVisibility:
    """P0-1: æ•°æ®å¯è§æ€§æµ‹è¯•"""

    def test_bar_aggregated_visibility(self, data_manager):
        """æµ‹è¯• bar èšåˆç‰¹å¾çš„å¯è§æ€§"""
        signal_time = datetime(2024, 6, 15, 12, 0, 0, tzinfo=timezone.utc)

        # è·å– CVD æ•°æ®
        cvd = data_manager.get_cvd_at_time(signal_time, bar_freq="1h")

        # CVD åº”è¯¥ä½¿ç”¨ 11:00 bar çš„æ•°æ®ï¼Œä¸èƒ½ä½¿ç”¨ 12:00 bar
        assert cvd.index.max() <= signal_time - timedelta(hours=1), \
            "CVD ä½¿ç”¨äº†æœªæ”¶ç›˜ bar çš„æ•°æ®ï¼Œå­˜åœ¨æ³„éœ²ï¼"

    def test_no_future_leakage(self, data_manager, sample_signals):
        """æµ‹è¯•æ— æœªæ¥æ•°æ®æ³„éœ²"""
        for signal in sample_signals:
            features = data_manager.get_features_at_time(signal.time)
            for f in features:
                visible_time = data_manager.get_visible_time(f)
                assert visible_time <= signal.time, \
                    f"å‘ç°æ³„éœ²: {f.name} visible_time > signal_time"

    def test_merge_asof_used(self):
        """æµ‹è¯•æ˜¯å¦ä½¿ç”¨ merge_asof è€Œéæ™®é€š merge"""
        import ast
        from pathlib import Path

        # æ‰«ææ‰€æœ‰å› å­è®¡ç®—å’Œæ•°æ®åˆå¹¶ç›¸å…³ä»£ç 
        target_dirs = [
            Path("algvex/core/factor"),
            Path("algvex/core/data"),
        ]

        violations = []
        for target_dir in target_dirs:
            if not target_dir.exists():
                continue

            for py_file in target_dir.rglob("*.py"):
                content = py_file.read_text()
                tree = ast.parse(content)

                for node in ast.walk(tree):
                    # æ£€æŸ¥ pd.merge() è°ƒç”¨
                    if isinstance(node, ast.Call):
                        func = node.func
                        # æ£€æŸ¥ pd.merge æˆ– DataFrame.merge
                        if isinstance(func, ast.Attribute):
                            if func.attr == "merge":
                                # æ£€æŸ¥æ˜¯å¦åœ¨æ—¶åºæ•°æ®åˆå¹¶åœºæ™¯
                                # merge_asof çš„ç‰¹å¾: direction å‚æ•°
                                has_direction = any(
                                    kw.arg == "direction"
                                    for kw in node.keywords
                                )
                                if not has_direction:
                                    # æ£€æŸ¥æ³¨é‡Šæ˜¯å¦æœ‰è±å…æ ‡è®°
                                    violations.append({
                                        "file": str(py_file),
                                        "line": node.lineno,
                                        "issue": "ä½¿ç”¨ merge è€Œé merge_asof",
                                    })

        # æŠ¥å‘Šç»“æœ
        if violations:
            for v in violations:
                # å…è®¸é€šè¿‡ # noqa: ASOF è±å…
                print(f"âš ï¸ {v['file']}:{v['line']} - {v['issue']}")
                print("   è¯·ç¡®è®¤æ˜¯å¦éœ€è¦æ”¹ä¸º merge_asof (æ—¶åºæ•°æ®åˆå¹¶åœºæ™¯)")

        # è‡³å°‘æ£€æŸ¥æ ¸å¿ƒæ–‡ä»¶å­˜åœ¨ merge_asof è°ƒç”¨
        core_files = list(Path("algvex/core/factor").rglob("*.py"))
        has_merge_asof = False
        for f in core_files:
            if "merge_asof" in f.read_text():
                has_merge_asof = True
                break

        assert has_merge_asof, "æ ¸å¿ƒå› å­æ¨¡å—å¿…é¡»ä½¿ç”¨ merge_asof è¿›è¡Œæ—¶åºæ•°æ®åˆå¹¶"
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ¯ä¸ª P0 æ ‡å‡†è‡³å°‘æœ‰ 3 ä¸ªæµ‹è¯•ç”¨ä¾‹
- [ ] æµ‹è¯•è¦†ç›–ç‡ > 80%
- [ ] æ‰€æœ‰ P0 æµ‹è¯•é€šè¿‡

---

### 12.8 Step 7: æ•°æ®è´¨é‡ç›‘æ§ (è¡¥å……)

**ç›®æ ‡**: ç›‘æ§æ•°æ®æºå¥åº·çŠ¶æ€ï¼ŒåŠæ—¶å‘ç°é—®é¢˜ã€‚

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/quality.py`

```python
# algvex/core/data/quality.py

class DataQualityMonitor:
    """æ•°æ®è´¨é‡ç›‘æ§å™¨"""

    # ç›‘æ§æŒ‡æ ‡é˜ˆå€¼
    THRESHOLDS = {
        "missing_rate": 0.05,       # ç¼ºå¤±ç‡ > 5% å‘Šè­¦
        "delay_seconds": 300,       # å»¶è¿Ÿ > 5åˆ†é’Ÿå‘Šè­¦
        "schema_change": True,      # å­—æ®µå˜åŒ–å‘Šè­¦
        "value_range_violation": 0.01,  # å¼‚å¸¸å€¼ > 1% å‘Šè­¦
    }

    def check_data_source(self, source: str) -> DataQualityReport:
        """æ£€æŸ¥å•ä¸ªæ•°æ®æºçš„å¥åº·çŠ¶æ€"""
        report = DataQualityReport(source=source)

        # 1. æ£€æŸ¥æœ€æ–°æ•°æ®æ—¶é—´ (å»¶è¿Ÿæ£€æµ‹)
        latest_time = self.db.get_latest_time(source)
        delay = datetime.now(timezone.utc) - latest_time
        if delay.total_seconds() > self.THRESHOLDS["delay_seconds"]:
            report.add_alert(
                level="WARNING",
                message=f"Data delay: {delay.total_seconds()}s",
            )

        # 2. æ£€æŸ¥ç¼ºå¤±ç‡
        missing_rate = self.db.get_missing_rate(source, window="24h")
        if missing_rate > self.THRESHOLDS["missing_rate"]:
            report.add_alert(
                level="ERROR",
                message=f"High missing rate: {missing_rate:.2%}",
            )

        # 3. æ£€æŸ¥å­—æ®µå˜åŒ–
        current_schema = self.get_current_schema(source)
        expected_schema = self.get_expected_schema(source)
        if current_schema != expected_schema:
            report.add_alert(
                level="CRITICAL",
                message=f"Schema changed: {current_schema}",
            )

        return report

    def run_all_checks(self) -> List[DataQualityReport]:
        """è¿è¡Œæ‰€æœ‰æ•°æ®æºæ£€æŸ¥"""
        reports = []
        for source in self.ALL_SOURCES:
            report = self.check_data_source(source)
            reports.append(report)

            # å‘é€å‘Šè­¦
            if report.has_critical():
                self.alert_manager.send_critical(report)
            elif report.has_error():
                self.alert_manager.send_error(report)

        return reports
```

**Celery å®šæ—¶æ£€æŸ¥**:

```python
@app.task
def check_data_quality():
    """æ¯å°æ—¶æ£€æŸ¥æ•°æ®è´¨é‡"""
    monitor = DataQualityMonitor()
    reports = monitor.run_all_checks()

    # ç”ŸæˆæŠ¥å‘Š
    summary = DataQualitySummary(reports)
    logger.info(f"Data quality check: {summary.status}")

    # å¦‚æœæœ‰ä¸¥é‡é—®é¢˜ï¼Œæš‚åœç›¸å…³æ•°æ®é‡‡é›†
    if summary.has_critical():
        pause_data_collection(summary.critical_sources)
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] æ•°æ®å»¶è¿Ÿç›‘æ§æ­£å¸¸
- [ ] ç¼ºå¤±ç‡ç›‘æ§æ­£å¸¸
- [ ] å‘Šè­¦é€šçŸ¥å¯è¾¾ (Slack/é‚®ä»¶)

---

### 12.9 Step 8: CI/CD é›†æˆ (è¡¥å……)

**ç›®æ ‡**: å°† P0 æµ‹è¯•é›†æˆåˆ° CI/CD æµç¨‹ï¼Œç¡®ä¿æ¯æ¬¡æäº¤éƒ½é€šè¿‡éªŒæ”¶ã€‚

**GitHub Actions é…ç½®**:

```yaml
# .github/workflows/p0-tests.yml

name: P0 Verification Tests

on:
  push:
    branches: [main, develop]
  pull_request:
    branches: [main]

jobs:
  p0-tests:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: timescale/timescaledb:latest-pg15
        env:
          POSTGRES_DB: algvex_test
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
        ports:
          - 5432:5432

      redis:
        image: redis:7-alpine
        ports:
          - 6379:6379

    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          pip install -r requirements.txt
          pip install -r requirements-dev.txt

      - name: Run P0 Tests
        run: |
          pytest tests/p0/ -v --tb=short --cov=algvex --cov-report=xml

      - name: Check P0 Coverage
        run: |
          # P0 æµ‹è¯•è¦†ç›–ç‡å¿…é¡» > 80%
          coverage report --fail-under=80

      - name: Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          files: ./coverage.xml
```

**éªŒæ”¶æ ‡å‡†**:
- [ ] GitHub Actions é…ç½®å®Œæˆ
- [ ] PR å¿…é¡»é€šè¿‡ P0 æµ‹è¯•æ‰èƒ½åˆå¹¶
- [ ] è¦†ç›–ç‡æŠ¥å‘Šè‡ªåŠ¨ç”Ÿæˆ

---

### 12.10 å¼€å‘æ£€æŸ¥æ¸…å•

| Phase | Step | æè¿° | çŠ¶æ€ | è´Ÿè´£äºº |
|-------|------|------|------|--------|
| 0 | 1 | æ•°æ®é‡‡é›†å™¨å®ç° (5ä¸ª Collector) | â¬œ | - |
| 0 | 2 | B/Cæ¡£æ•°æ®è½ç›˜ (Celery + TimescaleDB) | â¬œ | - |
| 0 | 3 | æ•°æ®è¡€ç¼˜ä¸å¿«ç…§ | â¬œ | - |
| 0 | 7 | æ•°æ®è´¨é‡ç›‘æ§ | â¬œ | - |
| 1 | 4 | å›æµ‹-å®ç›˜æˆäº¤å¯¹é½ (DynamicSlippageModel) | â¬œ | - |
| 1 | 5 | Walk-Forward éªŒè¯æµç¨‹ | â¬œ | - |
| **1** | **9** | **â˜… L2æ·±åº¦èšåˆ + æ»‘ç‚¹æ ¡å‡†** | â¬œ | - |
| **1** | **10** | **â˜… æ¸…ç®—æ•°æ® + çº§è”æ£€æµ‹** | â¬œ | - |
| **1** | **11** | **â˜… å¤šäº¤æ˜“æ‰€Basis (Binance/Bybit/OKX)** | â¬œ | - |
| 2 | 6 | P0 å•å…ƒæµ‹è¯• (6ç»„) | â¬œ | - |
| 2 | 8 | CI/CD é›†æˆ | â¬œ | - |
| 3 | - | Baselineæ¨¡å‹è®­ç»ƒ (30-60ç¨³å®šå› å­) | â¬œ | - |
| 3 | - | å®ç›˜å½±å­æ¨¡å¼ (Paper Trading) | â¬œ | - |

---

### 12.11 Step 9: L2 æ·±åº¦èšåˆ + æ»‘ç‚¹æ¨¡å‹æ ¡å‡† (ä¼˜å…ˆå®æ–½)

> **ä¸ºä»€ä¹ˆä¼˜å…ˆ**: è¿™æ˜¯ç¬¬ä¸€ä¸ªæ•°æ®æ‰©å±•ï¼Œç›´æ¥è§£å†³ P0-6 æ»‘ç‚¹æ¨¡å‹"ä¼°ç®—"çš„é—®é¢˜ï¼Œç”¨çœŸå®æ·±åº¦æ•°æ®æ ¡å‡†ã€‚
>
> **å·¥ç¨‹å¤æ‚åº¦**: å¯æ§ã€‚åªåš 1m/5m bar èšåˆï¼Œä¸åšæ¯«ç§’çº§ orderbook å¿«ç…§ã€‚
>
> **åŒå‘å—ç›Š**: å›æµ‹æ»‘ç‚¹æ›´çœŸå® + å®ç›˜ä¸‹å•å‰å¯é¢„ä¼°å†²å‡»æˆæœ¬ã€‚

#### 12.11.1 æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Step 9: L2 æ·±åº¦èšåˆ + æ»‘ç‚¹æ ¡å‡† æ¶æ„                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    1. DepthCollector (WebSocket)                    â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   Binance WS â”€â”€â†’ åŸå§‹æ·±åº¦å¿«ç…§ â”€â”€â†’ 1m/5m èšåˆ â”€â”€â†’ TimescaleDB       â”‚   â”‚
â”‚  â”‚   (100msæ›´æ–°)     (å†…å­˜buffer)      (bar_close)    (æŒä¹…åŒ–)         â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   âš ï¸ å¯è§æ€§: bar_close (åªæœ‰å½“barç»“æŸåï¼Œèšåˆæ•°æ®æ‰å¯ç”¨)              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    2. æ·±åº¦å› å­è®¡ç®— (8ä¸ªæ ¸å¿ƒæŒ‡æ ‡)                      â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   bid_ask_spread, order_book_imbalance, depth_1pct_bid/ask,         â”‚   â”‚
â”‚  â”‚   depth_slope_bid/ask, impact_cost_buy/sell                         â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    3. CalibratedSlippageModel                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   Step 4 DynamicSlippageModel (ä¼°ç®—) â”€â”€å‡çº§â”€â”€â†’ çœŸå®æ·±åº¦æ ¡å‡†           â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   å›æµ‹: ç”¨å†å² impact_cost ä»£æ›¿ç»éªŒå…¬å¼                               â”‚   â”‚
â”‚  â”‚   å®ç›˜: ç”¨å®æ—¶æ·±åº¦é¢„ä¼°ä¸‹å•å†²å‡»                                        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 12.11.2 æ–‡ä»¶ç»“æ„

```
algvex/core/data/collectors/
â”œâ”€â”€ depth.py                    # DepthCollector (æ–°å¢)
â”‚
algvex/core/data/features/
â”œâ”€â”€ depth_features.py           # 8ä¸ªæ·±åº¦å› å­è®¡ç®— (æ–°å¢)
â”‚
algvex/core/backtest/
â”œâ”€â”€ slippage_model.py           # DynamicSlippageModel (å·²æœ‰, Step 4)
â”œâ”€â”€ calibrated_slippage.py      # CalibratedSlippageModel (æ–°å¢, Step 9)
â”‚
tests/p0/
â”œâ”€â”€ test_depth_collector.py     # æ·±åº¦é‡‡é›†æµ‹è¯• (æ–°å¢)
â”œâ”€â”€ test_calibrated_slippage.py # æ ¡å‡†æ»‘ç‚¹æµ‹è¯• (æ–°å¢)
```

#### 12.11.3 DepthCollector å®ç°

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/collectors/depth.py`

```python
# algvex/core/data/collectors/depth.py

import asyncio
import json
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Dict, List, Optional, Callable
from collections import defaultdict
import numpy as np
import pandas as pd
import websockets

from .base import BaseCollector


@dataclass
class DepthSnapshot:
    """å•æ¬¡æ·±åº¦å¿«ç…§"""
    timestamp: datetime
    symbol: str
    bids: List[List[float]]  # [[price, qty], ...]
    asks: List[List[float]]  # [[price, qty], ...]

    @property
    def best_bid(self) -> float:
        return self.bids[0][0] if self.bids else 0

    @property
    def best_ask(self) -> float:
        return self.asks[0][0] if self.asks else float('inf')

    @property
    def mid_price(self) -> float:
        return (self.best_bid + self.best_ask) / 2


@dataclass
class AggregatedDepthBar:
    """èšåˆåçš„æ·±åº¦ Bar (1m/5m)"""
    bar_time: datetime           # bar å¼€å§‹æ—¶é—´
    symbol: str

    # èšåˆç»Ÿè®¡ (bar å†…æ‰€æœ‰å¿«ç…§çš„å‡å€¼/åŠ æƒå‡å€¼)
    avg_bid_ask_spread: float    # å¹³å‡ spread (bps)
    avg_imbalance: float         # å¹³å‡ imbalance (-1 to 1)
    avg_depth_1pct_bid: float    # 1% èŒƒå›´å†…å¹³å‡ä¹°å•é‡ (USD)
    avg_depth_1pct_ask: float    # 1% èŒƒå›´å†…å¹³å‡å–å•é‡ (USD)
    avg_depth_slope_bid: float   # ä¹°å•é‡è¡°å‡æ–œç‡
    avg_depth_slope_ask: float   # å–å•é‡è¡°å‡æ–œç‡

    # å†²å‡»æˆæœ¬ (å…³é”®! ç”¨äºæ»‘ç‚¹æ ¡å‡†)
    impact_cost_10k_buy: float   # ä¹°å…¥ $10k çš„å†²å‡»æˆæœ¬ (bps)
    impact_cost_10k_sell: float  # å–å‡º $10k çš„å†²å‡»æˆæœ¬ (bps)
    impact_cost_50k_buy: float   # ä¹°å…¥ $50k çš„å†²å‡»æˆæœ¬ (bps)
    impact_cost_50k_sell: float  # å–å‡º $50k çš„å†²å‡»æˆæœ¬ (bps)
    impact_cost_100k_buy: float  # ä¹°å…¥ $100k çš„å†²å‡»æˆæœ¬ (bps)
    impact_cost_100k_sell: float # å–å‡º $100k çš„å†²å‡»æˆæœ¬ (bps)

    # å…ƒæ•°æ®
    snapshot_count: int          # bar å†…é‡‡é›†çš„å¿«ç…§æ•°
    visibility: str = "bar_close"  # å¯è§æ€§è§„åˆ™


class DepthCollector(BaseCollector):
    """
    å¸å®‰ L2 æ·±åº¦é‡‡é›†å™¨ (WebSocket)

    âš ï¸ å¯è§æ€§è§„åˆ™: bar_close
    - æ·±åº¦æ•°æ®åœ¨ bar ç»“æŸåæ‰èƒ½ç”¨äºå› å­è®¡ç®—
    - é˜²æ­¢æœªæ¥ä¿¡æ¯æ³„éœ²

    å­˜å‚¨ç­–ç•¥: åªå­˜èšåˆåçš„ bar æ•°æ®ï¼Œä¸å­˜åŸå§‹å¿«ç…§ (å¤ªå¤§)
    """

    # å¸å®‰ WebSocket é…ç½®
    WS_URL = "wss://fstream.binance.com/ws"
    DEPTH_LEVELS = 20  # å‰20æ¡£
    UPDATE_SPEED = "100ms"  # 100ms æ›´æ–°é¢‘ç‡

    # èšåˆé…ç½®
    BAR_FREQUENCIES = ["1m", "5m"]  # æ”¯æŒçš„èšåˆå‘¨æœŸ

    # å†²å‡»æˆæœ¬è®¡ç®—çš„è®¢å•è§„æ¨¡ (USD)
    IMPACT_SIZES = [10_000, 50_000, 100_000]

    def __init__(self,
                 symbols: List[str],
                 bar_freq: str = "1m",
                 on_bar_complete: Optional[Callable] = None):
        """
        Args:
            symbols: è¦è®¢é˜…çš„äº¤æ˜“å¯¹åˆ—è¡¨ (å¦‚ ["btcusdt", "ethusdt"])
            bar_freq: èšåˆé¢‘ç‡ ("1m" æˆ– "5m")
            on_bar_complete: bar å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°
        """
        self.symbols = [s.lower() for s in symbols]
        self.bar_freq = bar_freq
        self.on_bar_complete = on_bar_complete

        # å†…å­˜ç¼“å†²åŒº: symbol -> å½“å‰ bar çš„å¿«ç…§åˆ—è¡¨
        self._buffers: Dict[str, List[DepthSnapshot]] = defaultdict(list)

        # å½“å‰ bar å¼€å§‹æ—¶é—´
        self._current_bar_start: Dict[str, datetime] = {}

        # è¿è¡ŒçŠ¶æ€
        self._running = False
        self._ws = None

    async def start(self):
        """å¯åŠ¨ WebSocket è¿æ¥å’Œæ•°æ®é‡‡é›†"""
        self._running = True

        # æ„å»ºè®¢é˜… streams
        streams = [f"{s}@depth{self.DEPTH_LEVELS}@{self.UPDATE_SPEED}"
                   for s in self.symbols]
        url = f"{self.WS_URL}/stream?streams={'/'.join(streams)}"

        while self._running:
            try:
                async with websockets.connect(url) as ws:
                    self._ws = ws
                    await self._receive_loop()
            except Exception as e:
                if self._running:
                    print(f"WebSocket disconnected: {e}, reconnecting in 5s...")
                    await asyncio.sleep(5)

    async def _receive_loop(self):
        """æ¥æ”¶å¹¶å¤„ç†æ·±åº¦æ›´æ–°"""
        async for message in self._ws:
            data = json.loads(message)

            # è§£ææ·±åº¦æ•°æ®
            stream = data.get("stream", "")
            symbol = stream.split("@")[0]
            depth_data = data.get("data", {})

            snapshot = DepthSnapshot(
                timestamp=datetime.now(timezone.utc),
                symbol=symbol,
                bids=[[float(p), float(q)] for p, q in depth_data.get("b", [])],
                asks=[[float(p), float(q)] for p, q in depth_data.get("a", [])],
            )

            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self._add_to_buffer(snapshot)

    def _add_to_buffer(self, snapshot: DepthSnapshot):
        """æ·»åŠ å¿«ç…§åˆ°ç¼“å†²åŒºï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦èšåˆ"""
        symbol = snapshot.symbol

        # è®¡ç®—å½“å‰ bar å¼€å§‹æ—¶é—´
        bar_start = self._get_bar_start(snapshot.timestamp)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œæˆä¸Šä¸€ä¸ª bar
        if symbol in self._current_bar_start:
            if bar_start > self._current_bar_start[symbol]:
                # å®Œæˆä¸Šä¸€ä¸ª bar
                self._complete_bar(symbol, self._current_bar_start[symbol])
                self._buffers[symbol] = []

        self._current_bar_start[symbol] = bar_start
        self._buffers[symbol].append(snapshot)

    def _get_bar_start(self, ts: datetime) -> datetime:
        """è®¡ç®— bar å¼€å§‹æ—¶é—´"""
        if self.bar_freq == "1m":
            return ts.replace(second=0, microsecond=0)
        elif self.bar_freq == "5m":
            minute = (ts.minute // 5) * 5
            return ts.replace(minute=minute, second=0, microsecond=0)
        else:
            raise ValueError(f"Unsupported bar_freq: {self.bar_freq}")

    def _complete_bar(self, symbol: str, bar_time: datetime):
        """èšåˆå¹¶è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„ bar"""
        snapshots = self._buffers[symbol]
        if not snapshots:
            return

        # è®¡ç®—èšåˆæŒ‡æ ‡
        aggregated = self._aggregate_snapshots(symbol, bar_time, snapshots)

        # å›è°ƒ
        if self.on_bar_complete:
            self.on_bar_complete(aggregated)

    def _aggregate_snapshots(self,
                             symbol: str,
                             bar_time: datetime,
                             snapshots: List[DepthSnapshot]) -> AggregatedDepthBar:
        """èšåˆå¿«ç…§ä¸º bar æ•°æ®"""

        spreads = []
        imbalances = []
        depth_1pct_bids = []
        depth_1pct_asks = []
        slope_bids = []
        slope_asks = []
        impact_costs = {size: {"buy": [], "sell": []}
                       for size in self.IMPACT_SIZES}

        for snap in snapshots:
            mid = snap.mid_price
            if mid <= 0:
                continue

            # 1. Bid-Ask Spread (bps)
            spread_bps = (snap.best_ask - snap.best_bid) / mid * 10000
            spreads.append(spread_bps)

            # 2. Order Book Imbalance
            bid_qty = sum(qty for _, qty in snap.bids)
            ask_qty = sum(qty for _, qty in snap.asks)
            total = bid_qty + ask_qty
            imbalance = (bid_qty - ask_qty) / total if total > 0 else 0
            imbalances.append(imbalance)

            # 3. Depth within 1% (USD)
            depth_bid = self._calculate_depth_within_pct(snap.bids, mid, 0.01)
            depth_ask = self._calculate_depth_within_pct(snap.asks, mid, 0.01)
            depth_1pct_bids.append(depth_bid * mid)  # è½¬æ¢ä¸º USD
            depth_1pct_asks.append(depth_ask * mid)

            # 4. Depth Slope (è¡°å‡é€Ÿåº¦)
            slope_bid = self._calculate_depth_slope(snap.bids, mid)
            slope_ask = self._calculate_depth_slope(snap.asks, mid)
            slope_bids.append(slope_bid)
            slope_asks.append(slope_ask)

            # 5. Impact Cost (å…³é”®!)
            for size in self.IMPACT_SIZES:
                cost_buy = self._calculate_impact_cost(snap.asks, mid, size)
                cost_sell = self._calculate_impact_cost(snap.bids, mid, size)
                impact_costs[size]["buy"].append(cost_buy)
                impact_costs[size]["sell"].append(cost_sell)

        return AggregatedDepthBar(
            bar_time=bar_time,
            symbol=symbol.upper(),
            avg_bid_ask_spread=np.mean(spreads) if spreads else 0,
            avg_imbalance=np.mean(imbalances) if imbalances else 0,
            avg_depth_1pct_bid=np.mean(depth_1pct_bids) if depth_1pct_bids else 0,
            avg_depth_1pct_ask=np.mean(depth_1pct_asks) if depth_1pct_asks else 0,
            avg_depth_slope_bid=np.mean(slope_bids) if slope_bids else 0,
            avg_depth_slope_ask=np.mean(slope_asks) if slope_asks else 0,
            impact_cost_10k_buy=np.mean(impact_costs[10000]["buy"]),
            impact_cost_10k_sell=np.mean(impact_costs[10000]["sell"]),
            impact_cost_50k_buy=np.mean(impact_costs[50000]["buy"]),
            impact_cost_50k_sell=np.mean(impact_costs[50000]["sell"]),
            impact_cost_100k_buy=np.mean(impact_costs[100000]["buy"]),
            impact_cost_100k_sell=np.mean(impact_costs[100000]["sell"]),
            snapshot_count=len(snapshots),
        )

    def _calculate_depth_within_pct(self,
                                    levels: List[List[float]],
                                    mid: float,
                                    pct: float) -> float:
        """è®¡ç®—æŒ‡å®šç™¾åˆ†æ¯”èŒƒå›´å†…çš„æ·±åº¦"""
        total_qty = 0
        for price, qty in levels:
            if abs(price - mid) / mid <= pct:
                total_qty += qty
        return total_qty

    def _calculate_depth_slope(self,
                               levels: List[List[float]],
                               mid: float) -> float:
        """è®¡ç®—æ·±åº¦è¡°å‡æ–œç‡ (è¶Šé™¡å³­è¯´æ˜æµåŠ¨æ€§è¶Šé›†ä¸­åœ¨ best price)"""
        if len(levels) < 5:
            return 0

        distances = []
        quantities = []
        for price, qty in levels[:10]:  # å‰10æ¡£
            dist = abs(price - mid) / mid * 100  # ç™¾åˆ†æ¯”è·ç¦»
            distances.append(dist)
            quantities.append(qty)

        if not distances:
            return 0

        # ç®€å•çº¿æ€§å›å½’æ–œç‡
        x = np.array(distances)
        y = np.array(quantities)
        if len(x) > 1 and np.std(x) > 0:
            slope = np.polyfit(x, y, 1)[0]
            return slope
        return 0

    def _calculate_impact_cost(self,
                               levels: List[List[float]],
                               mid: float,
                               order_size_usd: float) -> float:
        """
        è®¡ç®—å†²å‡»æˆæœ¬ (bps)

        æ¨¡æ‹Ÿåƒæ‰è®¢å•ç°¿ï¼Œè®¡ç®—å¹³å‡æˆäº¤ä»·ä¸ mid çš„åç¦»
        """
        remaining_usd = order_size_usd
        total_qty = 0
        total_cost = 0

        for price, qty in levels:
            level_usd = price * qty
            if remaining_usd <= 0:
                break

            fill_usd = min(remaining_usd, level_usd)
            fill_qty = fill_usd / price

            total_qty += fill_qty
            total_cost += fill_qty * price
            remaining_usd -= fill_usd

        if total_qty == 0:
            return 0

        avg_price = total_cost / total_qty
        impact_bps = abs(avg_price - mid) / mid * 10000
        return impact_bps

    async def stop(self):
        """åœæ­¢é‡‡é›†"""
        self._running = False
        if self._ws:
            await self._ws.close()


# ============== TimescaleDB å­˜å‚¨ ==============

DEPTH_TABLE_SCHEMA = """
CREATE TABLE IF NOT EXISTS depth_bars (
    bar_time TIMESTAMPTZ NOT NULL,
    symbol VARCHAR(20) NOT NULL,

    -- æµåŠ¨æ€§æŒ‡æ ‡
    avg_bid_ask_spread DOUBLE PRECISION,
    avg_imbalance DOUBLE PRECISION,
    avg_depth_1pct_bid DOUBLE PRECISION,
    avg_depth_1pct_ask DOUBLE PRECISION,
    avg_depth_slope_bid DOUBLE PRECISION,
    avg_depth_slope_ask DOUBLE PRECISION,

    -- å†²å‡»æˆæœ¬ (æ ¸å¿ƒï¼ç”¨äºæ»‘ç‚¹æ ¡å‡†)
    impact_cost_10k_buy DOUBLE PRECISION,
    impact_cost_10k_sell DOUBLE PRECISION,
    impact_cost_50k_buy DOUBLE PRECISION,
    impact_cost_50k_sell DOUBLE PRECISION,
    impact_cost_100k_buy DOUBLE PRECISION,
    impact_cost_100k_sell DOUBLE PRECISION,

    -- å…ƒæ•°æ®
    snapshot_count INTEGER,

    PRIMARY KEY (bar_time, symbol)
);

-- åˆ›å»º hypertable (TimescaleDB)
SELECT create_hypertable('depth_bars', 'bar_time', if_not_exists => TRUE);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_depth_symbol ON depth_bars (symbol, bar_time DESC);
"""
```

#### 12.11.4 CalibratedSlippageModel å®ç°

**æ–‡ä»¶ä½ç½®**: `algvex/core/backtest/calibrated_slippage.py`

```python
# algvex/core/backtest/calibrated_slippage.py

from dataclasses import dataclass
from typing import Optional, Dict
import numpy as np
import pandas as pd

from .slippage_model import DynamicSlippageModel  # Step 4 çš„åŸºç¡€æ¨¡å‹


@dataclass
class SlippageEstimate:
    """æ»‘ç‚¹ä¼°ç®—ç»“æœ"""
    slippage_bps: float          # ä¼°ç®—æ»‘ç‚¹ (bps)
    confidence: str              # "high" / "medium" / "low"
    source: str                  # "depth_data" / "fallback_model"
    details: Dict                # è¯¦ç»†ä¿¡æ¯


class CalibratedSlippageModel:
    """
    æ ¡å‡†æ»‘ç‚¹æ¨¡å‹ - åŸºäºçœŸå® L2 æ·±åº¦æ•°æ®

    å‡çº§è·¯å¾„:
    - Step 4 DynamicSlippageModel: åŸºäºç»éªŒå…¬å¼ä¼°ç®— (fallback)
    - Step 9 CalibratedSlippageModel: åŸºäºçœŸå®æ·±åº¦æ•°æ®æ ¡å‡† (primary)

    ä½¿ç”¨åœºæ™¯:
    - å›æµ‹: ä½¿ç”¨å†å² impact_cost è®¡ç®—æ›´çœŸå®çš„æ»‘ç‚¹
    - å®ç›˜: ä½¿ç”¨å®æ—¶æ·±åº¦æ•°æ®é¢„ä¼°ä¸‹å•å†²å‡»
    """

    # é¢„è®¾çš„è®¢å•è§„æ¨¡æ¡£ä½ (ä¸ DepthCollector å¯¹é½)
    SIZE_TIERS = [10_000, 50_000, 100_000]

    def __init__(self,
                 data_manager,
                 fallback_model: Optional[DynamicSlippageModel] = None):
        """
        Args:
            data_manager: æ•°æ®ç®¡ç†å™¨ (ç”¨äºè·å–æ·±åº¦æ•°æ®)
            fallback_model: å½“æ²¡æœ‰æ·±åº¦æ•°æ®æ—¶çš„å›é€€æ¨¡å‹ (Step 4)
        """
        self.data_manager = data_manager
        self.fallback_model = fallback_model or DynamicSlippageModel()

        # æ ¡å‡†ç³»æ•° (å¯é€šè¿‡å†å²æ•°æ®æ‹Ÿåˆ)
        self.calibration_params = {
            "spread_weight": 0.5,      # spread å¯¹æ»‘ç‚¹çš„è´¡çŒ®
            "impact_weight": 1.0,      # impact_cost å¯¹æ»‘ç‚¹çš„è´¡çŒ®
            "volatility_adj": 0.3,     # æ³¢åŠ¨ç‡è°ƒæ•´ç³»æ•°
        }

    def estimate_slippage(self,
                         symbol: str,
                         order_size_usd: float,
                         bar_time: pd.Timestamp,
                         side: str = "buy",
                         use_fallback_if_missing: bool = True) -> SlippageEstimate:
        """
        ä¼°ç®—æ»‘ç‚¹

        Args:
            symbol: äº¤æ˜“å¯¹ (å¦‚ "BTCUSDT")
            order_size_usd: è®¢å•é‡‘é¢ (USD)
            bar_time: å½“å‰ bar æ—¶é—´ (ç”¨äºè·å– as-of æ·±åº¦æ•°æ®)
            side: "buy" æˆ– "sell"
            use_fallback_if_missing: æ— æ·±åº¦æ•°æ®æ—¶æ˜¯å¦ä½¿ç”¨å›é€€æ¨¡å‹

        Returns:
            SlippageEstimate: æ»‘ç‚¹ä¼°ç®—ç»“æœ
        """

        # 1. å°è¯•è·å–æ·±åº¦æ•°æ®
        depth_data = self._get_depth_at_time(symbol, bar_time)

        if depth_data is None:
            # æ— æ·±åº¦æ•°æ®ï¼Œä½¿ç”¨å›é€€æ¨¡å‹
            if use_fallback_if_missing:
                fallback_slip = self.fallback_model.estimate_slippage(
                    symbol=symbol,
                    order_size_usd=order_size_usd,
                    market_conditions=self._get_market_conditions(symbol, bar_time)
                )
                return SlippageEstimate(
                    slippage_bps=fallback_slip * 10000,  # è½¬ä¸º bps
                    confidence="low",
                    source="fallback_model",
                    details={"reason": "no_depth_data"}
                )
            else:
                raise ValueError(f"No depth data for {symbol} at {bar_time}")

        # 2. æ ¹æ®è®¢å•è§„æ¨¡æ’å€¼è®¡ç®—å†²å‡»æˆæœ¬
        impact_bps = self._interpolate_impact_cost(
            depth_data, order_size_usd, side
        )

        # 3. åŠ å…¥ spread è´¡çŒ®
        spread_bps = depth_data.get("avg_bid_ask_spread", 0)
        spread_contribution = spread_bps * self.calibration_params["spread_weight"]

        # 4. æ³¢åŠ¨ç‡è°ƒæ•´ (é«˜æ³¢åŠ¨æ—¶æ»‘ç‚¹é€šå¸¸æ›´å¤§)
        volatility = self._get_volatility(symbol, bar_time)
        vol_adj = 1 + (volatility - 0.02) * self.calibration_params["volatility_adj"]
        vol_adj = max(0.5, min(vol_adj, 2.0))  # é™åˆ¶åœ¨ [0.5, 2.0]

        # 5. ç»¼åˆè®¡ç®—
        total_slippage_bps = (impact_bps + spread_contribution) * vol_adj

        return SlippageEstimate(
            slippage_bps=total_slippage_bps,
            confidence="high" if depth_data.get("snapshot_count", 0) > 30 else "medium",
            source="depth_data",
            details={
                "impact_bps": impact_bps,
                "spread_contribution": spread_contribution,
                "volatility_adj": vol_adj,
                "snapshot_count": depth_data.get("snapshot_count", 0),
            }
        )

    def _get_depth_at_time(self,
                          symbol: str,
                          bar_time: pd.Timestamp) -> Optional[Dict]:
        """
        è·å–æŒ‡å®šæ—¶é—´çš„æ·±åº¦æ•°æ® (as-of query)

        âš ï¸ å¯è§æ€§è§„åˆ™: åªèƒ½è·å– bar_time ä¹‹å‰å·²å®Œæˆçš„ bar æ•°æ®
        """
        return self.data_manager.get_depth_bar(
            symbol=symbol,
            bar_time=bar_time,
            visibility_rule="bar_close"  # ç¡®ä¿ä¸æ³„éœ²æœªæ¥ä¿¡æ¯
        )

    def _interpolate_impact_cost(self,
                                 depth_data: Dict,
                                 order_size_usd: float,
                                 side: str) -> float:
        """
        æ ¹æ®è®¢å•è§„æ¨¡æ’å€¼è®¡ç®—å†²å‡»æˆæœ¬

        é¢„å­˜çš„æ¡£ä½: 10k, 50k, 100k
        å¯¹äºå…¶ä»–è§„æ¨¡ï¼Œä½¿ç”¨çº¿æ€§/å¯¹æ•°æ’å€¼
        """
        suffix = "buy" if side.lower() == "buy" else "sell"

        # è·å–å„æ¡£ä½çš„å†²å‡»æˆæœ¬
        costs = {
            10_000: depth_data.get(f"impact_cost_10k_{suffix}", 0),
            50_000: depth_data.get(f"impact_cost_50k_{suffix}", 0),
            100_000: depth_data.get(f"impact_cost_100k_{suffix}", 0),
        }

        # å°äº 10k: ç›´æ¥ç”¨ 10k çš„å€¼ (ä¿å®ˆ)
        if order_size_usd <= 10_000:
            # çº¿æ€§ç¼©æ”¾
            return costs[10_000] * (order_size_usd / 10_000)

        # 10k-50k: çº¿æ€§æ’å€¼
        if order_size_usd <= 50_000:
            t = (order_size_usd - 10_000) / (50_000 - 10_000)
            return costs[10_000] + t * (costs[50_000] - costs[10_000])

        # 50k-100k: çº¿æ€§æ’å€¼
        if order_size_usd <= 100_000:
            t = (order_size_usd - 50_000) / (100_000 - 50_000)
            return costs[50_000] + t * (costs[100_000] - costs[50_000])

        # å¤§äº 100k: å¤–æ¨ (å‡è®¾çº¿æ€§å¢é•¿)
        slope = (costs[100_000] - costs[50_000]) / 50_000
        extra = order_size_usd - 100_000
        return costs[100_000] + slope * extra

    def _get_volatility(self, symbol: str, bar_time: pd.Timestamp) -> float:
        """è·å–å½“å‰æ³¢åŠ¨ç‡ (ç”¨äºè°ƒæ•´æ»‘ç‚¹)"""
        # ä» DataManager è·å–æ³¢åŠ¨ç‡å› å­
        try:
            vol = self.data_manager.get_feature(
                symbol=symbol,
                feature="volatility_24h",
                bar_time=bar_time
            )
            return vol if vol else 0.02  # é»˜è®¤ 2%
        except:
            return 0.02

    def _get_market_conditions(self,
                               symbol: str,
                               bar_time: pd.Timestamp) -> Dict:
        """è·å–å¸‚åœºæ¡ä»¶ (ç”¨äº fallback æ¨¡å‹)"""
        return {
            "volatility": self._get_volatility(symbol, bar_time),
            "avg_daily_volume": 1e9,  # é»˜è®¤å€¼
            "bid_ask_spread": 0.0005,  # é»˜è®¤ 5bps
        }

    # ============== æ ¡å‡†æ–¹æ³• ==============

    def calibrate(self,
                 historical_trades: pd.DataFrame,
                 historical_depth: pd.DataFrame) -> Dict:
        """
        ä½¿ç”¨å†å²æˆäº¤æ•°æ®æ ¡å‡†æ¨¡å‹å‚æ•°

        Args:
            historical_trades: å†å²æˆäº¤è®°å½• (åŒ…å«å®é™…æ»‘ç‚¹)
                columns: [symbol, timestamp, side, size_usd, expected_price,
                          actual_avg_price, actual_slippage_bps]
            historical_depth: å†å²æ·±åº¦æ•°æ®
                columns: [symbol, timestamp, bids, asks]

        Returns:
            æ ¡å‡†åçš„å‚æ•°
        """
        import numpy as np
        from scipy import optimize

        calibration_results = {}

        for symbol in historical_trades["symbol"].unique():
            symbol_trades = historical_trades[
                historical_trades["symbol"] == symbol
            ]
            symbol_depth = historical_depth[
                historical_depth["symbol"] == symbol
            ]

            # 1. è®¡ç®—æ¯ç¬”äº¤æ˜“çš„é¢„ä¼°æ»‘ç‚¹ vs å®é™…æ»‘ç‚¹
            errors = []
            for _, trade in symbol_trades.iterrows():
                # æ‰¾åˆ°å¯¹åº”æ—¶é—´ç‚¹çš„æ·±åº¦æ•°æ®
                depth_at_time = symbol_depth[
                    symbol_depth["timestamp"] <= trade["timestamp"]
                ].iloc[-1] if len(symbol_depth) > 0 else None

                if depth_at_time is not None:
                    estimated = self.estimate_slippage_from_depth(
                        size_usd=trade["size_usd"],
                        side=trade["side"],
                        depth=depth_at_time,
                    )
                    actual = trade["actual_slippage_bps"]
                    errors.append(actual - estimated)

            # 2. è®¡ç®—æ ¡å‡†å› å­
            if errors:
                mean_error = np.mean(errors)
                std_error = np.std(errors)

                # æ ¡å‡†å‚æ•°: åç§»é‡ + æ³¢åŠ¨ç‡è°ƒæ•´
                calibration_results[symbol] = {
                    "bias_adjustment_bps": mean_error,
                    "volatility_multiplier": 1 + std_error / 10,
                    "sample_count": len(errors),
                    "calibration_date": pd.Timestamp.now(),
                }

        # 3. æ›´æ–°å†…éƒ¨å‚æ•°
        self.calibration_params.update(calibration_results)

        return calibration_results

    def backtest_vs_actual(self,
                          symbol: str,
                          start_date: str,
                          end_date: str) -> pd.DataFrame:
        """
        å¯¹æ¯”å›æµ‹æ»‘ç‚¹ vs çœŸå®æ·±åº¦æ»‘ç‚¹

        ç”¨äºéªŒè¯æ¨¡å‹å‡†ç¡®æ€§

        Returns:
            DataFrame with columns:
            - timestamp: æ—¶é—´æˆ³
            - size_usd: è®¢å•å¤§å°
            - side: æ–¹å‘
            - backtest_slippage_bps: å›æµ‹ä¼°ç®—æ»‘ç‚¹
            - depth_slippage_bps: çœŸå®æ·±åº¦è®¡ç®—æ»‘ç‚¹
            - error_bps: è¯¯å·®
        """
        # è·å–å†å²æ·±åº¦æ•°æ®
        depth_data = self.data_manager.get_depth_history(
            symbol=symbol,
            start_date=start_date,
            end_date=end_date,
        )

        # æµ‹è¯•ä¸åŒè®¢å•å¤§å°
        test_sizes = [1000, 5000, 10000, 25000, 50000, 100000]
        results = []

        for _, depth_row in depth_data.iterrows():
            for size in test_sizes:
                for side in ["buy", "sell"]:
                    # å›æµ‹æ¨¡å‹ä¼°ç®—
                    backtest_slip = self.fallback_model.estimate_slippage(
                        symbol=symbol,
                        side=side,
                        order_size_usd=size,
                        bar_time=depth_row["timestamp"],
                    )

                    # çœŸå®æ·±åº¦è®¡ç®—
                    depth_slip = self.estimate_slippage_from_depth(
                        size_usd=size,
                        side=side,
                        depth=depth_row,
                    )

                    results.append({
                        "timestamp": depth_row["timestamp"],
                        "size_usd": size,
                        "side": side,
                        "backtest_slippage_bps": backtest_slip * 10000,
                        "depth_slippage_bps": depth_slip,
                        "error_bps": (backtest_slip * 10000) - depth_slip,
                    })

        result_df = pd.DataFrame(results)

        # æ·»åŠ ç»Ÿè®¡æ‘˜è¦
        print(f"=== æ»‘ç‚¹æ¨¡å‹éªŒè¯æŠ¥å‘Š ({symbol}) ===")
        print(f"æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
        print(f"æ ·æœ¬æ•°: {len(result_df)}")
        print(f"å¹³å‡è¯¯å·®: {result_df['error_bps'].mean():.2f} bps")
        print(f"è¯¯å·®æ ‡å‡†å·®: {result_df['error_bps'].std():.2f} bps")
        print(f"æœ€å¤§ä½ä¼°: {result_df['error_bps'].min():.2f} bps")
        print(f"æœ€å¤§é«˜ä¼°: {result_df['error_bps'].max():.2f} bps")

        return result_df


# ============== ExecutionModel é›†æˆ ==============

class ExecutionModelV2:
    """
    æ‰§è¡Œæ¨¡å‹ V2 - æ”¯æŒæ ¡å‡†æ»‘ç‚¹

    å‡çº§è·¯å¾„:
    - V1 (Step 4): DynamicSlippageModel (ç»éªŒå…¬å¼)
    - V2 (Step 9): CalibratedSlippageModel (çœŸå®æ·±åº¦)
    """

    def __init__(self,
                 config,
                 use_calibrated_slippage: bool = True):
        self.config = config
        self.fee_model = FeeModel(config.vip_level)

        # æ»‘ç‚¹æ¨¡å‹é€‰æ‹©
        if use_calibrated_slippage:
            self.slippage_model = CalibratedSlippageModel(
                data_manager=config.data_manager,
                fallback_model=DynamicSlippageModel()
            )
        else:
            self.slippage_model = DynamicSlippageModel()

    def calculate_fill_price(self,
                            symbol: str,
                            side: str,
                            order_type: str,
                            order_size_usd: float,
                            bar_time: pd.Timestamp,
                            market_data: dict) -> float:
        """è®¡ç®—æˆäº¤ä»·æ ¼ (è€ƒè™‘çœŸå®æ»‘ç‚¹)"""

        if order_type == "MARKET":
            base_price = market_data['last_price']

            # ä½¿ç”¨æ ¡å‡†æ»‘ç‚¹æ¨¡å‹
            if isinstance(self.slippage_model, CalibratedSlippageModel):
                estimate = self.slippage_model.estimate_slippage(
                    symbol=symbol,
                    order_size_usd=order_size_usd,
                    bar_time=bar_time,
                    side=side,
                )
                slippage = estimate.slippage_bps / 10000  # è½¬ä¸ºå°æ•°
            else:
                slippage = self.slippage_model.estimate_slippage(
                    symbol=symbol,
                    order_size_usd=order_size_usd,
                    market_conditions=market_data,
                )

            if side == "BUY":
                return base_price * (1 + slippage)
            else:
                return base_price * (1 - slippage)
        else:
            return market_data['limit_price']
```

#### 12.11.5 æ•°æ®å¯è§æ€§é…ç½®æ›´æ–°

**æ›´æ–°æ–‡ä»¶**: `algvex/core/data/visibility.py` (Section 11.1 å®šä¹‰çš„)

```python
# æ–°å¢æ·±åº¦æ•°æ®çš„å¯è§æ€§è§„åˆ™
PUBLICATION_DELAYS = {
    # ... å·²æœ‰é…ç½® ...

    # Step 9: L2 æ·±åº¦æ•°æ® (Cæ¡£, bar_close)
    "depth_bid_ask_spread": "bar_close",
    "depth_imbalance": "bar_close",
    "depth_1pct_bid": "bar_close",
    "depth_1pct_ask": "bar_close",
    "depth_slope_bid": "bar_close",
    "depth_slope_ask": "bar_close",
    "depth_impact_cost_buy": "bar_close",
    "depth_impact_cost_sell": "bar_close",
}

# æ•°æ®å¯å¾—æ€§åˆ†çº§
DATA_AVAILABILITY = {
    # ... å·²æœ‰é…ç½® ...

    # Step 9: L2 æ·±åº¦ (Cæ¡£ - å¿…é¡»è‡ªå»ºè½ç›˜)
    "depth_bars": {
        "tier": "C",
        "history_window": "æ—  (å¿…é¡»è‡ªå»º)",
        "schema_stability": "â˜…â˜…â˜†",
        "notes": "WebSocket æ·±åº¦æ•°æ®ï¼Œåªèƒ½å®æ—¶é‡‡é›†ï¼Œæ— å†å² API",
    },
}
```

#### 12.11.6 æµ‹è¯•ç”¨ä¾‹

**æ–‡ä»¶ä½ç½®**: `tests/p0/test_depth_collector.py`

```python
# tests/p0/test_depth_collector.py

import pytest
from datetime import datetime, timezone
from algvex.core.data.collectors.depth import (
    DepthCollector, DepthSnapshot, AggregatedDepthBar
)


class TestDepthSnapshot:
    """æ·±åº¦å¿«ç…§æµ‹è¯•"""

    def test_basic_metrics(self):
        """åŸºç¡€æŒ‡æ ‡è®¡ç®—"""
        snapshot = DepthSnapshot(
            timestamp=datetime.now(timezone.utc),
            symbol="btcusdt",
            bids=[[100000, 1.0], [99900, 2.0], [99800, 3.0]],
            asks=[[100100, 1.0], [100200, 2.0], [100300, 3.0]],
        )

        assert snapshot.best_bid == 100000
        assert snapshot.best_ask == 100100
        assert snapshot.mid_price == 100050

    def test_impact_cost_calculation(self):
        """å†²å‡»æˆæœ¬è®¡ç®—æµ‹è¯•"""
        collector = DepthCollector(symbols=["btcusdt"])

        # æ¨¡æ‹Ÿè®¢å•ç°¿
        asks = [
            [100000, 0.1],   # $10,000
            [100100, 0.2],   # $20,020
            [100200, 0.3],   # $30,060
        ]
        mid = 99950

        # ä¹°å…¥ $10,000 åº”è¯¥åªåƒç¬¬ä¸€æ¡£
        impact_10k = collector._calculate_impact_cost(asks, mid, 10000)
        assert impact_10k < 10  # å°äº 10 bps

        # ä¹°å…¥ $50,000 éœ€è¦åƒæ‰å¤šæ¡£
        impact_50k = collector._calculate_impact_cost(asks, mid, 50000)
        assert impact_50k > impact_10k  # å¤§å•å†²å‡»æ›´å¤§


class TestCalibratedSlippageModel:
    """æ ¡å‡†æ»‘ç‚¹æ¨¡å‹æµ‹è¯•"""

    def test_interpolation(self):
        """å†²å‡»æˆæœ¬æ’å€¼æµ‹è¯•"""
        model = CalibratedSlippageModel(data_manager=MockDataManager())

        # æ¨¡æ‹Ÿæ·±åº¦æ•°æ®
        depth_data = {
            "impact_cost_10k_buy": 2.0,   # 2 bps
            "impact_cost_50k_buy": 5.0,   # 5 bps
            "impact_cost_100k_buy": 10.0, # 10 bps
        }

        # æµ‹è¯•æ’å€¼
        assert model._interpolate_impact_cost(depth_data, 10000, "buy") == 2.0
        assert model._interpolate_impact_cost(depth_data, 30000, "buy") == 3.5  # çº¿æ€§æ’å€¼
        assert model._interpolate_impact_cost(depth_data, 100000, "buy") == 10.0

    def test_fallback_when_no_depth(self):
        """æ— æ·±åº¦æ•°æ®æ—¶å›é€€æµ‹è¯•"""
        model = CalibratedSlippageModel(
            data_manager=MockDataManager(return_none=True),
            fallback_model=DynamicSlippageModel()
        )

        result = model.estimate_slippage(
            symbol="BTCUSDT",
            order_size_usd=10000,
            bar_time=pd.Timestamp.now(),
            use_fallback_if_missing=True
        )

        assert result.source == "fallback_model"
        assert result.confidence == "low"

    def test_visibility_compliance(self):
        """å¯è§æ€§è§„åˆ™åˆè§„æµ‹è¯•"""
        model = CalibratedSlippageModel(data_manager=MockDataManager())

        # ä¸èƒ½ä½¿ç”¨æœªæ¥çš„æ·±åº¦æ•°æ®
        # (MockDataManager åº”è¯¥åªè¿”å› bar_time ä¹‹å‰çš„æ•°æ®)
        # ...
```

#### 12.11.7 éªŒæ”¶æ ‡å‡†

| éªŒæ”¶é¡¹ | æè¿° | æµ‹è¯•æ–¹æ³• | çŠ¶æ€ |
|--------|------|----------|------|
| DepthCollector | WebSocket è¿æ¥ç¨³å®šï¼Œèƒ½æŒç»­é‡‡é›†æ·±åº¦æ•°æ® | è¿è¡Œ 24h æ— æ–­è¿ | â¬œ |
| Bar èšåˆ | 1m/5m èšåˆé€»è¾‘æ­£ç¡®ï¼Œsnapshot_count > 0 | å•å…ƒæµ‹è¯• | â¬œ |
| 8ä¸ªæ·±åº¦å› å­ | æ‰€æœ‰æŒ‡æ ‡è®¡ç®—æ­£ç¡® (spread, imbalance, depth, slope, impact) | å•å…ƒæµ‹è¯• | â¬œ |
| å†²å‡»æˆæœ¬ | impact_cost ä¸çœŸå®è®¢å•ç°¿æ»‘ç‚¹ä¸€è‡´ | å›æ”¾å¯¹æ¯”æµ‹è¯• | â¬œ |
| TimescaleDB å­˜å‚¨ | æ•°æ®æ­£ç¡®å†™å…¥ï¼ŒæŸ¥è¯¢æ€§èƒ½è¾¾æ ‡ | å‹åŠ›æµ‹è¯• | â¬œ |
| CalibratedSlippageModel | æ»‘ç‚¹ä¼°ç®—æ¯” DynamicSlippageModel æ›´å‡†ç¡® | å¯¹æ¯”æµ‹è¯• | â¬œ |
| å¯è§æ€§ | depth æ•°æ®ä½¿ç”¨ bar_close è§„åˆ™ï¼Œæ— æœªæ¥æ³„éœ² | æ³„éœ²æ£€æµ‹æµ‹è¯• | â¬œ |
| Fallback | æ— æ·±åº¦æ•°æ®æ—¶æ­£ç¡®å›é€€åˆ° DynamicSlippageModel | å•å…ƒæµ‹è¯• | â¬œ |
| ExecutionModelV2 | å›æµ‹å¼•æ“æ­£ç¡®ä½¿ç”¨ CalibratedSlippageModel | é›†æˆæµ‹è¯• | â¬œ |
| å®ç›˜é¢„ä¼° | å®ç›˜ä¸‹å•å‰èƒ½é¢„ä¼°å†²å‡»æˆæœ¬ | æ‰‹åŠ¨éªŒè¯ | â¬œ |

---

### 12.12 Step 10: æ¸…ç®—æ•°æ® (Liquidations)

> **å¢é‡ä»·å€¼**: å¯¹"æç«¯è¡Œæƒ…/ç€‘å¸ƒ/æŒ¤ä»“"é¢„æµ‹æ¯”æ™®é€šä»·é‡æ›´æ•æ„Ÿã€‚æ¸…ç®—çº§è”æ˜¯åŠ å¯†å¸‚åœºç‹¬ç‰¹çš„é£é™©ç‰¹å¾ã€‚
>
> **å·¥ç¨‹å¤æ‚åº¦**: ä¸­ç­‰ã€‚WebSocket å®æ—¶é‡‡é›† + bar èšåˆï¼Œä¸ Step 9 ç»“æ„ç±»ä¼¼ã€‚
>
> **æ•°æ®å¯å¾—æ€§**: Bæ¡£ (éœ€è‡ªå»ºè½ç›˜ï¼Œå¸å®‰æœ‰å®æ—¶æµä½†å†å²æœ‰é™)

#### 12.12.1 æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Step 10: æ¸…ç®—æ•°æ®é‡‡é›†ä¸å› å­è®¡ç®—                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    1. LiquidationCollector (WebSocket)              â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   Binance WS â”€â”€â†’ å•ç¬”æ¸…ç®—äº‹ä»¶ â”€â”€â†’ 1m/5m/1h èšåˆ â”€â”€â†’ TimescaleDB    â”‚   â”‚
â”‚  â”‚   !forceOrder@arr   (å®æ—¶æ¨é€)      (bar_close)       (æŒä¹…åŒ–)       â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   âš ï¸ å¯è§æ€§: bar_close (èšåˆåæ‰å¯ç”¨äºå› å­è®¡ç®—)                       â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    2. æ¸…ç®—å› å­è®¡ç®— (5ä¸ªæ ¸å¿ƒæŒ‡æ ‡)                      â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   liquidation_volume_long/short, liquidation_imbalance,             â”‚   â”‚
â”‚  â”‚   liquidation_spike, liquidation_momentum                           â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    3. æç«¯è¡Œæƒ…é¢„è­¦ä¿¡å·                                â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   æ¸…ç®—çº§è”æ£€æµ‹ â†’ å¯è§¦å‘é£æ§é™ä»“ / æš‚åœå¼€ä»“                            â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 12.12.2 æ•°æ®æºä¸è·å–æ–¹å¼

**å¸å®‰å¼ºå¹³æ•°æ®æµ (å…è´¹)**:

```python
# WebSocket è®¢é˜…åœ°å€
wss://fstream.binance.com/ws/!forceOrder@arr

# è¿”å›æ•°æ®æ ¼å¼
{
    "e": "forceOrder",                   # äº‹ä»¶ç±»å‹
    "E": 1703001234567,                  # äº‹ä»¶æ—¶é—´
    "o": {
        "s": "BTCUSDT",                  # äº¤æ˜“å¯¹
        "S": "SELL",                     # æ–¹å‘ (SELL=å¤šå¤´è¢«æ¸…ç®—, BUY=ç©ºå¤´è¢«æ¸…ç®—)
        "o": "LIMIT",                    # è®¢å•ç±»å‹
        "f": "IOC",                      # æœ‰æ•ˆæ–¹å¼
        "q": "0.050",                    # æ•°é‡
        "p": "43000.00",                 # ä»·æ ¼
        "ap": "42980.00",                # å¹³å‡æˆäº¤ä»·
        "X": "FILLED",                   # è®¢å•çŠ¶æ€
        "l": "0.050",                    # æœ€æ–°æˆäº¤é‡
        "z": "0.050",                    # ç´¯è®¡æˆäº¤é‡
        "T": 1703001234560               # æˆäº¤æ—¶é—´
    }
}
```

**æ•°æ®å¯å¾—æ€§**:

| é¡¹ç›® | è¯´æ˜ |
|------|------|
| **è´¹ç”¨** | å…è´¹ï¼Œæ— éœ€ API Key |
| **å»¶è¿Ÿ** | å®æ—¶æ¨é€ (<100ms) |
| **å†å²æ•°æ®** | âŒ æ— å†å² APIï¼Œå¿…é¡»è‡ªå»ºè½ç›˜ (Bæ¡£) |
| **æ•°æ®é‡** | å¹³é™æœŸ: ~100æ¡/å°æ—¶ï¼Œæç«¯è¡Œæƒ…: ~10000æ¡/å°æ—¶ |

#### 12.12.3 æ–‡ä»¶ç»“æ„

```
algvex/core/data/collectors/
â”œâ”€â”€ liquidation.py              # LiquidationCollector (æ–°å¢)
â”‚
algvex/core/data/features/
â”œâ”€â”€ liquidation_features.py     # 5ä¸ªæ¸…ç®—å› å­è®¡ç®— (æ–°å¢)
â”‚
algvex/core/risk/
â”œâ”€â”€ liquidation_cascade.py      # æ¸…ç®—çº§è”æ£€æµ‹ (æ–°å¢)
â”‚
tests/p0/
â”œâ”€â”€ test_liquidation_collector.py
â”œâ”€â”€ test_liquidation_features.py
```

#### 12.12.4 LiquidationCollector å®ç°

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/collectors/liquidation.py`

```python
# algvex/core/data/collectors/liquidation.py

import asyncio
import json
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Dict, List, Optional, Callable
from collections import defaultdict
import numpy as np
import pandas as pd
import websockets

from .base import BaseCollector


@dataclass
class LiquidationEvent:
    """å•ç¬”æ¸…ç®—äº‹ä»¶"""
    timestamp: datetime
    symbol: str
    side: str                    # "LONG" æˆ– "SHORT" (è¢«æ¸…ç®—æ–¹å‘)
    quantity: float              # æ¸…ç®—æ•°é‡
    price: float                 # æ¸…ç®—ä»·æ ¼
    notional_usd: float          # æ¸…ç®—é‡‘é¢ (USD)


@dataclass
class AggregatedLiquidationBar:
    """èšåˆåçš„æ¸…ç®— Bar"""
    bar_time: datetime
    symbol: str

    # æ¸…ç®—é‡ç»Ÿè®¡
    volume_long: float           # å¤šå¤´æ¸…ç®—é‡‘é¢ (USD)
    volume_short: float          # ç©ºå¤´æ¸…ç®—é‡‘é¢ (USD)
    count_long: int              # å¤šå¤´æ¸…ç®—ç¬”æ•°
    count_short: int             # ç©ºå¤´æ¸…ç®—ç¬”æ•°

    # æ´¾ç”ŸæŒ‡æ ‡
    total_volume: float          # æ€»æ¸…ç®—é‡‘é¢
    imbalance: float             # å¤šç©ºä¸å¹³è¡¡ (-1 to 1)
    avg_size: float              # å¹³å‡å•ç¬”æ¸…ç®—é‡‘é¢

    # æç«¯è¡Œæƒ…æ ‡è®°
    is_spike: bool               # æ˜¯å¦ä¸ºæ¸…ç®—æ¿€å¢
    spike_ratio: float           # ç›¸å¯¹äºåŸºå‡†çš„å€æ•°

    # å…ƒæ•°æ®
    event_count: int             # bar å†…æ¸…ç®—äº‹ä»¶æ•°
    visibility: str = "bar_close"


class LiquidationCollector(BaseCollector):
    """
    å¸å®‰å¼ºå¹³æ•°æ®é‡‡é›†å™¨ (WebSocket)

    âš ï¸ å¯è§æ€§è§„åˆ™: bar_close
    - æ¸…ç®—æ•°æ®åœ¨ bar ç»“æŸåæ‰èƒ½ç”¨äºå› å­è®¡ç®—
    - é˜²æ­¢æœªæ¥ä¿¡æ¯æ³„éœ²

    âš ï¸ æ³¨æ„: 0 å€¼æ˜¯æ­£å¸¸çš„ (æ²¡æœ‰æ¸…ç®—å‘ç”Ÿ)ï¼Œä¸æ˜¯ç¼ºå¤±
    """

    # å¸å®‰ WebSocket é…ç½®
    WS_URL = "wss://fstream.binance.com/ws/!forceOrder@arr"

    # èšåˆé…ç½®
    BAR_FREQUENCIES = ["1m", "5m", "1h"]

    # æ¸…ç®—æ¿€å¢é˜ˆå€¼
    SPIKE_THRESHOLD = 3.0  # è¶…è¿‡24hå‡å€¼çš„3å€è§†ä¸º spike

    def __init__(self,
                 symbols: Optional[List[str]] = None,
                 bar_freq: str = "1h",
                 on_bar_complete: Optional[Callable] = None):
        """
        Args:
            symbols: è¦è¿½è¸ªçš„äº¤æ˜“å¯¹åˆ—è¡¨ (None=å…¨éƒ¨)
            bar_freq: èšåˆé¢‘ç‡ ("1m", "5m", "1h")
            on_bar_complete: bar å®Œæˆæ—¶çš„å›è°ƒå‡½æ•°
        """
        self.symbols = [s.upper() for s in symbols] if symbols else None
        self.bar_freq = bar_freq
        self.on_bar_complete = on_bar_complete

        # å†…å­˜ç¼“å†²åŒº: symbol -> å½“å‰ bar çš„äº‹ä»¶åˆ—è¡¨
        self._buffers: Dict[str, List[LiquidationEvent]] = defaultdict(list)

        # å½“å‰ bar å¼€å§‹æ—¶é—´
        self._current_bar_start: Dict[str, datetime] = {}

        # 24h æ»šåŠ¨å‡å€¼ (ç”¨äºè®¡ç®— spike)
        self._rolling_avg: Dict[str, float] = defaultdict(lambda: 0.0)
        self._rolling_count: Dict[str, int] = defaultdict(int)

        # è¿è¡ŒçŠ¶æ€
        self._running = False
        self._ws = None

    async def start(self):
        """å¯åŠ¨ WebSocket è¿æ¥å’Œæ•°æ®é‡‡é›†"""
        self._running = True

        while self._running:
            try:
                async with websockets.connect(self.WS_URL) as ws:
                    self._ws = ws
                    await self._receive_loop()
            except Exception as e:
                if self._running:
                    print(f"WebSocket disconnected: {e}, reconnecting in 5s...")
                    await asyncio.sleep(5)

    async def _receive_loop(self):
        """æ¥æ”¶å¹¶å¤„ç†æ¸…ç®—äº‹ä»¶"""
        async for message in self._ws:
            data = json.loads(message)

            # è§£ææ¸…ç®—äº‹ä»¶
            order = data.get("o", {})
            symbol = order.get("s", "")

            # è¿‡æ»¤äº¤æ˜“å¯¹
            if self.symbols and symbol not in self.symbols:
                continue

            # è§£ææ–¹å‘: SELL = å¤šå¤´è¢«æ¸…ç®—, BUY = ç©ºå¤´è¢«æ¸…ç®—
            side = "LONG" if order.get("S") == "SELL" else "SHORT"

            quantity = float(order.get("q", 0))
            price = float(order.get("ap", 0))  # ä½¿ç”¨å¹³å‡æˆäº¤ä»·
            notional = quantity * price

            event = LiquidationEvent(
                timestamp=datetime.fromtimestamp(
                    data.get("E", 0) / 1000, tz=timezone.utc
                ),
                symbol=symbol,
                side=side,
                quantity=quantity,
                price=price,
                notional_usd=notional,
            )

            # æ·»åŠ åˆ°ç¼“å†²åŒº
            self._add_to_buffer(event)

    def _add_to_buffer(self, event: LiquidationEvent):
        """æ·»åŠ äº‹ä»¶åˆ°ç¼“å†²åŒºï¼Œæ£€æŸ¥æ˜¯å¦éœ€è¦èšåˆ"""
        symbol = event.symbol

        # è®¡ç®—å½“å‰ bar å¼€å§‹æ—¶é—´
        bar_start = self._get_bar_start(event.timestamp)

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œæˆä¸Šä¸€ä¸ª bar
        if symbol in self._current_bar_start:
            if bar_start > self._current_bar_start[symbol]:
                # å®Œæˆä¸Šä¸€ä¸ª bar
                self._complete_bar(symbol, self._current_bar_start[symbol])
                self._buffers[symbol] = []

        self._current_bar_start[symbol] = bar_start
        self._buffers[symbol].append(event)

    def _get_bar_start(self, ts: datetime) -> datetime:
        """è®¡ç®— bar å¼€å§‹æ—¶é—´"""
        if self.bar_freq == "1m":
            return ts.replace(second=0, microsecond=0)
        elif self.bar_freq == "5m":
            minute = (ts.minute // 5) * 5
            return ts.replace(minute=minute, second=0, microsecond=0)
        elif self.bar_freq == "1h":
            return ts.replace(minute=0, second=0, microsecond=0)
        else:
            raise ValueError(f"Unsupported bar_freq: {self.bar_freq}")

    def _complete_bar(self, symbol: str, bar_time: datetime):
        """èšåˆå¹¶è¾“å‡ºä¸€ä¸ªå®Œæ•´çš„ bar"""
        events = self._buffers[symbol]

        # è®¡ç®—èšåˆæŒ‡æ ‡
        aggregated = self._aggregate_events(symbol, bar_time, events)

        # æ›´æ–°æ»šåŠ¨å‡å€¼
        self._update_rolling_avg(symbol, aggregated.total_volume)

        # å›è°ƒ
        if self.on_bar_complete:
            self.on_bar_complete(aggregated)

    def _aggregate_events(self,
                          symbol: str,
                          bar_time: datetime,
                          events: List[LiquidationEvent]) -> AggregatedLiquidationBar:
        """èšåˆæ¸…ç®—äº‹ä»¶ä¸º bar æ•°æ®"""

        volume_long = sum(e.notional_usd for e in events if e.side == "LONG")
        volume_short = sum(e.notional_usd for e in events if e.side == "SHORT")
        count_long = sum(1 for e in events if e.side == "LONG")
        count_short = sum(1 for e in events if e.side == "SHORT")

        total_volume = volume_long + volume_short
        total_count = count_long + count_short

        # è®¡ç®—ä¸å¹³è¡¡åº¦
        if total_volume > 0:
            imbalance = (volume_long - volume_short) / total_volume
        else:
            imbalance = 0.0

        # è®¡ç®—å¹³å‡å•ç¬”å¤§å°
        avg_size = total_volume / total_count if total_count > 0 else 0.0

        # åˆ¤æ–­æ˜¯å¦ä¸º spike
        rolling_avg = self._rolling_avg.get(symbol, 0)
        if rolling_avg > 0:
            spike_ratio = total_volume / rolling_avg
            is_spike = spike_ratio >= self.SPIKE_THRESHOLD
        else:
            spike_ratio = 0.0
            is_spike = False

        return AggregatedLiquidationBar(
            bar_time=bar_time,
            symbol=symbol,
            volume_long=volume_long,
            volume_short=volume_short,
            count_long=count_long,
            count_short=count_short,
            total_volume=total_volume,
            imbalance=imbalance,
            avg_size=avg_size,
            is_spike=is_spike,
            spike_ratio=spike_ratio,
            event_count=len(events),
        )

    def _update_rolling_avg(self, symbol: str, new_volume: float):
        """æ›´æ–°24hæ»šåŠ¨å‡å€¼ (ç®€åŒ–ç‰ˆ: æŒ‡æ•°ç§»åŠ¨å¹³å‡)"""
        alpha = 0.01  # å¹³æ»‘ç³»æ•°
        current = self._rolling_avg.get(symbol, new_volume)
        self._rolling_avg[symbol] = alpha * new_volume + (1 - alpha) * current

    async def stop(self):
        """åœæ­¢é‡‡é›†"""
        self._running = False
        if self._ws:
            await self._ws.close()


# ============== TimescaleDB å­˜å‚¨ ==============

LIQUIDATION_TABLE_SCHEMA = """
CREATE TABLE IF NOT EXISTS liquidation_bars (
    bar_time TIMESTAMPTZ NOT NULL,
    symbol VARCHAR(20) NOT NULL,

    -- æ¸…ç®—é‡
    volume_long DOUBLE PRECISION,
    volume_short DOUBLE PRECISION,
    count_long INTEGER,
    count_short INTEGER,

    -- æ´¾ç”ŸæŒ‡æ ‡
    total_volume DOUBLE PRECISION,
    imbalance DOUBLE PRECISION,
    avg_size DOUBLE PRECISION,

    -- æç«¯è¡Œæƒ…æ ‡è®°
    is_spike BOOLEAN,
    spike_ratio DOUBLE PRECISION,

    -- å…ƒæ•°æ®
    event_count INTEGER,

    PRIMARY KEY (bar_time, symbol)
);

-- åˆ›å»º hypertable
SELECT create_hypertable('liquidation_bars', 'bar_time', if_not_exists => TRUE);

-- ç´¢å¼•
CREATE INDEX IF NOT EXISTS idx_liquidation_symbol ON liquidation_bars (symbol, bar_time DESC);
CREATE INDEX IF NOT EXISTS idx_liquidation_spike ON liquidation_bars (is_spike, bar_time DESC);
"""
```

#### 12.12.5 æ¸…ç®—å› å­è®¡ç®—

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/features/liquidation_features.py`

```python
# algvex/core/data/features/liquidation_features.py

import pandas as pd
import numpy as np
from typing import Dict


class LiquidationFeatureCalculator:
    """
    æ¸…ç®—å› å­è®¡ç®—å™¨

    æ‰€æœ‰å› å­çš„å¯è§æ€§: bar_close
    """

    def calculate_features(self,
                          df: pd.DataFrame,
                          lookback_hours: int = 24) -> pd.DataFrame:
        """
        è®¡ç®—æ¸…ç®—å› å­

        Args:
            df: æ¸…ç®— bar æ•°æ® (ä» TimescaleDB æŸ¥è¯¢)
            lookback_hours: æ»šåŠ¨çª—å£å°æ—¶æ•°

        Returns:
            åŒ…å«æ¸…ç®—å› å­çš„ DataFrame
        """
        features = pd.DataFrame(index=df.index)

        # 1. æ¸…ç®—é‡ (å½’ä¸€åŒ–åˆ°æ—¥å‡å€¼)
        features['liquidation_volume_long'] = self._normalize_volume(
            df['volume_long'], lookback_hours
        )
        features['liquidation_volume_short'] = self._normalize_volume(
            df['volume_short'], lookback_hours
        )

        # 2. æ¸…ç®—ä¸å¹³è¡¡åº¦ (-1 to 1)
        features['liquidation_imbalance'] = df['imbalance']

        # 3. æ¸…ç®—æ¿€å¢æŒ‡æ ‡ (spike detection)
        features['liquidation_spike'] = df['spike_ratio'].clip(0, 10)  # ä¸Šé™10å€

        # 4. æ¸…ç®—åŠ¨é‡ (volume å˜åŒ–è¶‹åŠ¿)
        features['liquidation_momentum'] = self._calculate_momentum(
            df['total_volume'], lookback_hours
        )

        return features

    def _normalize_volume(self,
                         series: pd.Series,
                         lookback_hours: int) -> pd.Series:
        """å½’ä¸€åŒ–æ¸…ç®—é‡ (ç›¸å¯¹äºæ»šåŠ¨å‡å€¼)"""
        # å‡è®¾ 1h bar
        rolling_mean = series.rolling(window=lookback_hours, min_periods=1).mean()
        normalized = series / (rolling_mean + 1e-8)  # é¿å…é™¤é›¶
        return normalized.clip(0, 10)  # ä¸Šé™10å€

    def _calculate_momentum(self,
                           series: pd.Series,
                           lookback_hours: int) -> pd.Series:
        """è®¡ç®—æ¸…ç®—åŠ¨é‡ (çŸ­æœŸ vs é•¿æœŸ)"""
        short_window = max(1, lookback_hours // 6)  # 4h
        long_window = lookback_hours  # 24h

        short_ma = series.rolling(window=short_window, min_periods=1).mean()
        long_ma = series.rolling(window=long_window, min_periods=1).mean()

        momentum = (short_ma - long_ma) / (long_ma + 1e-8)
        return momentum.clip(-5, 5)  # é™åˆ¶èŒƒå›´


# ============== å¯è§æ€§é…ç½® ==============

LIQUIDATION_VISIBILITY = {
    "liquidation_volume_long": "bar_close",
    "liquidation_volume_short": "bar_close",
    "liquidation_imbalance": "bar_close",
    "liquidation_spike": "bar_close",
    "liquidation_momentum": "bar_close",
}
```

#### 12.12.6 æ¸…ç®—çº§è”æ£€æµ‹ (é£æ§é›†æˆ)

**æ–‡ä»¶ä½ç½®**: `algvex/core/risk/liquidation_cascade.py`

```python
# algvex/core/risk/liquidation_cascade.py

from dataclasses import dataclass
from typing import Optional
from datetime import datetime, timedelta
import pandas as pd


@dataclass
class CascadeAlert:
    """æ¸…ç®—çº§è”å‘Šè­¦"""
    timestamp: datetime
    symbol: str
    severity: str              # "warning" / "critical"
    spike_ratio: float
    imbalance: float
    recommendation: str        # "reduce_position" / "pause_new_orders"


class LiquidationCascadeDetector:
    """
    æ¸…ç®—çº§è”æ£€æµ‹å™¨

    ç”¨é€”:
    - æ£€æµ‹æç«¯è¡Œæƒ…é£é™©
    - è§¦å‘é£æ§é™ä»“ / æš‚åœå¼€ä»“
    """

    # å‘Šè­¦é˜ˆå€¼
    WARNING_SPIKE_RATIO = 3.0    # 3å€å‡å€¼
    CRITICAL_SPIKE_RATIO = 5.0   # 5å€å‡å€¼

    # è¿ç»­ spike æ£€æµ‹
    CONSECUTIVE_THRESHOLD = 3    # è¿ç»­3ä¸ªbaréƒ½æ˜¯spike

    def __init__(self, data_manager):
        self.data_manager = data_manager
        self._recent_spikes: dict = {}  # symbol -> spike count

    def check(self, symbol: str) -> Optional[CascadeAlert]:
        """
        æ£€æŸ¥æ˜¯å¦å­˜åœ¨æ¸…ç®—çº§è”é£é™©

        Returns:
            CascadeAlert if risk detected, None otherwise
        """
        # è·å–æœ€è¿‘çš„æ¸…ç®—æ•°æ®
        recent_bars = self.data_manager.get_liquidation_bars(
            symbol=symbol,
            lookback="3h",
        )

        if recent_bars.empty:
            return None

        latest = recent_bars.iloc[-1]

        # æ£€æŸ¥ spike
        if latest['is_spike']:
            self._recent_spikes[symbol] = self._recent_spikes.get(symbol, 0) + 1
        else:
            self._recent_spikes[symbol] = 0

        # åˆ¤æ–­å‘Šè­¦çº§åˆ«
        spike_ratio = latest['spike_ratio']
        consecutive_count = self._recent_spikes.get(symbol, 0)

        if spike_ratio >= self.CRITICAL_SPIKE_RATIO or consecutive_count >= self.CONSECUTIVE_THRESHOLD:
            return CascadeAlert(
                timestamp=datetime.now(),
                symbol=symbol,
                severity="critical",
                spike_ratio=spike_ratio,
                imbalance=latest['imbalance'],
                recommendation="pause_new_orders",
            )
        elif spike_ratio >= self.WARNING_SPIKE_RATIO:
            return CascadeAlert(
                timestamp=datetime.now(),
                symbol=symbol,
                severity="warning",
                spike_ratio=spike_ratio,
                imbalance=latest['imbalance'],
                recommendation="reduce_position",
            )

        return None


# ============== ä¸ RiskManager é›†æˆ ==============

class RiskManagerWithLiquidation:
    """æ‰©å±• RiskManager ä»¥æ”¯æŒæ¸…ç®—çº§è”æ£€æµ‹"""

    def __init__(self, base_risk_manager, cascade_detector):
        self.base = base_risk_manager
        self.cascade_detector = cascade_detector

    def check_order(self, order) -> bool:
        """æ£€æŸ¥è®¢å•æ˜¯å¦å…è®¸æ‰§è¡Œ"""

        # 1. åŸºç¡€é£æ§æ£€æŸ¥
        if not self.base.check_order(order):
            return False

        # 2. æ¸…ç®—çº§è”æ£€æŸ¥
        alert = self.cascade_detector.check(order.symbol)
        if alert:
            if alert.severity == "critical":
                # æš‚åœæ‰€æœ‰æ–°è®¢å•
                return False
            elif alert.severity == "warning":
                # åªå…è®¸å‡ä»“è®¢å•
                if order.is_reduce_only:
                    return True
                return False

        return True
```

#### 12.12.7 æµ‹è¯•ç”¨ä¾‹

```python
# tests/p0/test_liquidation_collector.py

import pytest
from datetime import datetime, timezone
from algvex.core.data.collectors.liquidation import (
    LiquidationCollector, LiquidationEvent, AggregatedLiquidationBar
)


class TestLiquidationEvent:
    """æ¸…ç®—äº‹ä»¶æµ‹è¯•"""

    def test_parse_long_liquidation(self):
        """å¤šå¤´æ¸…ç®—è§£æ"""
        raw = {
            "e": "forceOrder",
            "E": 1703001234567,
            "o": {
                "s": "BTCUSDT",
                "S": "SELL",  # å–å‡º = å¤šå¤´è¢«æ¸…ç®—
                "q": "0.1",
                "ap": "43000.00",
            }
        }
        # è§£æå side åº”ä¸º "LONG"
        # notional = 0.1 * 43000 = 4300 USD

    def test_parse_short_liquidation(self):
        """ç©ºå¤´æ¸…ç®—è§£æ"""
        raw = {
            "o": {
                "s": "BTCUSDT",
                "S": "BUY",  # ä¹°å…¥ = ç©ºå¤´è¢«æ¸…ç®—
                "q": "0.2",
                "ap": "43500.00",
            }
        }
        # è§£æå side åº”ä¸º "SHORT"


class TestAggregation:
    """èšåˆé€»è¾‘æµ‹è¯•"""

    def test_imbalance_calculation(self):
        """ä¸å¹³è¡¡åº¦è®¡ç®—"""
        events = [
            LiquidationEvent(..., side="LONG", notional_usd=100000),
            LiquidationEvent(..., side="SHORT", notional_usd=50000),
        ]
        # imbalance = (100000 - 50000) / 150000 = 0.333

    def test_spike_detection(self):
        """æ¸…ç®—æ¿€å¢æ£€æµ‹"""
        # å½“ volume è¶…è¿‡ 24h å‡å€¼çš„ 3 å€æ—¶ï¼Œis_spike = True


class TestCascadeDetector:
    """æ¸…ç®—çº§è”æ£€æµ‹æµ‹è¯•"""

    def test_warning_alert(self):
        """è­¦å‘Šçº§åˆ«å‘Šè­¦"""
        # spike_ratio >= 3.0 æ—¶è§¦å‘ warning

    def test_critical_alert(self):
        """ä¸¥é‡çº§åˆ«å‘Šè­¦"""
        # spike_ratio >= 5.0 æˆ–è¿ç»­ 3 ä¸ª spike æ—¶è§¦å‘ critical
```

#### 12.12.8 éªŒæ”¶æ ‡å‡†

| éªŒæ”¶é¡¹ | æè¿° | æµ‹è¯•æ–¹æ³• | çŠ¶æ€ |
|--------|------|----------|------|
| LiquidationCollector | WebSocket è¿æ¥ç¨³å®šï¼Œèƒ½é‡‡é›†æ¸…ç®—äº‹ä»¶ | è¿è¡Œ 24h éªŒè¯ | â¬œ |
| äº‹ä»¶è§£æ | æ­£ç¡®åŒºåˆ†å¤šå¤´/ç©ºå¤´æ¸…ç®— | å•å…ƒæµ‹è¯• | â¬œ |
| Bar èšåˆ | 1m/5m/1h èšåˆé€»è¾‘æ­£ç¡® | å•å…ƒæµ‹è¯• | â¬œ |
| 5ä¸ªæ¸…ç®—å› å­ | æ‰€æœ‰å› å­è®¡ç®—æ­£ç¡® | å•å…ƒæµ‹è¯• | â¬œ |
| Spike æ£€æµ‹ | æ¸…ç®—æ¿€å¢æ­£ç¡®æ ‡è®° | å›æ”¾æµ‹è¯• | â¬œ |
| çº§è”æ£€æµ‹ | è¿ç»­ spike æ­£ç¡®è§¦å‘ critical | æ¨¡æ‹Ÿæµ‹è¯• | â¬œ |
| é£æ§é›†æˆ | RiskManager æ­£ç¡®å“åº”å‘Šè­¦ | é›†æˆæµ‹è¯• | â¬œ |
| å¯è§æ€§ | bar_close è§„åˆ™æ— æ³„éœ² | æ³„éœ²æ£€æµ‹æµ‹è¯• | â¬œ |
| TimescaleDB | æ•°æ®æ­£ç¡®å†™å…¥å’ŒæŸ¥è¯¢ | å‹åŠ›æµ‹è¯• | â¬œ |
| é›¶å€¼å¤„ç† | æ— æ¸…ç®—æ—¶æ­£ç¡®è®°å½• 0 è€Œé NULL | å•å…ƒæµ‹è¯• | â¬œ |

---

### 12.13 Step 11: å¤šäº¤æ˜“æ‰€ Basis/ä»·å·®çŸ©é˜µ

> **å¢é‡ä»·å€¼**: å•ä¸€äº¤æ˜“æ‰€ basis å®¹æ˜“è¢«å±€éƒ¨æµåŠ¨æ€§æ‰­æ›²ï¼Œå¤šäº¤æ˜“æ‰€èƒ½æ£€æµ‹"ç»“æ„æ€§åç¦»"ä¸"å¥—åˆ©å‹åŠ›"ã€‚
>
> **å·¥ç¨‹å¤æ‚åº¦**: ä½ã€‚REST API è½®è¯¢ï¼Œæ— éœ€ WebSocketã€‚
>
> **æ•°æ®å¯å¾—æ€§**: Cæ¡£ (éœ€è‡ªè¡Œè®¡ç®—å’Œè½ç›˜)

#### 12.13.1 æ¶æ„æ¦‚è§ˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Step 11: å¤šäº¤æ˜“æ‰€ Basis/ä»·å·®çŸ©é˜µ                          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    1. MultiExchangeCollector (REST)                 â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   Binance â”€â”                                                        â”‚   â”‚
â”‚  â”‚   Bybit   â”€â”¼â”€â”€â†’ ä»·æ ¼å¯¹é½ (asof) â”€â”€â†’ Basisè®¡ç®— â”€â”€â†’ TimescaleDB      â”‚   â”‚
â”‚  â”‚   OKX     â”€â”˜      (UTCç»Ÿä¸€)          (bar_close)    (æŒä¹…åŒ–)        â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   âš ï¸ å¯è§æ€§: bar_close                                               â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    2. Basis å› å­è®¡ç®— (8ä¸ªæ ¸å¿ƒæŒ‡æ ‡)                    â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   basis_binance/bybit/okx, basis_consensus, basis_dispersion,       â”‚   â”‚
â”‚  â”‚   cross_exchange_spread, price_discovery_leader, arbitrage_pressure â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                    â†“                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚                    3. å¥—åˆ©å‹åŠ›ä¿¡å·                                    â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â”‚   è·¨æ‰€ä»·å·®å¼‚å¸¸ â†’ å¯èƒ½é¢„ç¤ºå¤§é¢èµ„é‡‘æµåŠ¨ / ä»·æ ¼ç»“æ„è°ƒæ•´                   â”‚   â”‚
â”‚  â”‚                                                                      â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 12.13.2 æ•°æ®æºä¸è·å–æ–¹å¼

**ä¸‰ä¸ªäº¤æ˜“æ‰€çš„ä»·æ ¼ API (å…¨éƒ¨å…è´¹)**:

| äº¤æ˜“æ‰€ | ç°è´§ API | æ°¸ç»­ API | é¢‘ç‡é™åˆ¶ |
|--------|----------|----------|----------|
| **Binance** | `GET /api/v3/ticker/price` | `GET /fapi/v1/ticker/price` | 1200/min |
| **Bybit** | `GET /v5/market/tickers?category=spot` | `GET /v5/market/tickers?category=linear` | 600/min |
| **OKX** | `GET /api/v5/market/ticker?instId=BTC-USDT` | `GET /api/v5/market/ticker?instId=BTC-USDT-SWAP` | 20/2s |

**Symbol æ˜ å°„**:

```python
SYMBOL_MAPPING = {
    "BTCUSDT": {
        "binance_spot": "BTCUSDT",
        "binance_perp": "BTCUSDT",
        "bybit_spot": "BTCUSDT",
        "bybit_perp": "BTCUSDT",
        "okx_spot": "BTC-USDT",
        "okx_perp": "BTC-USDT-SWAP",
    },
    "ETHUSDT": {
        "binance_spot": "ETHUSDT",
        "binance_perp": "ETHUSDT",
        "bybit_spot": "ETHUSDT",
        "bybit_perp": "ETHUSDT",
        "okx_spot": "ETH-USDT",
        "okx_perp": "ETH-USDT-SWAP",
    },
    # ... æ›´å¤šäº¤æ˜“å¯¹
}
```

#### 12.13.3 æ–‡ä»¶ç»“æ„

```
algvex/core/data/collectors/
â”œâ”€â”€ multi_exchange.py           # MultiExchangeCollector (æ–°å¢)
â”‚
algvex/core/data/features/
â”œâ”€â”€ basis_features.py           # 8ä¸ª basis å› å­è®¡ç®— (æ–°å¢)
â”‚
algvex/core/config/
â”œâ”€â”€ exchange_symbols.py         # Symbol æ˜ å°„é…ç½® (æ–°å¢)
â”‚
tests/p0/
â”œâ”€â”€ test_multi_exchange_collector.py
â”œâ”€â”€ test_basis_features.py
```

#### 12.13.4 MultiExchangeCollector å®ç°

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/collectors/multi_exchange.py`

```python
# algvex/core/data/collectors/multi_exchange.py

import asyncio
import aiohttp
from dataclasses import dataclass
from datetime import datetime, timezone
from typing import Dict, List, Optional
import pandas as pd

from .base import BaseCollector
from ..config.exchange_symbols import SYMBOL_MAPPING


@dataclass
class ExchangePrice:
    """å•ä¸ªäº¤æ˜“æ‰€çš„ä»·æ ¼å¿«ç…§"""
    timestamp: datetime
    exchange: str            # "binance" / "bybit" / "okx"
    symbol: str              # ç»Ÿä¸€ symbol (å¦‚ "BTCUSDT")
    spot_price: float
    perp_price: float
    basis_bps: float         # (spot - perp) / spot * 10000


@dataclass
class AggregatedBasisBar:
    """èšåˆåçš„ Basis Bar"""
    bar_time: datetime
    symbol: str

    # å„äº¤æ˜“æ‰€ basis (bps)
    basis_binance: float
    basis_bybit: float
    basis_okx: float

    # å…±è¯† basis
    basis_consensus: float   # median
    basis_dispersion: float  # std

    # è·¨æ‰€ä»·å·®
    cross_exchange_spread_spot: float   # max - min (bps)
    cross_exchange_spread_perp: float   # max - min (bps)

    # å¥—åˆ©å‹åŠ›æŒ‡æ ‡
    arbitrage_pressure: float  # ä»·å·®å›å½’é€Ÿåº¦

    # å…ƒæ•°æ®
    sample_count: int
    visibility: str = "bar_close"


class MultiExchangeCollector(BaseCollector):
    """
    å¤šäº¤æ˜“æ‰€ä»·æ ¼é‡‡é›†å™¨ (REST API è½®è¯¢)

    âš ï¸ å¯è§æ€§è§„åˆ™: bar_close
    - Basis æ•°æ®åœ¨ bar ç»“æŸåæ‰èƒ½ç”¨äºå› å­è®¡ç®—

    é‡‡é›†é¢‘ç‡: æ¯åˆ†é’Ÿä¸€æ¬¡ (ç¬¦åˆæ‰€æœ‰äº¤æ˜“æ‰€çš„é¢‘ç‡é™åˆ¶)
    """

    # äº¤æ˜“æ‰€ API é…ç½®
    EXCHANGES = {
        "binance": {
            "spot_url": "https://api.binance.com/api/v3/ticker/price",
            "perp_url": "https://fapi.binance.com/fapi/v1/ticker/price",
        },
        "bybit": {
            "spot_url": "https://api.bybit.com/v5/market/tickers",
            "perp_url": "https://api.bybit.com/v5/market/tickers",
        },
        "okx": {
            "base_url": "https://www.okx.com/api/v5/market/ticker",
        },
    }

    def __init__(self,
                 symbols: List[str],
                 poll_interval: int = 60,
                 bar_freq: str = "1m"):
        """
        Args:
            symbols: ç»Ÿä¸€ symbol åˆ—è¡¨ (å¦‚ ["BTCUSDT", "ETHUSDT"])
            poll_interval: è½®è¯¢é—´éš” (ç§’)
            bar_freq: èšåˆé¢‘ç‡
        """
        self.symbols = symbols
        self.poll_interval = poll_interval
        self.bar_freq = bar_freq

        # å†…å­˜ç¼“å†²åŒº
        self._buffers: Dict[str, List[ExchangePrice]] = {}
        self._current_bar_start: Dict[str, datetime] = {}

        self._running = False
        self._session: Optional[aiohttp.ClientSession] = None

    async def start(self):
        """å¯åŠ¨è½®è¯¢é‡‡é›†"""
        self._running = True
        self._session = aiohttp.ClientSession()

        while self._running:
            try:
                await self._poll_all_exchanges()
                await asyncio.sleep(self.poll_interval)
            except Exception as e:
                print(f"Poll error: {e}")
                await asyncio.sleep(5)

    async def _poll_all_exchanges(self):
        """è½®è¯¢æ‰€æœ‰äº¤æ˜“æ‰€"""
        timestamp = datetime.now(timezone.utc)

        # å¹¶å‘è·å–æ‰€æœ‰äº¤æ˜“æ‰€ä»·æ ¼
        tasks = [
            self._fetch_binance_prices(timestamp),
            self._fetch_bybit_prices(timestamp),
            self._fetch_okx_prices(timestamp),
        ]
        results = await asyncio.gather(*tasks, return_exceptions=True)

        # åˆå¹¶ç»“æœ
        for result in results:
            if isinstance(result, list):
                for price in result:
                    self._add_to_buffer(price)

    async def _fetch_binance_prices(self, timestamp: datetime) -> List[ExchangePrice]:
        """è·å–å¸å®‰ä»·æ ¼"""
        prices = []

        try:
            # è·å–ç°è´§ä»·æ ¼
            async with self._session.get(self.EXCHANGES["binance"]["spot_url"]) as resp:
                spot_data = {item["symbol"]: float(item["price"])
                            for item in await resp.json()}

            # è·å–æ°¸ç»­ä»·æ ¼
            async with self._session.get(self.EXCHANGES["binance"]["perp_url"]) as resp:
                perp_data = {item["symbol"]: float(item["price"])
                            for item in await resp.json()}

            # è®¡ç®— basis
            for symbol in self.symbols:
                mapping = SYMBOL_MAPPING.get(symbol, {})
                spot_sym = mapping.get("binance_spot", symbol)
                perp_sym = mapping.get("binance_perp", symbol)

                if spot_sym in spot_data and perp_sym in perp_data:
                    spot = spot_data[spot_sym]
                    perp = perp_data[perp_sym]
                    basis_bps = (spot - perp) / spot * 10000

                    prices.append(ExchangePrice(
                        timestamp=timestamp,
                        exchange="binance",
                        symbol=symbol,
                        spot_price=spot,
                        perp_price=perp,
                        basis_bps=basis_bps,
                    ))

        except Exception as e:
            print(f"Binance fetch error: {e}")

        return prices

    async def _fetch_bybit_prices(self, timestamp: datetime) -> List[ExchangePrice]:
        """è·å– Bybit ä»·æ ¼"""
        prices = []

        try:
            # ç°è´§
            url = f"{self.EXCHANGES['bybit']['spot_url']}?category=spot"
            async with self._session.get(url) as resp:
                data = await resp.json()
                spot_data = {item["symbol"]: float(item["lastPrice"])
                            for item in data.get("result", {}).get("list", [])}

            # æ°¸ç»­
            url = f"{self.EXCHANGES['bybit']['perp_url']}?category=linear"
            async with self._session.get(url) as resp:
                data = await resp.json()
                perp_data = {item["symbol"]: float(item["lastPrice"])
                            for item in data.get("result", {}).get("list", [])}

            for symbol in self.symbols:
                mapping = SYMBOL_MAPPING.get(symbol, {})
                spot_sym = mapping.get("bybit_spot", symbol)
                perp_sym = mapping.get("bybit_perp", symbol)

                if spot_sym in spot_data and perp_sym in perp_data:
                    spot = spot_data[spot_sym]
                    perp = perp_data[perp_sym]
                    basis_bps = (spot - perp) / spot * 10000

                    prices.append(ExchangePrice(
                        timestamp=timestamp,
                        exchange="bybit",
                        symbol=symbol,
                        spot_price=spot,
                        perp_price=perp,
                        basis_bps=basis_bps,
                    ))

        except Exception as e:
            print(f"Bybit fetch error: {e}")

        return prices

    async def _fetch_okx_prices(self, timestamp: datetime) -> List[ExchangePrice]:
        """è·å– OKX ä»·æ ¼"""
        prices = []

        for symbol in self.symbols:
            try:
                mapping = SYMBOL_MAPPING.get(symbol, {})
                spot_sym = mapping.get("okx_spot")
                perp_sym = mapping.get("okx_perp")

                if not spot_sym or not perp_sym:
                    continue

                # ç°è´§
                url = f"{self.EXCHANGES['okx']['base_url']}?instId={spot_sym}"
                async with self._session.get(url) as resp:
                    data = await resp.json()
                    spot = float(data["data"][0]["last"])

                # æ°¸ç»­
                url = f"{self.EXCHANGES['okx']['base_url']}?instId={perp_sym}"
                async with self._session.get(url) as resp:
                    data = await resp.json()
                    perp = float(data["data"][0]["last"])

                basis_bps = (spot - perp) / spot * 10000

                prices.append(ExchangePrice(
                    timestamp=timestamp,
                    exchange="okx",
                    symbol=symbol,
                    spot_price=spot,
                    perp_price=perp,
                    basis_bps=basis_bps,
                ))

            except Exception as e:
                print(f"OKX fetch error for {symbol}: {e}")

        return prices

    def _add_to_buffer(self, price: ExchangePrice):
        """æ·»åŠ åˆ°ç¼“å†²åŒº"""
        key = f"{price.symbol}_{price.exchange}"
        bar_start = self._get_bar_start(price.timestamp)

        if key not in self._buffers:
            self._buffers[key] = []
            self._current_bar_start[key] = bar_start

        # æ£€æŸ¥æ˜¯å¦éœ€è¦å®Œæˆä¸Šä¸€ä¸ª bar (ç®€åŒ–: ç”±å¤–éƒ¨å®šæ—¶å™¨è§¦å‘)
        self._buffers[key].append(price)

    def _get_bar_start(self, ts: datetime) -> datetime:
        """è®¡ç®— bar å¼€å§‹æ—¶é—´"""
        if self.bar_freq == "1m":
            return ts.replace(second=0, microsecond=0)
        elif self.bar_freq == "5m":
            minute = (ts.minute // 5) * 5
            return ts.replace(minute=minute, second=0, microsecond=0)
        else:
            return ts.replace(minute=0, second=0, microsecond=0)

    async def stop(self):
        """åœæ­¢é‡‡é›†"""
        self._running = False
        if self._session:
            await self._session.close()


# ============== TimescaleDB å­˜å‚¨ ==============

BASIS_TABLE_SCHEMA = """
CREATE TABLE IF NOT EXISTS basis_bars (
    bar_time TIMESTAMPTZ NOT NULL,
    symbol VARCHAR(20) NOT NULL,

    -- å„äº¤æ˜“æ‰€ basis (bps)
    basis_binance DOUBLE PRECISION,
    basis_bybit DOUBLE PRECISION,
    basis_okx DOUBLE PRECISION,

    -- å…±è¯† basis
    basis_consensus DOUBLE PRECISION,
    basis_dispersion DOUBLE PRECISION,

    -- è·¨æ‰€ä»·å·®
    cross_exchange_spread_spot DOUBLE PRECISION,
    cross_exchange_spread_perp DOUBLE PRECISION,

    -- å¥—åˆ©å‹åŠ›
    arbitrage_pressure DOUBLE PRECISION,

    -- å…ƒæ•°æ®
    sample_count INTEGER,

    PRIMARY KEY (bar_time, symbol)
);

SELECT create_hypertable('basis_bars', 'bar_time', if_not_exists => TRUE);
CREATE INDEX IF NOT EXISTS idx_basis_symbol ON basis_bars (symbol, bar_time DESC);
"""
```

#### 12.13.5 Basis å› å­è®¡ç®—

**æ–‡ä»¶ä½ç½®**: `algvex/core/data/features/basis_features.py`

```python
# algvex/core/data/features/basis_features.py

import pandas as pd
import numpy as np
from typing import Dict, List


class BasisFeatureCalculator:
    """
    Basis å› å­è®¡ç®—å™¨

    æ‰€æœ‰å› å­çš„å¯è§æ€§: bar_close
    """

    def calculate_features(self,
                          df: pd.DataFrame,
                          lookback_hours: int = 24) -> pd.DataFrame:
        """
        è®¡ç®— Basis å› å­

        Args:
            df: Basis bar æ•°æ®
            lookback_hours: æ»šåŠ¨çª—å£

        Returns:
            åŒ…å« Basis å› å­çš„ DataFrame
        """
        features = pd.DataFrame(index=df.index)

        # 1. å„äº¤æ˜“æ‰€ basis (å½’ä¸€åŒ–)
        features['basis_binance'] = df['basis_binance']
        features['basis_bybit'] = df['basis_bybit']
        features['basis_okx'] = df['basis_okx']

        # 2. å…±è¯† basis (ä¸­ä½æ•°)
        basis_cols = ['basis_binance', 'basis_bybit', 'basis_okx']
        features['basis_consensus'] = df[basis_cols].median(axis=1)

        # 3. Basis åˆ†æ•£åº¦ (æ ‡å‡†å·®)
        features['basis_dispersion'] = df[basis_cols].std(axis=1)

        # 4. è·¨æ‰€ä»·å·®
        features['cross_exchange_spread'] = df['cross_exchange_spread_perp']

        # 5. ä»·æ ¼å‘ç°é¢†å¯¼è€… (å“ªä¸ªäº¤æ˜“æ‰€çš„ basis å˜åŒ–é¢†å…ˆ)
        features['price_discovery_leader'] = self._calculate_price_discovery(
            df, lookback_hours
        )

        # 6. å¥—åˆ©å‹åŠ› (ä»·å·®æ”¶æ•›é€Ÿåº¦)
        features['arbitrage_pressure'] = self._calculate_arbitrage_pressure(
            df['cross_exchange_spread_perp'], lookback_hours
        )

        return features

    def _calculate_price_discovery(self,
                                   df: pd.DataFrame,
                                   lookback_hours: int) -> pd.Series:
        """
        è®¡ç®—ä»·æ ¼å‘ç°é¢†å¯¼è€…

        ä½¿ç”¨å„äº¤æ˜“æ‰€ basis å˜åŒ–çš„é¢†å…ˆæ€§ (ç®€åŒ–ç‰ˆ: å˜åŒ–å¹…åº¦æœ€å¤§çš„)
        """
        basis_changes = pd.DataFrame({
            'binance': df['basis_binance'].diff().abs(),
            'bybit': df['basis_bybit'].diff().abs(),
            'okx': df['basis_okx'].diff().abs(),
        })

        # è¿”å›å˜åŒ–æœ€å¤§çš„äº¤æ˜“æ‰€ (ç¼–ç : binance=1, bybit=2, okx=3)
        leader_map = {'binance': 1, 'bybit': 2, 'okx': 3}
        leader = basis_changes.idxmax(axis=1)
        return leader.map(leader_map).fillna(0)

    def _calculate_arbitrage_pressure(self,
                                      spread: pd.Series,
                                      lookback_hours: int) -> pd.Series:
        """
        è®¡ç®—å¥—åˆ©å‹åŠ›

        ä»·å·®è¶Šå¤§ã€æ”¶æ•›è¶Šæ…¢ â†’ å¥—åˆ©å‹åŠ›è¶Šå¤§
        """
        # è®¡ç®—ä»·å·®çš„è‡ªç›¸å…³è¡°å‡
        spread_ma = spread.rolling(window=lookback_hours, min_periods=1).mean()
        deviation = (spread - spread_ma).abs()

        # å½’ä¸€åŒ–
        normalized = deviation / (spread_ma.abs() + 1e-8)
        return normalized.clip(0, 5)


# ============== å¯è§æ€§é…ç½® ==============

BASIS_VISIBILITY = {
    "basis_binance": "bar_close",
    "basis_bybit": "bar_close",
    "basis_okx": "bar_close",
    "basis_consensus": "bar_close",
    "basis_dispersion": "bar_close",
    "cross_exchange_spread": "bar_close",
    "price_discovery_leader": "bar_close",
    "arbitrage_pressure": "bar_close",
}
```

#### 12.13.6 æµ‹è¯•ç”¨ä¾‹

```python
# tests/p0/test_multi_exchange_collector.py

import pytest
from algvex.core.data.collectors.multi_exchange import (
    MultiExchangeCollector, ExchangePrice
)


class TestSymbolMapping:
    """Symbol æ˜ å°„æµ‹è¯•"""

    def test_binance_mapping(self):
        """å¸å®‰ symbol æ˜ å°„æ­£ç¡®"""
        from algvex.core.config.exchange_symbols import SYMBOL_MAPPING
        assert SYMBOL_MAPPING["BTCUSDT"]["binance_spot"] == "BTCUSDT"
        assert SYMBOL_MAPPING["BTCUSDT"]["binance_perp"] == "BTCUSDT"

    def test_okx_mapping(self):
        """OKX symbol æ˜ å°„æ­£ç¡®"""
        from algvex.core.config.exchange_symbols import SYMBOL_MAPPING
        assert SYMBOL_MAPPING["BTCUSDT"]["okx_spot"] == "BTC-USDT"
        assert SYMBOL_MAPPING["BTCUSDT"]["okx_perp"] == "BTC-USDT-SWAP"


class TestBasisCalculation:
    """Basis è®¡ç®—æµ‹è¯•"""

    def test_basis_positive(self):
        """ç°è´§ > æ°¸ç»­æ—¶ basis ä¸ºæ­£"""
        spot = 43500
        perp = 43400
        basis_bps = (spot - perp) / spot * 10000
        assert basis_bps > 0

    def test_basis_negative(self):
        """ç°è´§ < æ°¸ç»­æ—¶ basis ä¸ºè´Ÿ (contango)"""
        spot = 43400
        perp = 43500
        basis_bps = (spot - perp) / spot * 10000
        assert basis_bps < 0


class TestConsensus:
    """å…±è¯† Basis æµ‹è¯•"""

    def test_median_calculation(self):
        """ä¸­ä½æ•°è®¡ç®—æ­£ç¡®"""
        import numpy as np
        basis_values = [10, 15, 12]  # bps
        consensus = np.median(basis_values)
        assert consensus == 12
```

#### 12.13.7 éªŒæ”¶æ ‡å‡†

| éªŒæ”¶é¡¹ | æè¿° | æµ‹è¯•æ–¹æ³• | çŠ¶æ€ |
|--------|------|----------|------|
| Binance Collector | èƒ½æ­£ç¡®è·å–ç°è´§/æ°¸ç»­ä»·æ ¼ | API æµ‹è¯• | â¬œ |
| Bybit Collector | èƒ½æ­£ç¡®è·å–ç°è´§/æ°¸ç»­ä»·æ ¼ | API æµ‹è¯• | â¬œ |
| OKX Collector | èƒ½æ­£ç¡®è·å–ç°è´§/æ°¸ç»­ä»·æ ¼ | API æµ‹è¯• | â¬œ |
| Symbol æ˜ å°„ | å„äº¤æ˜“æ‰€ symbol æ­£ç¡®æ˜ å°„ | å•å…ƒæµ‹è¯• | â¬œ |
| æ—¶åŒºå¯¹é½ | æ‰€æœ‰ä»·æ ¼ç»Ÿä¸€ä¸º UTC | å•å…ƒæµ‹è¯• | â¬œ |
| Basis è®¡ç®— | å„äº¤æ˜“æ‰€ basis è®¡ç®—æ­£ç¡® | å•å…ƒæµ‹è¯• | â¬œ |
| å…±è¯† Basis | ä¸­ä½æ•°å’Œæ ‡å‡†å·®è®¡ç®—æ­£ç¡® | å•å…ƒæµ‹è¯• | â¬œ |
| è·¨æ‰€ä»·å·® | spot/perp ä»·å·®è®¡ç®—æ­£ç¡® | å•å…ƒæµ‹è¯• | â¬œ |
| 8ä¸ª Basis å› å­ | æ‰€æœ‰å› å­è®¡ç®—æ­£ç¡® | å•å…ƒæµ‹è¯• | â¬œ |
| å¯è§æ€§ | bar_close è§„åˆ™æ— æ³„éœ² | æ³„éœ²æ£€æµ‹æµ‹è¯• | â¬œ |
| é¢‘ç‡é™åˆ¶ | ä¸è¶…è¿‡å„äº¤æ˜“æ‰€ API é™åˆ¶ | å‹åŠ›æµ‹è¯• | â¬œ |
| TimescaleDB | æ•°æ®æ­£ç¡®å†™å…¥å’ŒæŸ¥è¯¢ | é›†æˆæµ‹è¯• | â¬œ |

---

### 12.14 æ•°æ®æ‰©å±•è·¯çº¿å›¾ (P2/P3 åç»­)

> **æ ¸å¿ƒåŸåˆ™**: P1 æ•°æ®æ‰©å±•å·²çº³å…¥ Steps 9-11ã€‚P2/P3 å¾…åŸºç¡€è®¾æ–½ç¨³å®šåå†å®æ–½ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        æ•°æ®æ‰©å±•çŠ¶æ€ (P1 å·²å®Œæˆè§„åˆ’)                           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                             â”‚
â”‚  âœ… ã€P1 å·²å‡çº§ä¸º Steps 9-11ã€‘                                               â”‚
â”‚  â”œâ”€ Step 9: L2æ·±åº¦èšåˆ + æ»‘ç‚¹æ ¡å‡† (Section 12.11)                           â”‚
â”‚  â”œâ”€ Step 10: æ¸…ç®—æ•°æ® + çº§è”æ£€æµ‹ (Section 12.12)                            â”‚
â”‚  â””â”€ Step 11: å¤šäº¤æ˜“æ‰€BasisçŸ©é˜µ (Section 12.13)                              â”‚
â”‚                                                                             â”‚
â”‚  â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•   â”‚
â”‚                                                                             â”‚
â”‚  â³ ã€P2 ä¸­æœŸæ‰©å±•ã€‘æœ‰ä»·å€¼ä½†å·¥ç¨‹é‡è¾ƒå¤§æˆ–å£å¾„éœ€éªŒè¯                              â”‚
â”‚  â”œâ”€ é“¾ä¸Šæµå‘äº¤æ˜“æ‰€ (ç¨³å®šå¸å‡€æµå…¥, BTC/ETHå¤§é¢è½¬è´¦)                            â”‚
â”‚  â””â”€ æ›´ç»†IVç»“æ„ (ä¸åŒDelta/åˆ°æœŸçš„skew, term structure)                        â”‚
â”‚                                                                             â”‚
â”‚  â¸ï¸ ã€P3 è°¨æ…æ‰©å±•ã€‘å…è´¹æ•°æ®ä¸ç¨³å®šï¼Œå®å¯æ™šåš                                   â”‚
â”‚  â””â”€ ç¤¾åª’/æ–°é—» (Reddit, Twitter, Telegram - å…è´¹APIå—é™ä¸¥é‡)                  â”‚
â”‚                                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 12.14.1 P2-1: é“¾ä¸Šæµå‘äº¤æ˜“æ‰€

**å¢é‡ä»·å€¼**: æ¯” DefiLlama çš„ä¾›åº”é‡æ›´æ¥è¿‘"äº¤æ˜“é©±åŠ¨"

**æ•°æ®æ¥æº**: å…¬å¼€é“¾ä¸Šæ•°æ® (éœ€è‡ªå»ºè§£ææˆ–ä½¿ç”¨å…è´¹API)

**å¯è§æ€§åˆ†çº§**: B/Cæ¡£

| æŒ‡æ ‡ | è¯´æ˜ | éš¾åº¦ |
|------|------|------|
| stablecoin_exchange_netflow | ç¨³å®šå¸å‡€æµå…¥äº¤æ˜“æ‰€ | ä¸­ |
| btc_exchange_netflow | BTCå‡€æµå…¥äº¤æ˜“æ‰€ | ä¸­ |
| eth_exchange_netflow | ETHå‡€æµå…¥äº¤æ˜“æ‰€ | ä¸­ |
| whale_transfer_count | å¤§é¢è½¬è´¦æ¬¡æ•° (>$1M) | ä½ |
| whale_transfer_volume | å¤§é¢è½¬è´¦é‡‘é¢ | ä½ |

**éš¾ç‚¹**: åœ°å€æ ‡ç­¾éœ€æ‰‹åŠ¨ç»´æŠ¤

---

#### 12.14.2 P2-2: æ›´ç»†IVç»“æ„

**å¢é‡ä»·å€¼**: å¯¹"è¡Œæƒ…åˆ¶åº¦åˆ‡æ¢/å°¾éƒ¨é£é™©"æ›´æ•æ„Ÿ

**æ•°æ®æ¥æº**: Deribit API (å·²æœ‰)

| æŒ‡æ ‡ | è¯´æ˜ |
|------|------|
| iv_25delta_put/call | 25-delta put/callçš„IV |
| iv_skew_25delta | 25-delta skew |
| iv_butterfly | å‡¸æ€§ (wings vs ATM) |
| iv_term_slope | è¿‘æœˆ vs è¿œæœˆ IVå·® |
| vol_surface_pca_1 | æ³¢åŠ¨ç‡æ›²é¢ç¬¬ä¸€ä¸»æˆåˆ† |

---

#### 12.14.3 P3: ç¤¾åª’/æ–°é—» (è°¨æ…)

**å»ºè®®**: åˆ—ä¸º"å¯é€‰/å®éªŒæ€§Cæ¡£"ï¼ŒPhase 3ä¹‹åå†è€ƒè™‘

---

#### 12.14.4 æ–°å¢æ•°æ®çš„å‡†å…¥æ£€æŸ¥æ¸…å•

> **ä»»ä½•æ–°å¢æ•°æ®ï¼Œéƒ½å¿…é¡»å…ˆå›ç­”ä»¥ä¸‹å››é¡¹**:

1. **å¯è§æ€§** - è¿™æ•°æ®åœ¨Tæ—¶åˆ»"ä»€ä¹ˆæ—¶å€™å¯è§"ï¼Ÿ
2. **å¯å¾—æ€§** - å†å²çª—å£å±äºA/B/Cå“ªä¸€æ¡£ï¼Ÿ
3. **å£å¾„ç¨³å®šæ€§** - äº¤æ˜“æ‰€ä¼šä¸ä¼šæ”¹APIï¼Ÿ
4. **å¢é‡éªŒè¯** - ablation + walk-forward éªŒè¯å¢é‡å­˜åœ¨

---

#### 12.14.5 æ•°æ®æ‰©å±•æ£€æŸ¥æ¸…å•

| ä¼˜å…ˆçº§ | æ•°æ®æº | çŠ¶æ€ | è¯¦ç»†æ–¹æ¡ˆ |
|--------|--------|------|----------|
| **P1** | **L2æ·±åº¦èšåˆ** | **â†’ Step 9** | Section 12.11 |
| **P1** | **æ¸…ç®—æ•°æ®** | **â†’ Step 10** | Section 12.12 |
| **P1** | **å¤šäº¤æ˜“æ‰€Basis** | **â†’ Step 11** | Section 12.13 |
| P2 | é“¾ä¸Šæµå‘äº¤æ˜“æ‰€ | â³ å¾…å®æ–½ | Section 12.14.1 |
| P2 | æ›´ç»†IVç»“æ„ | â³ å¾…å®æ–½ | Section 12.14.2 |
| P3 | ç¤¾åª’/æ–°é—» | â¸ï¸ è°¨æ… | Section 12.14.3 |

---

## æ–‡æ¡£æ€»ç»“

### æ ¸å¿ƒèƒ½åŠ›

1. **ç‰©ç†è¾¹ç•Œéš”ç¦»** - production/ vs research/ ç›®å½•éš”ç¦» + CIå¯¼å…¥æ‰«æé—¨ç¦
2. **DataManagerå”¯ä¸€å…¥å£** - ç¦æ­¢ç›´æ¥è®¿é—®DB/Redisï¼Œä¾èµ–æ³¨å…¥éš”ç¦»è¿æ¥ä¿¡æ¯
3. **Canonical Hashing** - è§„èŒƒåŒ–åºåˆ—åŒ–/æ’åº/æµ®ç‚¹ç²¾åº¦ï¼ŒCIè‡ªåŠ¨æ›´æ–°hash
4. **Replayç¡®å®šæ€§** - TimeProvider/SeededRandom/Decimalï¼Œæ¶ˆé™¤éç¡®å®šæ€§
5. **MVP Scopeé…ç½®å¼€å…³** - mvp_scope.yaml è¿è¡Œæ—¶å¼ºåˆ¶æ£€æŸ¥å› å­/æ•°æ®æºè¾¹ç•Œ
6. **åŒé“¾è·¯æ¶æ„** - ç”Ÿäº§é“¾è·¯ä¸ä¾èµ–Qlibï¼Œç ”ç©¶é“¾è·¯ç‹¬ç«‹
7. **MVPèŒƒå›´æ˜ç¡®** - 1æ—¶é—´æ¡†æ¶ (5m) + 20-50æ ‡çš„ + 11æ ¸å¿ƒå› å­
8. **ç‰ˆæœ¬åŒ–é…ç½®** - visibility.yaml + data_contracts/*.yaml + alignment.yaml
9. **å“ˆå¸Œå®¡è®¡** - æ‰€æœ‰é…ç½®æœ‰ config_version + config_hashï¼Œå¯åŠ¨æ—¶æ ¡éªŒ
10. **Daily Replayå¯¹é½** - å¯éªŒè¯çš„å›æµ‹-å®ç›˜é—­ç¯éªŒè¯
11. **4è½®è¿­ä»£äº¤ä»˜** - Iter-1å¥‘çº¦ â†’ Iter-2å¯¹é½ â†’ Iter-3å¿«ç…§ â†’ Iter-4æ‰§è¡Œå±‚
12. **åŠ¨æ€å› å­é—¨æ§›** - ICåŸºå‡†ç›¸å¯¹åŒ–ï¼Œé€‚é…åŠ å¯†è´§å¸é«˜æ³¢åŠ¨ç‰¹æ€§

### å®Œæ•´ç³»ç»Ÿèƒ½åŠ› (ç ”ç©¶ä¾§)

1. **æ•°æ®åˆ†çº§** - 6å¤§ç±»å…è´¹æ•°æ®æºï¼Œæ˜ç¡®A/B/Cä¸‰æ¡£å†å²å¯å¾—æ€§
2. **å› å­ä¸°å¯Œ** - 201ä¸ªæ°¸ç»­ä¸“ç”¨å› å­ (180æ ¸å¿ƒ + 21 P1æ‰©å±•)ï¼Œ**ä»…ç”¨äºç ”ç©¶**
3. **P1æ‰©å±•å®Œæˆ** - L2æ·±åº¦(8) + æ¸…ç®—(5) + å¤šäº¤æ˜“æ‰€Basis(8) = 21ä¸ªæ–°å› å­
4. **å›æµ‹å¯ä¿¡** - 6é¡¹P0éªŒæ”¶ + Steps 9-11 æ»‘ç‚¹æ ¡å‡†
5. **æ‰§è¡Œå¯é ** - Hummingbot v2.11.0 ä¼ä¸šçº§æˆç†Ÿåº¦
6. **å¯å¤ç°** - æ•°æ®å¿«ç…§ + Trace Schema + å®Œæ•´è¡€ç¼˜é“¾
7. **é›¶æ•°æ®æˆæœ¬** - å…¨éƒ¨ä½¿ç”¨å…è´¹å…¬å¼€æ•°æ®

> **MVP vs å®Œæ•´ç³»ç»Ÿ**: MVPç”Ÿäº§ç®¡é“ä»…ä½¿ç”¨11ä¸ªéªŒè¯å› å­ + 3ä¸ªæ•°æ®æºï¼Œ201å› å­ä½“ç³»ä»…ç”¨äºç ”ç©¶/å›æµ‹ï¼Œä¸è¿›å…¥ç”Ÿäº§ä»£ç ã€‚

---

*æ–‡æ¡£ç‰ˆæœ¬: v2.0.0 | æ›´æ–°äº 2025-12-31*