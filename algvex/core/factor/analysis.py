"""
AlgVex å› å­åˆ†æå·¥å…· (Qlib é£æ ¼)

å®ç° Qlib çš„å®Œæ•´å› å­åˆ†æåŠŸèƒ½:
- IC/Rank IC è®¡ç®—
- å› å­æ”¶ç›Šåˆ†æ
- å¤šç©ºæ”¶ç›Šè®¡ç®—
- åˆ†ç»„å›æµ‹
- ç›¸å…³æ€§çŸ©é˜µ
- å› å­è¡°å‡åˆ†æ

ç”¨æ³•:
    from algvex.core.factor.analysis import FactorAnalyzer

    analyzer = FactorAnalyzer()
    ic_result = analyzer.calc_ic(predictions, labels)
    report = analyzer.generate_report(predictions, labels, returns)
"""

import numpy as np
import pandas as pd
from typing import Union, Optional, Dict, List, Tuple
from dataclasses import dataclass

try:
    from scipy import stats
    SCIPY_AVAILABLE = True
except ImportError:
    SCIPY_AVAILABLE = False

try:
    from loguru import logger
except ImportError:
    import logging
    logger = logging.getLogger(__name__)


@dataclass
class ICResult:
    """IC è®¡ç®—ç»“æœ"""
    ic: float                       # Pearson IC
    rank_ic: float                  # Spearman Rank IC
    ic_mean: float                  # IC å‡å€¼
    ic_std: float                   # IC æ ‡å‡†å·®
    icir: float                     # IC ä¿¡æ¯æ¯”ç‡ (IC/std)
    rank_icir: float                # Rank IC ä¿¡æ¯æ¯”ç‡
    positive_ratio: float           # IC > 0 çš„æ¯”ç‡
    ic_series: pd.Series            # æ—¶åº IC
    rank_ic_series: pd.Series       # æ—¶åº Rank IC


@dataclass
class FactorReport:
    """å› å­åˆ†ææŠ¥å‘Š"""
    ic_result: ICResult
    long_short_return: float        # å¤šç©ºæ”¶ç›Š
    long_return: float              # å¤šå¤´æ”¶ç›Š
    short_return: float             # ç©ºå¤´æ”¶ç›Š
    turnover: float                 # æ¢æ‰‹ç‡
    quantile_returns: pd.DataFrame  # åˆ†ç»„æ”¶ç›Š
    decay_ic: pd.Series             # IC è¡°å‡


class FactorAnalyzer:
    """
    å› å­åˆ†æå™¨ (Qlib åŸç‰ˆ)

    æä¾›å®Œæ•´çš„å› å­è¯„ä¼°åŠŸèƒ½
    """

    def __init__(self, n_quantiles: int = 5):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            n_quantiles: åˆ†ç»„æ•°é‡
        """
        self.n_quantiles = n_quantiles

    def calc_ic(
        self,
        predictions: Union[pd.Series, pd.DataFrame],
        labels: Union[pd.Series, pd.DataFrame],
        method: str = "pearson",
    ) -> Union[float, Tuple[float, float]]:
        """
        è®¡ç®— IC (Information Coefficient)

        Args:
            predictions: é¢„æµ‹å€¼
            labels: å®é™…æ ‡ç­¾
            method: 'pearson' æˆ– 'spearman'

        Returns:
            IC å€¼ (å¦‚æœ method='both' è¿”å›å…ƒç»„)
        """
        if isinstance(predictions, pd.DataFrame):
            predictions = predictions.iloc[:, 0]
        if isinstance(labels, pd.DataFrame):
            labels = labels.iloc[:, 0]

        # å¯¹é½ç´¢å¼•
        common_idx = predictions.index.intersection(labels.index)
        pred = predictions.loc[common_idx].values
        label = labels.loc[common_idx].values

        # ç§»é™¤ NaN
        mask = ~(np.isnan(pred) | np.isnan(label))
        pred = pred[mask]
        label = label[mask]

        if len(pred) < 2:
            return np.nan if method != "both" else (np.nan, np.nan)

        if method == "pearson":
            return np.corrcoef(pred, label)[0, 1]
        elif method == "spearman":
            if SCIPY_AVAILABLE:
                return stats.spearmanr(pred, label)[0]
            else:
                # æ‰‹åŠ¨è®¡ç®— Spearman
                pred_rank = pd.Series(pred).rank().values
                label_rank = pd.Series(label).rank().values
                return np.corrcoef(pred_rank, label_rank)[0, 1]
        elif method == "both":
            pearson_ic = np.corrcoef(pred, label)[0, 1]
            if SCIPY_AVAILABLE:
                spearman_ic = stats.spearmanr(pred, label)[0]
            else:
                pred_rank = pd.Series(pred).rank().values
                label_rank = pd.Series(label).rank().values
                spearman_ic = np.corrcoef(pred_rank, label_rank)[0, 1]
            return pearson_ic, spearman_ic
        else:
            raise ValueError(f"Unknown method: {method}")

    def calc_ic_series(
        self,
        predictions: pd.DataFrame,
        labels: pd.DataFrame,
        group_col: str = None,
    ) -> ICResult:
        """
        è®¡ç®—æ—¶åº IC

        Args:
            predictions: é¢„æµ‹å€¼ (index=datetime, columns=assets æˆ–å•åˆ—)
            labels: å®é™…æ ‡ç­¾
            group_col: åˆ†ç»„åˆ— (å¦‚æ—¥æœŸ)

        Returns:
            ICResult å¯¹è±¡
        """
        # ç¡®ä¿æ˜¯ DataFrame
        if isinstance(predictions, pd.Series):
            predictions = predictions.to_frame('prediction')
        if isinstance(labels, pd.Series):
            labels = labels.to_frame('label')

        # å¦‚æœæœ‰ MultiIndexï¼Œæå–æ—¥æœŸä½œä¸ºåˆ†ç»„
        if isinstance(predictions.index, pd.MultiIndex):
            dates = predictions.index.get_level_values(0).unique()
        elif group_col is not None:
            dates = predictions[group_col].unique()
        else:
            # å‡è®¾ç´¢å¼•æ˜¯ datetime
            dates = predictions.index.unique()

        ic_list = []
        rank_ic_list = []

        for date in dates:
            try:
                if isinstance(predictions.index, pd.MultiIndex):
                    pred_slice = predictions.loc[date]
                    label_slice = labels.loc[date]
                else:
                    pred_slice = predictions.loc[[date]]
                    label_slice = labels.loc[[date]]

                if len(pred_slice) < 2:
                    continue

                ic, rank_ic = self.calc_ic(
                    pred_slice.iloc[:, 0],
                    label_slice.iloc[:, 0],
                    method="both"
                )

                ic_list.append((date, ic))
                rank_ic_list.append((date, rank_ic))
            except Exception as e:
                logger.debug(f"Skipping date {date}: {e}")
                continue

        if not ic_list:
            return ICResult(
                ic=np.nan, rank_ic=np.nan, ic_mean=np.nan, ic_std=np.nan,
                icir=np.nan, rank_icir=np.nan, positive_ratio=np.nan,
                ic_series=pd.Series(), rank_ic_series=pd.Series()
            )

        ic_series = pd.Series(dict(ic_list))
        rank_ic_series = pd.Series(dict(rank_ic_list))

        ic_mean = ic_series.mean()
        ic_std = ic_series.std()
        rank_ic_mean = rank_ic_series.mean()
        rank_ic_std = rank_ic_series.std()

        return ICResult(
            ic=ic_mean,
            rank_ic=rank_ic_mean,
            ic_mean=ic_mean,
            ic_std=ic_std,
            icir=ic_mean / ic_std if ic_std > 0 else np.nan,
            rank_icir=rank_ic_mean / rank_ic_std if rank_ic_std > 0 else np.nan,
            positive_ratio=(ic_series > 0).mean(),
            ic_series=ic_series,
            rank_ic_series=rank_ic_series,
        )

    def calc_long_short_return(
        self,
        predictions: pd.Series,
        returns: pd.Series,
        n_quantiles: int = None,
    ) -> Dict[str, float]:
        """
        è®¡ç®—å¤šç©ºæ”¶ç›Š

        Args:
            predictions: é¢„æµ‹å€¼
            returns: å®é™…æ”¶ç›Šç‡
            n_quantiles: åˆ†ç»„æ•°

        Returns:
            å¤šç©ºæ”¶ç›ŠæŒ‡æ ‡
        """
        n_quantiles = n_quantiles or self.n_quantiles

        # å¯¹é½
        common_idx = predictions.index.intersection(returns.index)
        pred = predictions.loc[common_idx]
        ret = returns.loc[common_idx]

        # å»é™¤ NaN
        mask = ~(pred.isna() | ret.isna())
        pred = pred[mask]
        ret = ret[mask]

        if len(pred) < n_quantiles:
            return {'long_short': np.nan, 'long': np.nan, 'short': np.nan}

        # åˆ†ç»„
        try:
            quantiles = pd.qcut(pred, n_quantiles, labels=False, duplicates='drop')
        except ValueError:
            # å¦‚æœåˆ†ç»„å¤±è´¥ï¼Œä½¿ç”¨ç™¾åˆ†ä½
            quantiles = pd.cut(pred.rank(pct=True), n_quantiles, labels=False)

        # è®¡ç®—å„ç»„æ”¶ç›Š
        group_returns = ret.groupby(quantiles).mean()

        # å¤šç©ºæ”¶ç›Š
        long_return = group_returns.iloc[-1] if len(group_returns) > 0 else np.nan
        short_return = group_returns.iloc[0] if len(group_returns) > 0 else np.nan
        long_short = long_return - short_return

        return {
            'long_short': long_short,
            'long': long_return,
            'short': short_return,
            'quantile_returns': group_returns,
        }

    def calc_quantile_returns(
        self,
        predictions: pd.DataFrame,
        returns: pd.DataFrame,
        n_quantiles: int = None,
    ) -> pd.DataFrame:
        """
        è®¡ç®—åˆ†ç»„æ”¶ç›Š

        Args:
            predictions: é¢„æµ‹å€¼ (æ¯è¡Œæ˜¯ä¸€ä¸ªæ—¶é—´ç‚¹)
            returns: å®é™…æ”¶ç›Šç‡
            n_quantiles: åˆ†ç»„æ•°

        Returns:
            åˆ†ç»„æ”¶ç›Š DataFrame
        """
        n_quantiles = n_quantiles or self.n_quantiles

        # ç¡®ä¿æ˜¯ DataFrame
        if isinstance(predictions, pd.Series):
            predictions = predictions.to_frame('prediction')
        if isinstance(returns, pd.Series):
            returns = returns.to_frame('return')

        results = []

        for idx in predictions.index:
            if idx not in returns.index:
                continue

            pred = predictions.loc[idx]
            ret = returns.loc[idx]

            if isinstance(pred, pd.Series) and isinstance(ret, pd.Series):
                # å•èµ„äº§
                continue

            # å¯¹é½èµ„äº§
            common = pred.index.intersection(ret.index)
            if len(common) < n_quantiles:
                continue

            pred_slice = pred[common]
            ret_slice = ret[common]

            # åˆ†ç»„
            try:
                quantiles = pd.qcut(pred_slice, n_quantiles, labels=False, duplicates='drop')
            except ValueError:
                continue

            # å„ç»„å¹³å‡æ”¶ç›Š
            group_ret = ret_slice.groupby(quantiles).mean()
            group_ret.name = idx
            results.append(group_ret)

        if not results:
            return pd.DataFrame()

        return pd.DataFrame(results)

    def calc_factor_decay(
        self,
        predictions: pd.Series,
        future_returns: Dict[int, pd.Series],
        max_lag: int = 20,
    ) -> pd.Series:
        """
        è®¡ç®—å› å­è¡°å‡

        Args:
            predictions: é¢„æµ‹å€¼
            future_returns: {lag: æœªæ¥ lag æœŸçš„æ”¶ç›Šç‡}
            max_lag: æœ€å¤§æ»åæœŸ

        Returns:
            å„æ»åæœŸçš„ IC
        """
        decay_ic = {}

        for lag in range(1, max_lag + 1):
            if lag not in future_returns:
                continue

            ret = future_returns[lag]
            common_idx = predictions.index.intersection(ret.index)

            if len(common_idx) < 10:
                continue

            ic = self.calc_ic(predictions.loc[common_idx], ret.loc[common_idx])
            decay_ic[lag] = ic

        return pd.Series(decay_ic)

    def calc_turnover(
        self,
        positions_series: List[pd.Series],
    ) -> float:
        """
        è®¡ç®—æ¢æ‰‹ç‡

        Args:
            positions_series: æŒä»“æƒé‡åºåˆ—

        Returns:
            å¹³å‡æ¢æ‰‹ç‡
        """
        if len(positions_series) < 2:
            return 0.0

        turnovers = []
        for i in range(1, len(positions_series)):
            prev = positions_series[i-1]
            curr = positions_series[i]

            # å¯¹é½
            all_assets = prev.index.union(curr.index)
            prev_aligned = prev.reindex(all_assets, fill_value=0)
            curr_aligned = curr.reindex(all_assets, fill_value=0)

            # æ¢æ‰‹ç‡ = |Î”w| / 2
            turnover = np.abs(curr_aligned - prev_aligned).sum() / 2
            turnovers.append(turnover)

        return np.mean(turnovers)

    def calc_factor_correlation(
        self,
        factors: pd.DataFrame,
    ) -> pd.DataFrame:
        """
        è®¡ç®—å› å­ç›¸å…³æ€§çŸ©é˜µ

        Args:
            factors: å› å­æ•°æ® (columns=å› å­å)

        Returns:
            ç›¸å…³æ€§çŸ©é˜µ
        """
        return factors.corr()

    def calc_factor_rank_correlation(
        self,
        factors: pd.DataFrame,
    ) -> pd.DataFrame:
        """
        è®¡ç®—å› å­ç§©ç›¸å…³æ€§çŸ©é˜µ

        Args:
            factors: å› å­æ•°æ®

        Returns:
            ç§©ç›¸å…³æ€§çŸ©é˜µ
        """
        if SCIPY_AVAILABLE:
            n = factors.shape[1]
            corr_matrix = np.zeros((n, n))
            for i in range(n):
                for j in range(n):
                    if i <= j:
                        mask = ~(factors.iloc[:, i].isna() | factors.iloc[:, j].isna())
                        if mask.sum() > 2:
                            corr, _ = stats.spearmanr(
                                factors.iloc[:, i][mask],
                                factors.iloc[:, j][mask]
                            )
                            corr_matrix[i, j] = corr
                            corr_matrix[j, i] = corr
            return pd.DataFrame(
                corr_matrix,
                index=factors.columns,
                columns=factors.columns
            )
        else:
            # ä½¿ç”¨æ’ååçš„ Pearson ç›¸å…³
            return factors.rank().corr()

    def generate_report(
        self,
        predictions: pd.Series,
        labels: pd.Series,
        returns: pd.Series = None,
    ) -> FactorReport:
        """
        ç”Ÿæˆå®Œæ•´å› å­æŠ¥å‘Š

        Args:
            predictions: é¢„æµ‹å€¼
            labels: å®é™…æ ‡ç­¾
            returns: å®é™…æ”¶ç›Šç‡ (å¯é€‰ï¼Œç”¨äºå¤šç©ºåˆ†æ)

        Returns:
            FactorReport å¯¹è±¡
        """
        # IC åˆ†æ
        ic, rank_ic = self.calc_ic(predictions, labels, method="both")

        # åˆ›å»ºç®€åŒ–çš„ ICResult
        ic_result = ICResult(
            ic=ic,
            rank_ic=rank_ic,
            ic_mean=ic,
            ic_std=0.0,
            icir=np.nan,
            rank_icir=np.nan,
            positive_ratio=1.0 if ic > 0 else 0.0,
            ic_series=pd.Series([ic]),
            rank_ic_series=pd.Series([rank_ic]),
        )

        # å¤šç©ºæ”¶ç›Š
        if returns is not None:
            ls_result = self.calc_long_short_return(predictions, returns)
            long_short_return = ls_result['long_short']
            long_return = ls_result['long']
            short_return = ls_result['short']
            quantile_returns = ls_result.get('quantile_returns', pd.DataFrame())
        else:
            long_short_return = np.nan
            long_return = np.nan
            short_return = np.nan
            quantile_returns = pd.DataFrame()

        return FactorReport(
            ic_result=ic_result,
            long_short_return=long_short_return,
            long_return=long_return,
            short_return=short_return,
            turnover=0.0,
            quantile_returns=quantile_returns,
            decay_ic=pd.Series(),
        )

    def print_report(self, report: FactorReport):
        """æ‰“å°å› å­æŠ¥å‘Š"""
        print("=" * 60)
        print("å› å­åˆ†ææŠ¥å‘Š")
        print("=" * 60)
        print(f"\nğŸ“Š IC åˆ†æ:")
        print(f"  Pearson IC:   {report.ic_result.ic:.4f}")
        print(f"  Rank IC:      {report.ic_result.rank_ic:.4f}")
        print(f"  IC IR:        {report.ic_result.icir:.4f}")
        print(f"  Rank IC IR:   {report.ic_result.rank_icir:.4f}")
        print(f"  IC æ­£å‘æ¯”ä¾‹:  {report.ic_result.positive_ratio:.2%}")

        if not np.isnan(report.long_short_return):
            print(f"\nğŸ“ˆ å¤šç©ºæ”¶ç›Š:")
            print(f"  å¤šç©ºæ”¶ç›Š:     {report.long_short_return:.4f}")
            print(f"  å¤šå¤´æ”¶ç›Š:     {report.long_return:.4f}")
            print(f"  ç©ºå¤´æ”¶ç›Š:     {report.short_return:.4f}")

        if not report.quantile_returns.empty:
            print(f"\nğŸ“Š åˆ†ç»„æ”¶ç›Š:")
            print(report.quantile_returns)

        print("=" * 60)


# ============================================================
# é£é™©åˆ†æ (Qlib åŸç‰ˆ)
# ============================================================

def risk_analysis(
    returns: pd.Series,
    rf: float = 0.0,
    freq: str = 'day',
) -> Dict[str, float]:
    """
    é£é™©åˆ†æ

    Args:
        returns: æ”¶ç›Šç‡åºåˆ—
        rf: æ— é£é™©åˆ©ç‡ (å¹´åŒ–)
        freq: é¢‘ç‡ ('day', 'hour', 'minute', '5min')

    Returns:
        é£é™©æŒ‡æ ‡å­—å…¸
    """
    # é¢‘ç‡è½¬æ¢å› å­
    freq_map = {
        'day': 252,
        'hour': 252 * 24,
        'minute': 252 * 24 * 60,
        '5min': 252 * 24 * 12,
        '1h': 252 * 24,
        '5m': 252 * 24 * 12,
    }
    ann_factor = freq_map.get(freq, 252)

    # åŸºç¡€ç»Ÿè®¡
    total_return = (1 + returns).prod() - 1
    ann_return = (1 + total_return) ** (ann_factor / len(returns)) - 1
    ann_volatility = returns.std() * np.sqrt(ann_factor)

    # å¤æ™®æ¯”ç‡
    excess_return = ann_return - rf
    sharpe_ratio = excess_return / ann_volatility if ann_volatility > 0 else np.nan

    # æœ€å¤§å›æ’¤
    cum_returns = (1 + returns).cumprod()
    running_max = cum_returns.cummax()
    drawdown = (cum_returns - running_max) / running_max
    max_drawdown = drawdown.min()

    # Calmar æ¯”ç‡
    calmar_ratio = ann_return / abs(max_drawdown) if max_drawdown != 0 else np.nan

    # èƒœç‡
    win_rate = (returns > 0).mean()

    # ç›ˆäºæ¯”
    wins = returns[returns > 0]
    losses = returns[returns < 0]
    profit_loss_ratio = abs(wins.mean() / losses.mean()) if len(losses) > 0 and losses.mean() != 0 else np.nan

    return {
        'total_return': total_return,
        'annual_return': ann_return,
        'annual_volatility': ann_volatility,
        'sharpe_ratio': sharpe_ratio,
        'max_drawdown': max_drawdown,
        'calmar_ratio': calmar_ratio,
        'win_rate': win_rate,
        'profit_loss_ratio': profit_loss_ratio,
        'n_trades': len(returns),
    }


def print_risk_analysis(metrics: Dict[str, float]):
    """æ‰“å°é£é™©åˆ†æç»“æœ"""
    print("=" * 60)
    print("é£é™©åˆ†ææŠ¥å‘Š")
    print("=" * 60)
    print(f"  æ€»æ”¶ç›Š:       {metrics['total_return']:.2%}")
    print(f"  å¹´åŒ–æ”¶ç›Š:     {metrics['annual_return']:.2%}")
    print(f"  å¹´åŒ–æ³¢åŠ¨ç‡:   {metrics['annual_volatility']:.2%}")
    print(f"  å¤æ™®æ¯”ç‡:     {metrics['sharpe_ratio']:.2f}")
    print(f"  æœ€å¤§å›æ’¤:     {metrics['max_drawdown']:.2%}")
    print(f"  å¡ç›æ¯”ç‡:     {metrics['calmar_ratio']:.2f}")
    print(f"  èƒœç‡:         {metrics['win_rate']:.2%}")
    print(f"  ç›ˆäºæ¯”:       {metrics['profit_loss_ratio']:.2f}")
    print("=" * 60)


# ============================================================
# ä¾¿æ·å‡½æ•°
# ============================================================

def calc_ic(
    predictions: pd.Series,
    labels: pd.Series,
) -> Tuple[float, float]:
    """
    è®¡ç®— IC (ä¾¿æ·å‡½æ•°)

    Returns:
        (Pearson IC, Rank IC)
    """
    analyzer = FactorAnalyzer()
    return analyzer.calc_ic(predictions, labels, method="both")


def generate_factor_report(
    predictions: pd.Series,
    labels: pd.Series,
    returns: pd.Series = None,
) -> FactorReport:
    """
    ç”Ÿæˆå› å­æŠ¥å‘Š (ä¾¿æ·å‡½æ•°)
    """
    analyzer = FactorAnalyzer()
    return analyzer.generate_report(predictions, labels, returns)


# å¯¼å‡º
__all__ = [
    'ICResult',
    'FactorReport',
    'FactorAnalyzer',
    'risk_analysis',
    'print_risk_analysis',
    'calc_ic',
    'generate_factor_report',
]
