"""
åŠ å¯†è´§å¸æ•°æ®å‡†å¤‡è„šæœ¬ (v10.1.0) - å®˜æ–¹æ•°æ®æºç‰ˆæœ¬

ä½¿ç”¨ Binance å®˜æ–¹æ•°æ®æº (data.binance.vision) ä¸‹è½½å†å² K çº¿æ•°æ®ã€‚
ç›¸æ¯” REST API æ–¹å¼ï¼Œé€Ÿåº¦å¿« 10-100 å€ï¼Œæ—  API é™æµï¼Œæœ‰æ ¡éªŒä¿è¯æ•°æ®å®Œæ•´æ€§ã€‚

è¾“å‡ºç›®å½•: ~/.algvex/data/{freq}/ (å¯é€šè¿‡ ALGVEX_DATA_DIR ç¯å¢ƒå˜é‡è‡ªå®šä¹‰)
è¾“å‡ºæ–‡ä»¶: {instrument}.parquet

ç”¨æ³•:
    pip install binance-historical-data
    python scripts/prepare_crypto_data.py --trading-pairs BTC-USDT ETH-USDT --interval 1h

ç¯å¢ƒå˜é‡:
    ALGVEX_DATA_DIR: è‡ªå®šä¹‰æ•°æ®ç›®å½• (é»˜è®¤ ~/.algvex/data)
    HTTPS_PROXY: ä»£ç†æœåŠ¡å™¨ (å¦‚ http://127.0.0.1:7890)

æ•°æ®æº: https://data.binance.vision/
"""

import os
import sys
import json
import argparse
import tempfile
import shutil
from pathlib import Path
from datetime import date, datetime, timezone
from typing import List, Dict, Optional

import pandas as pd


# ============================================================================
# å¸¸é‡å®šä¹‰
# ============================================================================

# æ”¯æŒçš„æ—¶é—´é—´éš”
SUPPORTED_INTERVALS = ["1m", "3m", "5m", "15m", "30m", "1h", "2h", "4h", "6h", "8h", "12h", "1d"]

# CSV åˆ—åæ˜ å°„ (Binance å®˜æ–¹æ ¼å¼)
KLINE_COLUMNS = [
    "open_time", "open", "high", "low", "close", "volume",
    "close_time", "quote_volume", "trades", "taker_buy_base",
    "taker_buy_quote", "ignore"
]


# ============================================================================
# å·¥å…·å‡½æ•°
# ============================================================================

def trading_pair_to_symbol(trading_pair: str) -> str:
    """å°†äº¤æ˜“å¯¹è½¬æ¢ä¸º Binance symbol: BTC-USDT -> BTCUSDT"""
    return trading_pair.replace("-", "").upper()


def trading_pair_to_instrument(trading_pair: str) -> str:
    """å°†äº¤æ˜“å¯¹è½¬æ¢ä¸º instrument åç§°: BTC-USDT -> btcusdt"""
    return trading_pair.replace("-", "").lower()


def get_default_data_dir() -> Path:
    """è·å–é»˜è®¤æ•°æ®ç›®å½•"""
    return Path(os.environ.get("ALGVEX_DATA_DIR", Path.home() / ".algvex" / "data"))


def check_binance_historical_data() -> bool:
    """æ£€æŸ¥ binance-historical-data åŒ…æ˜¯å¦å·²å®‰è£…"""
    try:
        from binance_historical_data import BinanceDataDumper
        return True
    except ImportError:
        return False


# ============================================================================
# æ•°æ®ä¸‹è½½ (ä½¿ç”¨å®˜æ–¹åŒ…)
# ============================================================================

def download_with_official_package(
    symbols: List[str],
    interval: str,
    start_date: date,
    end_date: date,
    temp_dir: Path,
) -> Dict[str, Path]:
    """
    ä½¿ç”¨ binance-historical-data å®˜æ–¹åŒ…ä¸‹è½½æ•°æ®

    Returns
    -------
    Dict[str, Path]
        symbol -> æ•°æ®ç›®å½•è·¯å¾„
    """
    from binance_historical_data import BinanceDataDumper

    print(f"\nğŸ“¥ ä½¿ç”¨å®˜æ–¹æ•°æ®æºä¸‹è½½ (data.binance.vision)")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
    print(f"   äº¤æ˜“å¯¹: {', '.join(symbols)}")
    print(f"   é—´éš”: {interval}")
    print()

    # åˆ›å»ºä¸‹è½½å™¨
    dumper = BinanceDataDumper(
        path_dir_where_to_dump=str(temp_dir),
        asset_class="spot",
        data_type="klines",
        data_frequency=interval,
    )

    # ä¸‹è½½æ•°æ®
    dumper.dump_data(
        tickers=symbols,
        date_start=start_date,
        date_end=end_date,
        is_to_update_existing=False,
    )

    # è¿”å›æ•°æ®ç›®å½•
    result = {}
    for symbol in symbols:
        data_dir = temp_dir / "spot" / "klines" / symbol / interval
        if data_dir.exists():
            result[symbol] = data_dir
        else:
            print(f"   âš ï¸ {symbol} æ•°æ®ç›®å½•ä¸å­˜åœ¨")

    return result


# ============================================================================
# æ•°æ®è½¬æ¢
# ============================================================================

def load_csv_files(data_dir: Path) -> pd.DataFrame:
    """
    åŠ è½½ç›®å½•ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶å¹¶åˆå¹¶

    Parameters
    ----------
    data_dir : Path
        åŒ…å« CSV æ–‡ä»¶çš„ç›®å½•

    Returns
    -------
    pd.DataFrame
        åˆå¹¶åçš„æ•°æ®
    """
    all_files = sorted(data_dir.glob("*.csv"))

    if not all_files:
        return pd.DataFrame()

    dfs = []
    for f in all_files:
        try:
            df = pd.read_csv(f, header=None, names=KLINE_COLUMNS)
            dfs.append(df)
        except Exception as e:
            print(f"   âš ï¸ è¯»å– {f.name} å¤±è´¥: {e}")

    if not dfs:
        return pd.DataFrame()

    # åˆå¹¶å¹¶å»é‡
    combined = pd.concat(dfs, ignore_index=True)
    combined = combined.drop_duplicates(subset=["open_time"])
    combined = combined.sort_values("open_time")

    return combined


def convert_to_parquet_format(df: pd.DataFrame) -> pd.DataFrame:
    """
    å°† Binance CSV æ ¼å¼è½¬æ¢ä¸º AlgVex Parquet æ ¼å¼

    è¾“å‡ºæ ¼å¼:
    - Index: datetime (UTC)
    - Columns: open, high, low, close, volume, quote_volume
    """
    if df.empty:
        return pd.DataFrame()

    # æ£€æµ‹æ—¶é—´æˆ³å•ä½ (2025å¹´èµ· Binance ä½¿ç”¨å¾®ç§’)
    sample_ts = df["open_time"].iloc[0]
    if sample_ts > 1e15:  # å¾®ç§’
        unit = "us"
    elif sample_ts > 1e12:  # æ¯«ç§’
        unit = "ms"
    else:  # ç§’
        unit = "s"

    # è½¬æ¢æ—¶é—´æˆ³
    df["datetime"] = pd.to_datetime(df["open_time"], unit=unit, utc=True)
    df = df.set_index("datetime")

    # åªä¿ç•™éœ€è¦çš„åˆ—
    result = pd.DataFrame({
        "open": df["open"].astype(float),
        "high": df["high"].astype(float),
        "low": df["low"].astype(float),
        "close": df["close"].astype(float),
        "volume": df["volume"].astype(float),
        "quote_volume": df["quote_volume"].astype(float),
    })

    return result


def save_to_parquet(
    data: Dict[str, pd.DataFrame],
    output_dir: Path,
    interval: str,
) -> None:
    """
    ä¿å­˜ä¸º Parquet æ ¼å¼

    ç›®å½•ç»“æ„:
    output_dir/
    â””â”€â”€ {interval}/
        â”œâ”€â”€ btcusdt.parquet
        â”œâ”€â”€ ethusdt.parquet
        â””â”€â”€ metadata.json
    """
    freq_dir = output_dir / interval
    freq_dir.mkdir(parents=True, exist_ok=True)

    metadata = {
        "freq": interval,
        "timezone": "UTC",
        "source": "data.binance.vision",
        "version": "v10.1.0",
        "instruments": [],
        "columns": ["open", "high", "low", "close", "volume", "quote_volume"],
    }

    for symbol, df in data.items():
        instrument = symbol.lower()
        file_path = freq_dir / f"{instrument}.parquet"

        # ä¿å­˜ Parquet
        df.to_parquet(file_path, engine="pyarrow")

        # æ›´æ–°å…ƒæ•°æ®
        metadata["instruments"].append({
            "name": instrument,
            "symbol": symbol,
            "start": df.index.min().isoformat(),
            "end": df.index.max().isoformat(),
            "rows": len(df),
        })
        print(f"   âœ… {instrument}.parquet: {len(df):,} è¡Œ")

    # ä¿å­˜å…ƒæ•°æ®
    with open(freq_dir / "metadata.json", "w") as f:
        json.dump(metadata, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ“ æ•°æ®å·²ä¿å­˜åˆ°: {freq_dir}")


# ============================================================================
# ä¸»å‡½æ•°
# ============================================================================

def main():
    parser = argparse.ArgumentParser(
        description="ä» Binance å®˜æ–¹æ•°æ®æºä¸‹è½½å†å² K çº¿æ•°æ®",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # åŸºæœ¬ç”¨æ³•
  python scripts/prepare_crypto_data.py --trading-pairs BTC-USDT ETH-USDT

  # æŒ‡å®šæ—¶é—´èŒƒå›´
  python scripts/prepare_crypto_data.py --start-date 2023-01-01 --end-date 2024-12-31

  # è‡ªå®šä¹‰è¾“å‡ºç›®å½•
  python scripts/prepare_crypto_data.py --output-dir /path/to/data

ç¯å¢ƒå˜é‡:
  ALGVEX_DATA_DIR  - è‡ªå®šä¹‰æ•°æ®ç›®å½• (é»˜è®¤: ~/.algvex/data)
  HTTPS_PROXY      - ä»£ç†æœåŠ¡å™¨åœ°å€

æ•°æ®æº: https://data.binance.vision/
        """
    )

    parser.add_argument(
        "--trading-pairs",
        type=str,
        nargs="+",
        default=["BTC-USDT", "ETH-USDT"],
        help="äº¤æ˜“å¯¹åˆ—è¡¨ (é»˜è®¤: BTC-USDT ETH-USDT)",
    )
    parser.add_argument(
        "--interval",
        type=str,
        default="1h",
        choices=SUPPORTED_INTERVALS,
        help="Kçº¿é—´éš” (é»˜è®¤: 1h)",
    )
    parser.add_argument(
        "--start-date",
        type=str,
        default="2023-01-01",
        help="å¼€å§‹æ—¥æœŸ YYYY-MM-DD (é»˜è®¤: 2023-01-01)",
    )
    parser.add_argument(
        "--end-date",
        type=str,
        default="2024-12-31",
        help="ç»“æŸæ—¥æœŸ YYYY-MM-DD (é»˜è®¤: 2024-12-31)",
    )
    parser.add_argument(
        "--output-dir",
        type=str,
        default=None,
        help="è¾“å‡ºç›®å½• (é»˜è®¤: ~/.algvex/data æˆ– ALGVEX_DATA_DIR)",
    )

    # å…¼å®¹æ—§å‚æ•° (å¿½ç•¥)
    parser.add_argument("--sync", action="store_true", help=argparse.SUPPRESS)
    parser.add_argument("--proxy", type=str, help=argparse.SUPPRESS)
    parser.add_argument("--api-base", type=str, help=argparse.SUPPRESS)

    args = parser.parse_args()

    # -------------------------------------------------------------------------
    # æ£€æŸ¥ä¾èµ–
    # -------------------------------------------------------------------------
    print("=" * 60)
    print("AlgVex æ•°æ®å‡†å¤‡å·¥å…· v10.1.0 (å®˜æ–¹æ•°æ®æº)")
    print("=" * 60)

    if not check_binance_historical_data():
        print("\nâŒ ç¼ºå°‘ä¾èµ–: binance-historical-data")
        print("\nè¯·å®‰è£…:")
        print("  pip install binance-historical-data")
        print("\næˆ–ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®:")
        print("  python scripts/generate_mock_data.py")
        sys.exit(1)

    try:
        import pyarrow
    except ImportError:
        print("\nâŒ ç¼ºå°‘ä¾èµ–: pyarrow")
        print("  pip install pyarrow")
        sys.exit(1)

    # -------------------------------------------------------------------------
    # æ£€æŸ¥ä»£ç†
    # -------------------------------------------------------------------------
    proxy = os.environ.get("HTTPS_PROXY") or os.environ.get("https_proxy")
    if proxy:
        print(f"\nğŸŒ ä»£ç†å·²é…ç½®: {proxy}")
    else:
        print("\nğŸŒ æœªé…ç½®ä»£ç† (å¦‚é‡ä¸‹è½½é—®é¢˜ï¼Œè¯·è®¾ç½® HTTPS_PROXY)")

    # -------------------------------------------------------------------------
    # è§£æå‚æ•°
    # -------------------------------------------------------------------------
    try:
        start_date = datetime.strptime(args.start_date, "%Y-%m-%d").date()
        end_date = datetime.strptime(args.end_date, "%Y-%m-%d").date()
    except ValueError as e:
        print(f"\nâŒ æ—¥æœŸæ ¼å¼é”™è¯¯: {e}")
        print("   è¯·ä½¿ç”¨ YYYY-MM-DD æ ¼å¼")
        sys.exit(1)

    if start_date >= end_date:
        print("\nâŒ start-date å¿…é¡»æ—©äº end-date")
        sys.exit(1)

    # è¾“å‡ºç›®å½•
    if args.output_dir:
        output_dir = Path(args.output_dir).expanduser()
    else:
        output_dir = get_default_data_dir()

    # è½¬æ¢äº¤æ˜“å¯¹ä¸º Binance symbol
    symbols = [trading_pair_to_symbol(p) for p in args.trading_pairs]

    print(f"\nğŸ“Š é…ç½®:")
    print(f"   äº¤æ˜“å¯¹: {', '.join(args.trading_pairs)}")
    print(f"   Symbols: {', '.join(symbols)}")
    print(f"   é—´éš”: {args.interval}")
    print(f"   æ—¶é—´èŒƒå›´: {start_date} ~ {end_date}")
    print(f"   è¾“å‡ºç›®å½•: {output_dir}")

    # -------------------------------------------------------------------------
    # ä¸‹è½½æ•°æ®
    # -------------------------------------------------------------------------
    with tempfile.TemporaryDirectory() as temp_dir:
        temp_path = Path(temp_dir)

        try:
            data_dirs = download_with_official_package(
                symbols=symbols,
                interval=args.interval,
                start_date=start_date,
                end_date=end_date,
                temp_dir=temp_path,
            )
        except Exception as e:
            print(f"\nâŒ ä¸‹è½½å¤±è´¥: {e}")
            print("\nğŸ’¡ æ•…éšœæ’é™¤:")
            print("   1. æ£€æŸ¥ç½‘ç»œè¿æ¥")
            print("   2. å¦‚æœåœ¨ä¸­å›½ï¼Œè®¾ç½®ä»£ç†: export HTTPS_PROXY=http://127.0.0.1:7890")
            print("   3. ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®: python scripts/generate_mock_data.py")
            sys.exit(1)

        if not data_dirs:
            print("\nâŒ æœªä¸‹è½½åˆ°ä»»ä½•æ•°æ®")
            sys.exit(1)

        # ---------------------------------------------------------------------
        # è½¬æ¢æ ¼å¼
        # ---------------------------------------------------------------------
        print("\nğŸ”„ è½¬æ¢ä¸º Parquet æ ¼å¼...")

        converted_data = {}
        for symbol, data_dir in data_dirs.items():
            print(f"   å¤„ç† {symbol}...")

            # åŠ è½½ CSV
            raw_df = load_csv_files(data_dir)
            if raw_df.empty:
                print(f"   âš ï¸ {symbol} æ— æ•°æ®")
                continue

            # è½¬æ¢æ ¼å¼
            parquet_df = convert_to_parquet_format(raw_df)

            # è¿‡æ»¤æ—¶é—´èŒƒå›´
            start_ts = pd.Timestamp(start_date, tz="UTC")
            end_ts = pd.Timestamp(end_date, tz="UTC") + pd.Timedelta(days=1)
            parquet_df = parquet_df[(parquet_df.index >= start_ts) & (parquet_df.index < end_ts)]

            if not parquet_df.empty:
                converted_data[symbol] = parquet_df

    if not converted_data:
        print("\nâŒ è½¬æ¢åæ— æœ‰æ•ˆæ•°æ®")
        sys.exit(1)

    # -------------------------------------------------------------------------
    # ä¿å­˜æ•°æ®
    # -------------------------------------------------------------------------
    print("\nğŸ’¾ ä¿å­˜æ•°æ®...")
    save_to_parquet(converted_data, output_dir, args.interval)

    # -------------------------------------------------------------------------
    # å®Œæˆ
    # -------------------------------------------------------------------------
    print("\n" + "=" * 60)
    print("âœ… æ•°æ®å‡†å¤‡å®Œæˆ!")
    print("=" * 60)
    print(f"   ä¸‹è½½: {', '.join(converted_data.keys())}")
    print(f"   ä½ç½®: {output_dir / args.interval}")
    print(f"   æ•°æ®æº: data.binance.vision (å®˜æ–¹)")


if __name__ == "__main__":
    main()
